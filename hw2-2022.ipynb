{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RZY7kcPjTtIk"
   },
   "source": [
    "# Домашнее задание 2\n",
    "## Named Entity Recognition and Event Extraction\n",
    "\n",
    "deadline: 06 ноября 2022, 23:59\n",
    "\n",
    "В этом домашнем задании вы будете работать с двумя корпусами - LitBank и MultiNERD_EN.\n",
    "Первый корпус (LitBank) собран из популярных художественных произведений на английском языке и содержит разметку по именованным сущностям и событиям, корпус состоит из 100 текстов по примерно 2000 слов каждый. \n",
    "\n",
    "Корпус описан в статьях:\n",
    "* David Bamman, Sejal Popat, Sheng Shen, An Annotated Dataset of Literary Entities http://people.ischool.berkeley.edu/~dbamman/pubs/pdf/naacl2019_literary_entities.pdf\n",
    "* Matthew Sims, Jong Ho Park, David Bamman, Literary Event Detection,  http://people.ischool.berkeley.edu/~dbamman/pubs/pdf/acl2019_literary_events.pdf\n",
    "\n",
    "Корпус доступен в репозитории проекта:  https://github.com/dbamman/litbank\n",
    "\n",
    "Статья и код, использованный для извлечения именованных сущностей: \n",
    "* Meizhi Ju, Makoto Miwa and Sophia Ananiadou, A Neural Layered Model for Nested Named Entity Recognition, https://github.com/meizhiju/layered-bilstm-crf\n",
    "\n",
    "Структура корпуса устроена так. \n",
    "Первый уровень: \n",
    "* entities -- разметка по сущностям\n",
    "* events -- разметка по сущностям\n",
    "\n",
    "\n",
    "В корпусе используются 6 типов именованных сущностей: PER, LOC, ORG, FAC, GPE, VEH (имена, локации, организации, помещения, топонимы, средства перемещения), допускаются вложенные сущности. \n",
    "\n",
    "События выражается одним словом - *триггером*, которое может быть глаголом, прилагательным и существительным. В корпусе описаны события, которые действительно происходят и не имеют гипотетического характера. \n",
    "Пример: she *walked* rapidly and resolutely, здесь *walked* -- триггер события. Типы событий не заданы. \n",
    "\n",
    "\n",
    "Второй уровень:\n",
    "* brat -- рабочие файлы инструмента разметки brat, ann-файлы содержат разметку, txt-файлы – сырые тексты \n",
    "* tsv -- tsv-файлы содержат разметку в IOB формате,\n",
    "\n",
    "Второй корпус (MultiNERD_EN) состоит из 164 тысяч предложений по различным тематикам. От предыдущего корпуса он отличается большим числом (15) типов именованных сущностей. Также одной из сущностей является сущность-событие (EVE). Каждая сущность может состоять как из одного, так и нескольких слов.\n",
    "\n",
    "Корпус доступен в репозитории проекта:  https://github.com/Babelscape/multinerd\n",
    "\n",
    "В статьях и репозиториях вы найдете идеи, которые помогут вам выполнить домашнее задание. Их стоит воспринимать как руководство к действию, и не стоит их копировать и использовать повторно. Обученные модели использовать не нужно, код для их обучения можно использовать как подсказку. \n",
    "\n",
    "## ПРАВИЛА\n",
    "1. Домашнее задание выполняется в группе до 4-х человек.\n",
    "2. Домашнее задание оформляется в виде отчета либо в .pdf файле, либо в ipython-тетрадке. При этом прикладывать ipynb-файл обязательно. \n",
    "43. Отчет должен содержать: нумерацию заданий и пунктов, которые вы выполнили, код решения, и понятное пошаговое описание того, что вы сделали. Отчет должен быть написан в академическом стиле, без излишнего использования сленга и с соблюдением норм русского языка.\n",
    "4. Не стоит копировать фрагменты лекций, статей и Википедии в ваш отчет.\n",
    "5. Отчеты, состоящие исключительно из кода, не будут проверены и будут автоматически оценены нулевой оценкой.\n",
    "6. Плагиат и любое недобросовестное цитирование приводит к обнулению оценки. \n",
    "\n",
    "\n",
    "## Часть 1. [2 балла] Эксплоративный анализ \n",
    "1. [0.4 балла] Найдите топ 10 (по частоте) именованных сущностей каждого из типов для каждого корпуса. Произведите сравнение частотности по совпадающим сущностям при сопоставлении корпусов друг с другом.\n",
    "2. [0.4 балла] Найдите топ 10 (по частоте) частотных триггеров событий (на основе LitBank). Произведите анализ из пункта 1 для именованной сущности типа EVE (на основе MultiNERD_EN). \n",
    "3. [0.6 балла] Кластеризуйте все уникальные триггеры событий (LitBank), используя эмбеддинги слов и любой алгоритм кластеризации (например, аггломеративный иерархический алгоритм кластеризации) и попробуйте проинтерпретировать кластеры: есть ли очевидные типы событий? \n",
    "4. [0.6 балла] Отдельно произведите анализ из п. 3 для сущностей типа EVE (на основе MultiNERD_EN). Сравните результаты из п. 3 и п. 4.\n",
    "\n",
    "[бонус] Визуализируйте полученные кластеры с помощью TSNE или UMAP\n",
    "\n",
    "[бонус] Постройте тематическую модель по корпусу LitBank и сравните кластеры триггеров и выделенные темы: есть ли схожие паттерны в тематической модели и в структуре кластеров?\n",
    "\n",
    "В следующих частях домашнего задания вам понадобится train-test-dev разбиения. Авторы статей предлагают следующую структуру разбиения для корпуса LitBank: обучающее множество – 80 книг, валидационное – 10 книг, тестовое – 10 книг. Предложения из одного источника не должны попадать в разные сегменты разбиения.\n",
    "Для корпуса MultiNERD_EN произведите стратифицированное разбиение по предложениям в соотношении 80%:10%:10%. Стратификацию производить в отношении пропорции по именованным сущностям (понятно, что с учётом всех вводных идеального разбиения не получится, но старайтесь сохранить распределения по типам сущностей для каждой и подвыборок).\n",
    "\n",
    "\n",
    "## Часть 2. [3 балла] Извлечение именованных сущностей\n",
    "Для каждой корпуса необходимо осуществить раздельно следующую процедуру:\n",
    "1. [0.75 балла] Обучите стандартную модель для извлечения именованных сущностей, CNN-BiLSTM-CRF, для извлечения именованных *низкоуровневых именованных сущностей*, т.е. для самых коротких из вложенных сущностей. \n",
    "Модель устроена так: сверточная сеть на символах + эмбеддинги слов + двунаправленная LSTM сеть (модель последовательности) + CRF (глобальная нормализация).\n",
    "2. [0.75 балла] Замените часть модели на символах и словах (CNN + эмбеддинги словах) на ELMo и / или BERT. Должна получиться модель ELMo / BERT + BiLSTM + CRF. \n",
    "3. [1.5 балла] Замените модель последовательности (BiLSTM) на другой слой, например, на Transformer. Должна получиться модель CNN  + Transformer + CRF.\n",
    "В результате у вас будет 2 набора моделей - проверьте качество извлечения на тестовых данных.\n",
    "- Примените модели первого корпуса ко всем (!!!) предложениям второго корпуса и наоборот.\n",
    "- Составьте отчёт по качеству работы моделей в терминах извлечения по типам сущностей, которые встречаются в обоих корпусах. Метрику выберите самостоятельно.\n",
    "- Проанализируйте ошибки моделей в терминах предсказания сущностям первого корпуса специфических типов для второго корпуса. И наоборот - когда специфическим типам второго корпуса модель, обученная на LitBank, прсваивает одну из своих категорий.\n",
    "\n",
    "[бонус] Дообучите BERT для извлечения именованных сущностей.\n",
    "\n",
    "[бонус] Используйте модель для извлечения вложенных именованных сущностей [Ju et al., 2018]\n",
    "\n",
    "[бонус] Модифицируйте модель для извлечения вложенных именованных сущностей [Ju et al., 2018]: вместо эмбеддингов слов используйте ELMo и/или BERT. \n",
    "\n",
    "## Часть 3. [2 балла] Извлечение событий \n",
    "\n",
    "1. [0.75 балла] Используйте BiLSTM на эмбеддингах слов для извлечения триггеров событий (на основе LitBank). \n",
    "\n",
    "2. [0.75 балла] Замените часть модели на словах на ELMo и/или BERT. Должна получиться модель ELMo / BERT + BiLSTM.\n",
    "\n",
    "3. [0.5 балла] Проверьте \"извлекающую\" силу модели на данных MultiNERD_EN для событий типа EVE. \n",
    "\n",
    "[бонус] Предобучите BiLSTM как языковую модель. Дообучите ее для извлечения триггеров. \n",
    "\n",
    "[бонус] Дообучите BERT для извлечения триггеров событий. \n",
    "\n",
    "## Часть 4. [2 балла] Одновременное извлечение именованных сущностей и событий \n",
    "1. [0.75 балла] Обучите модель для совместного извлечения именованных сущностей и триггеров событий только на основе LitBank (!). У модели должен быть общий энкодер (например, CNN + BiLSMT, ELMo + BiLSTM, BERT + BiLSTM) и два декодера: один отвечает за извлечение именованных сущностей, другой отвечает за извлечение триггеров событий.\n",
    "\n",
    "2. [0.75 балла] Создайте единую обучающую подвыборку, единую валидационную и единую тестовую на основе разбиений, которые вы произвели в первой части и обучите модель. (Единую - то есть на основе обоих корпусов сразу)\n",
    "\n",
    "3. [0.5 балла] Сравните предсказательную силу модели из п.1 и модели из п.2 как на совместных подвыборках, так и на раздельных. Проанализируйте полученный результат. Приводит ли обогащение дополнительными данными к улучшению \"извлекающей\" способности модели?\n",
    "\n",
    "[бонус] Добавьте в модель механизм внимания, таким способом, который покажется вам разумным.\n",
    "\n",
    "[бонус] Визуализируйте карты механизма внимания (attention). \n",
    "\n",
    "## Часть 5. [1 балл] Итоги\n",
    "Напишите краткое резюме проделанной работы. Сравните результаты всех разработанных моделей. Что помогло вам в выполнении работы, чего не хватало?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:pink\">Авторы работы: Токкожин Арсен, Соколов Ян, Екимов Егор, Гвасалия Лукас</span>\n",
    "# Решение:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. [2 балла] Эксплоративный анализ \n",
    "1. [0.4 балла] Найдите топ 10 (по частоте) именованных сущностей каждого из типов для каждого корпуса. Произведите сравнение частотности по совпадающим сущностям при сопоставлении корпусов друг с другом.\n",
    "2. [0.4 балла] Найдите топ 10 (по частоте) частотных триггеров событий (на основе LitBank). Произведите анализ из пункта 1 для именованной сущности типа EVE (на основе MultiNERD_EN). \n",
    "3. [0.6 балла] Кластеризуйте все уникальные триггеры событий (LitBank), используя эмбеддинги слов и любой алгоритм кластеризации (например, аггломеративный иерархический алгоритм кластеризации) и попробуйте проинтерпретировать кластеры: есть ли очевидные типы событий? \n",
    "4. [0.6 балла] Отдельно произведите анализ из п. 3 для сущностей типа EVE (на основе MultiNERD_EN). Сравните результаты из п. 3 и п. 4.\n",
    "\n",
    "[бонус] Визуализируйте полученные кластеры с помощью TSNE или UMAP\n",
    "\n",
    "[бонус] Постройте тематическую модель по корпусу LitBank и сравните кластеры триггеров и выделенные темы: есть ли схожие паттерны в тематической модели и в структуре кластеров?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from brat_parser import get_entities_relations_attributes_groups\n",
    "from collections import Counter\n",
    "\n",
    "entities_folder_path = \"litbank_entities/brat\"\n",
    "events_folder_path = \"litbank_events/brat\"\n",
    "multinerd_path = \"multinerd_en.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Топ 10 именованных сущностей для корпуса Litbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = [\"PER\", \"FAC\", \"LOC\", \"ORG\", \"GPE\", \"VEH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_entities(path_to_folder, entities_names):\n",
    "    result = {}\n",
    "    for entity in entities_names:\n",
    "        result[entity] = Counter()\n",
    "\n",
    "    for filename in os.listdir(path_to_folder):\n",
    "        if filename.endswith(\".ann\"):\n",
    "            entities, relations, attributes, groups = get_entities_relations_attributes_groups(os.path.join(path_to_folder, filename))\n",
    "            for item in entities:\n",
    "                result[entities[item].type][entities[item].text] += 1 \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "PER\n",
      "('Mr.', 148)\n",
      "('Miss', 133)\n",
      "('Mrs.', 132)\n",
      "('sir', 50)\n",
      "('Sir', 45)\n",
      "('my mother', 40)\n",
      "('men', 40)\n",
      "('Cameron', 38)\n",
      "('his wife', 37)\n",
      "('Mr', 37)\n",
      "-------------------------------------\n",
      "FAC\n",
      "('home', 65)\n",
      "('the house', 52)\n",
      "('there', 39)\n",
      "('here', 39)\n",
      "('the room', 34)\n",
      "('the garden', 23)\n",
      "('the street', 14)\n",
      "('the hall', 13)\n",
      "('the road', 13)\n",
      "('the place', 12)\n",
      "-------------------------------------\n",
      "LOC\n",
      "('the world', 72)\n",
      "('the sea', 27)\n",
      "('the river', 22)\n",
      "('the country', 20)\n",
      "('there', 18)\n",
      "('the earth', 16)\n",
      "('sea', 16)\n",
      "('the valley', 13)\n",
      "('this world', 12)\n",
      "('the woods', 9)\n",
      "-------------------------------------\n",
      "ORG\n",
      "('the army', 7)\n",
      "('the Committee of Public Safety', 4)\n",
      "('the Colonial Office', 4)\n",
      "('the Church', 4)\n",
      "('Harvard', 3)\n",
      "('college', 3)\n",
      "('the hospital', 2)\n",
      "('the C.C.H.', 2)\n",
      "(\"the Bank of Leichardt 's Land\", 2)\n",
      "('a regiment of regulars', 2)\n",
      "-------------------------------------\n",
      "GPE\n",
      "('London', 40)\n",
      "('England', 32)\n",
      "('there', 21)\n",
      "('the town', 21)\n",
      "('New York', 16)\n",
      "('town', 14)\n",
      "('France', 14)\n",
      "('Europe', 12)\n",
      "('the country', 10)\n",
      "('Rome', 10)\n",
      "-------------------------------------\n",
      "VEH\n",
      "('the ship', 11)\n",
      "('the car', 9)\n",
      "('the train', 6)\n",
      "('boats', 4)\n",
      "('the boat', 4)\n",
      "('a carriage', 3)\n",
      "('the waggon', 3)\n",
      "('the carriage', 3)\n",
      "('the coach', 3)\n",
      "('the Fuwalda', 3)\n"
     ]
    }
   ],
   "source": [
    "entities_ans = count_entities(entities_folder_path, entities)\n",
    "for entity in entities_ans:\n",
    "    print(\"-------------------------------------\")\n",
    "    print(entity)\n",
    "    temp = entities_ans[entity].most_common()[:10]\n",
    "    for item in temp:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Топ 10 именованных сущностей для корпуса MultiNERD_EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "col_names = [\"Index\", \"Token\", \"Label\", \"BabelNet ID\", \"Wikidata ID\", \"Wikipedia ID\", \"Wikipedia Title\", \"Definition\", \"Image URL\", \"Smth\"]\n",
    "multinerd_data = pd.read_csv(multinerd_path, sep=\"\\t\", names=col_names, index_col=False , quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Token</th>\n",
       "      <th>Label</th>\n",
       "      <th>BabelNet ID</th>\n",
       "      <th>Wikidata ID</th>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th>Wikipedia Title</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Image URL</th>\n",
       "      <th>Smth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Created</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>by</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>James</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>bn:00786804n</td>\n",
       "      <td>Q42574</td>\n",
       "      <td>15622.0</td>\n",
       "      <td>James_Cameron</td>\n",
       "      <td>James Francis Cameron is a Canadian film direc...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Cameron</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index    Token  Label   BabelNet ID Wikidata ID  Wikipedia ID  \\\n",
       "0      0  Created      O           NaN         NaN           NaN   \n",
       "1      1       by      O           NaN         NaN           NaN   \n",
       "2      2    James  B-PER  bn:00786804n      Q42574       15622.0   \n",
       "3      3  Cameron  I-PER           NaN         NaN           NaN   \n",
       "4      4      and      O           NaN         NaN           NaN   \n",
       "\n",
       "  Wikipedia Title                                         Definition  \\\n",
       "0             NaN                                                NaN   \n",
       "1             NaN                                                NaN   \n",
       "2   James_Cameron  James Francis Cameron is a Canadian film direc...   \n",
       "3             NaN                                                NaN   \n",
       "4             NaN                                                NaN   \n",
       "\n",
       "                                           Image URL  Smth  \n",
       "0                                                NaN   NaN  \n",
       "1                                                NaN   NaN  \n",
       "2  https://upload.wikimedia.org/wikipedia/commons...   NaN  \n",
       "3                                                NaN   NaN  \n",
       "4                                                NaN   NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinerd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3568155\n",
      "3568155\n"
     ]
    }
   ],
   "source": [
    "print(multinerd_data[\"Smth\"].size)\n",
    "print(multinerd_data[\"Smth\"].isna().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "видим что последняя колонка полнстью состоит из пропусков, так что ее можно удалить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinerd_data=multinerd_data.drop([\"Smth\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Token</th>\n",
       "      <th>Label</th>\n",
       "      <th>BabelNet ID</th>\n",
       "      <th>Wikidata ID</th>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th>Wikipedia Title</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Created</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>by</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>James</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>bn:00786804n</td>\n",
       "      <td>Q42574</td>\n",
       "      <td>15622.0</td>\n",
       "      <td>James_Cameron</td>\n",
       "      <td>James Francis Cameron is a Canadian film direc...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Cameron</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index    Token  Label   BabelNet ID Wikidata ID  Wikipedia ID  \\\n",
       "0      0  Created      O           NaN         NaN           NaN   \n",
       "1      1       by      O           NaN         NaN           NaN   \n",
       "2      2    James  B-PER  bn:00786804n      Q42574       15622.0   \n",
       "3      3  Cameron  I-PER           NaN         NaN           NaN   \n",
       "4      4      and      O           NaN         NaN           NaN   \n",
       "\n",
       "  Wikipedia Title                                         Definition  \\\n",
       "0             NaN                                                NaN   \n",
       "1             NaN                                                NaN   \n",
       "2   James_Cameron  James Francis Cameron is a Canadian film direc...   \n",
       "3             NaN                                                NaN   \n",
       "4             NaN                                                NaN   \n",
       "\n",
       "                                           Image URL  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2  https://upload.wikimedia.org/wikipedia/commons...  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinerd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinerd_data.loc[multinerd_data['Label'] != 'O', 'Label'] = multinerd_data.loc[multinerd_data['Label'] != 'O', 'Label'].str[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Token</th>\n",
       "      <th>Label</th>\n",
       "      <th>BabelNet ID</th>\n",
       "      <th>Wikidata ID</th>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th>Wikipedia Title</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Created</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>by</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>James</td>\n",
       "      <td>PER</td>\n",
       "      <td>bn:00786804n</td>\n",
       "      <td>Q42574</td>\n",
       "      <td>15622.0</td>\n",
       "      <td>James_Cameron</td>\n",
       "      <td>James Francis Cameron is a Canadian film direc...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Cameron</td>\n",
       "      <td>PER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Charles</td>\n",
       "      <td>PER</td>\n",
       "      <td>bn:02320763n</td>\n",
       "      <td>Q3666404</td>\n",
       "      <td>2956611.0</td>\n",
       "      <td>Charles_H._Eglee</td>\n",
       "      <td>Charles Hamilton Eglee is an American film and...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>H.</td>\n",
       "      <td>PER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Eglee</td>\n",
       "      <td>PER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>it</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index    Token Label   BabelNet ID Wikidata ID  Wikipedia ID  \\\n",
       "0      0  Created     O           NaN         NaN           NaN   \n",
       "1      1       by     O           NaN         NaN           NaN   \n",
       "2      2    James   PER  bn:00786804n      Q42574       15622.0   \n",
       "3      3  Cameron   PER           NaN         NaN           NaN   \n",
       "4      4      and     O           NaN         NaN           NaN   \n",
       "5      5  Charles   PER  bn:02320763n    Q3666404     2956611.0   \n",
       "6      6       H.   PER           NaN         NaN           NaN   \n",
       "7      7    Eglee   PER           NaN         NaN           NaN   \n",
       "8      8        ,     O           NaN         NaN           NaN   \n",
       "9      9       it     O           NaN         NaN           NaN   \n",
       "\n",
       "    Wikipedia Title                                         Definition  \\\n",
       "0               NaN                                                NaN   \n",
       "1               NaN                                                NaN   \n",
       "2     James_Cameron  James Francis Cameron is a Canadian film direc...   \n",
       "3               NaN                                                NaN   \n",
       "4               NaN                                                NaN   \n",
       "5  Charles_H._Eglee  Charles Hamilton Eglee is an American film and...   \n",
       "6               NaN                                                NaN   \n",
       "7               NaN                                                NaN   \n",
       "8               NaN                                                NaN   \n",
       "9               NaN                                                NaN   \n",
       "\n",
       "                                           Image URL  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2  https://upload.wikimedia.org/wikipedia/commons...  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5  https://upload.wikimedia.org/wikipedia/commons...  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinerd_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'O': 3111887,\n",
       "         'PER': 155669,\n",
       "         'LOC': 112519,\n",
       "         'MEDIA': 19673,\n",
       "         'TIME': 5584,\n",
       "         'EVE': 8525,\n",
       "         'ORG': 78179,\n",
       "         'PLANT': 12674,\n",
       "         'ANIM': 22284,\n",
       "         'FOOD': 15006,\n",
       "         'DIS': 18713,\n",
       "         'CEL': 4341,\n",
       "         'SUPER': 774,\n",
       "         'VEHI': 1114,\n",
       "         'INST': 822,\n",
       "         'PHY': 190,\n",
       "         'BIO': 201})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = list(multinerd_data[\"Label\"])\n",
    "cnt = Counter()\n",
    "for label in all_labels:\n",
    "    cnt[label] += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinerd_entities_names = cnt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = multinerd_data.groupby(['Label', 'Token'])[['Index']].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    \"Index\":\"Amount\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "O\n",
      "Token  Amount\n",
      "    ,  194114\n",
      "  the  169553\n",
      "    .  164196\n",
      "   of   94883\n",
      "  and   90076\n",
      "   in   83052\n",
      "    \"   72596\n",
      "    a   65926\n",
      "   to   58243\n",
      "   is   40965\n",
      "-------------------------------------\n",
      "PER\n",
      "  Token  Amount\n",
      "   John    2097\n",
      " George    1114\n",
      "  David    1026\n",
      "William     911\n",
      "  James     879\n",
      "Michael     824\n",
      " Robert     794\n",
      "   Paul     745\n",
      "Charles     691\n",
      "Richard     660\n",
      "-------------------------------------\n",
      "LOC\n",
      "    Token  Amount\n",
      "   United    2357\n",
      "      New    2030\n",
      "   States    1604\n",
      "    South    1568\n",
      "Australia    1103\n",
      "  America    1035\n",
      "       of     999\n",
      "    North     998\n",
      "   Africa     943\n",
      "    River     919\n",
      "-------------------------------------\n",
      "MEDIA\n",
      "   Token  Amount\n",
      "Tomatoes    1466\n",
      "  Rotten    1466\n",
      "     The     954\n",
      "      of     498\n",
      "     the     452\n",
      "      's     168\n",
      "       :     131\n",
      "     You     119\n",
      "     and     108\n",
      "    Show     107\n",
      "-------------------------------------\n",
      "TIME\n",
      "      Token  Amount\n",
      "        Day     222\n",
      "        Age     214\n",
      "     Middle     214\n",
      "       Ages     199\n",
      "      Great     160\n",
      " Depression     159\n",
      "Renaissance     134\n",
      "         of     121\n",
      "  Christmas      90\n",
      "     Bronze      89\n",
      "-------------------------------------\n",
      "EVE\n",
      "     Token  Amount\n",
      "       War    1340\n",
      "     World     826\n",
      "        II     398\n",
      "     Civil     281\n",
      "       Cup     276\n",
      "  American     196\n",
      "Revolution     192\n",
      "  Festival     183\n",
      "    League     179\n",
      "      Film     157\n",
      "-------------------------------------\n",
      "ORG\n",
      "     Token  Amount\n",
      "University    3189\n",
      "        of    3185\n",
      "    United     976\n",
      "     Party     818\n",
      "      City     703\n",
      "       New     662\n",
      "        FC     620\n",
      "  National     574\n",
      "      Town     538\n",
      "     Union     492\n",
      "-------------------------------------\n",
      "PLANT\n",
      "    Token  Amount\n",
      "    plant     414\n",
      "     rice     158\n",
      "      oak     140\n",
      "    wheat     120\n",
      "   pepper     120\n",
      "    shrub     114\n",
      "deciduous     112\n",
      "        \"     111\n",
      "     tree     106\n",
      "     pine     103\n",
      "-------------------------------------\n",
      "ANIM\n",
      "    Token  Amount\n",
      "     moth     993\n",
      "      sea     340\n",
      "    snail     274\n",
      "     fish     225\n",
      "     deer     204\n",
      "    trout     200\n",
      " Erebidae     181\n",
      "Noctuidae     158\n",
      "     mine     147\n",
      "    black     138\n",
      "-------------------------------------\n",
      "FOOD\n",
      "  Token  Amount\n",
      "  sugar     281\n",
      "    oil     266\n",
      "  cream     208\n",
      "  sauce     206\n",
      "   milk     188\n",
      "   salt     167\n",
      "  flour     157\n",
      "vitamin     157\n",
      "   food     156\n",
      "   meat     138\n",
      "-------------------------------------\n",
      "DIS\n",
      "       Token  Amount\n",
      "     disease     598\n",
      "      cancer     493\n",
      "    disorder     421\n",
      "          's     351\n",
      "    syndrome     347\n",
      "     anxiety     174\n",
      "     failure     128\n",
      "       heart     124\n",
      "tuberculosis     112\n",
      "   Alzheimer     110\n",
      "-------------------------------------\n",
      "CEL\n",
      "   Token  Amount\n",
      "   Earth     263\n",
      "    star     190\n",
      "     Sun     137\n",
      " Jupiter      97\n",
      "   giant      82\n",
      "asteroid      81\n",
      "    Moon      77\n",
      "    Mars      76\n",
      "   Milky      73\n",
      "     Way      73\n",
      "-------------------------------------\n",
      "SUPER\n",
      "    Token  Amount\n",
      "   Thomas      27\n",
      "  Aquinas      24\n",
      "     Zeus      22\n",
      "    Satan      15\n",
      "       Ra      14\n",
      "     John      14\n",
      "   Apollo      13\n",
      "Aphrodite      13\n",
      "      the      13\n",
      "  Baptist      11\n",
      "-------------------------------------\n",
      "VEHI\n",
      "   Token  Amount\n",
      "   Class      16\n",
      "  Toyota      14\n",
      "  Airbus      13\n",
      "  Boeing      12\n",
      "       2      11\n",
      "      He      11\n",
      "      Do      10\n",
      " Tupolev      10\n",
      "    Dash       9\n",
      "Lockheed       9\n",
      "-------------------------------------\n",
      "INST\n",
      "    Token  Amount\n",
      "  Voyager      24\n",
      "  Android      22\n",
      "        1      18\n",
      "LaserDisc      17\n",
      "    Apple      16\n",
      "        2      15\n",
      " Nintendo      14\n",
      "    Super      12\n",
      "   System      10\n",
      "Laserdisc      10\n",
      "-------------------------------------\n",
      "PHY\n",
      "     Token  Amount\n",
      "   Current      26\n",
      "earthquake      17\n",
      "   tsunami      12\n",
      "       and      11\n",
      "  disaster       9\n",
      "    Indian       6\n",
      "      2004       6\n",
      "    Tōhoku       5\n",
      "     Ocean       5\n",
      "      2011       5\n",
      "-------------------------------------\n",
      "BIO\n",
      "        Token  Amount\n",
      "         coli      29\n",
      "  Escherichia      16\n",
      "           E.      13\n",
      "   Plasmodium      10\n",
      "          HIV       7\n",
      "  Pseudomonas       6\n",
      "  Aspergillus       6\n",
      "   Salmonella       5\n",
      "Streptococcus       5\n",
      "Agrobacterium       4\n"
     ]
    }
   ],
   "source": [
    "multinerd_entities = {}\n",
    "for entity in multinerd_entities_names:\n",
    "    print(\"-------------------------------------\")\n",
    "    print(entity)\n",
    "    temp = df[df[\"Label\"] == entity].sort_values([\"Amount\"], ascending=False)\n",
    "    print(temp[[\"Token\",\"Amount\"]].head(10).to_string(index=False))\n",
    "    multinerd_entities[entity] = list(temp[\"Token\"].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': [',', 'the', '.', 'of', 'and', 'in', '\"', 'a', 'to', 'is'],\n",
       " 'PER': ['John',\n",
       "  'George',\n",
       "  'David',\n",
       "  'William',\n",
       "  'James',\n",
       "  'Michael',\n",
       "  'Robert',\n",
       "  'Paul',\n",
       "  'Charles',\n",
       "  'Richard'],\n",
       " 'LOC': ['United',\n",
       "  'New',\n",
       "  'States',\n",
       "  'South',\n",
       "  'Australia',\n",
       "  'America',\n",
       "  'of',\n",
       "  'North',\n",
       "  'Africa',\n",
       "  'River'],\n",
       " 'MEDIA': ['Tomatoes',\n",
       "  'Rotten',\n",
       "  'The',\n",
       "  'of',\n",
       "  'the',\n",
       "  \"'s\",\n",
       "  ':',\n",
       "  'You',\n",
       "  'and',\n",
       "  'Show'],\n",
       " 'TIME': ['Day',\n",
       "  'Age',\n",
       "  'Middle',\n",
       "  'Ages',\n",
       "  'Great',\n",
       "  'Depression',\n",
       "  'Renaissance',\n",
       "  'of',\n",
       "  'Christmas',\n",
       "  'Bronze'],\n",
       " 'EVE': ['War',\n",
       "  'World',\n",
       "  'II',\n",
       "  'Civil',\n",
       "  'Cup',\n",
       "  'American',\n",
       "  'Revolution',\n",
       "  'Festival',\n",
       "  'League',\n",
       "  'Film'],\n",
       " 'ORG': ['University',\n",
       "  'of',\n",
       "  'United',\n",
       "  'Party',\n",
       "  'City',\n",
       "  'New',\n",
       "  'FC',\n",
       "  'National',\n",
       "  'Town',\n",
       "  'Union'],\n",
       " 'PLANT': ['plant',\n",
       "  'rice',\n",
       "  'oak',\n",
       "  'wheat',\n",
       "  'pepper',\n",
       "  'shrub',\n",
       "  'deciduous',\n",
       "  '\"',\n",
       "  'tree',\n",
       "  'pine'],\n",
       " 'ANIM': ['moth',\n",
       "  'sea',\n",
       "  'snail',\n",
       "  'fish',\n",
       "  'deer',\n",
       "  'trout',\n",
       "  'Erebidae',\n",
       "  'Noctuidae',\n",
       "  'mine',\n",
       "  'black'],\n",
       " 'FOOD': ['sugar',\n",
       "  'oil',\n",
       "  'cream',\n",
       "  'sauce',\n",
       "  'milk',\n",
       "  'salt',\n",
       "  'flour',\n",
       "  'vitamin',\n",
       "  'food',\n",
       "  'meat'],\n",
       " 'DIS': ['disease',\n",
       "  'cancer',\n",
       "  'disorder',\n",
       "  \"'s\",\n",
       "  'syndrome',\n",
       "  'anxiety',\n",
       "  'failure',\n",
       "  'heart',\n",
       "  'tuberculosis',\n",
       "  'Alzheimer'],\n",
       " 'CEL': ['Earth',\n",
       "  'star',\n",
       "  'Sun',\n",
       "  'Jupiter',\n",
       "  'giant',\n",
       "  'asteroid',\n",
       "  'Moon',\n",
       "  'Mars',\n",
       "  'Milky',\n",
       "  'Way'],\n",
       " 'SUPER': ['Thomas',\n",
       "  'Aquinas',\n",
       "  'Zeus',\n",
       "  'Satan',\n",
       "  'Ra',\n",
       "  'John',\n",
       "  'Apollo',\n",
       "  'Aphrodite',\n",
       "  'the',\n",
       "  'Baptist'],\n",
       " 'VEHI': ['Class',\n",
       "  'Toyota',\n",
       "  'Airbus',\n",
       "  'Boeing',\n",
       "  '2',\n",
       "  'He',\n",
       "  'Do',\n",
       "  'Tupolev',\n",
       "  'Dash',\n",
       "  'Lockheed'],\n",
       " 'INST': ['Voyager',\n",
       "  'Android',\n",
       "  '1',\n",
       "  'LaserDisc',\n",
       "  'Apple',\n",
       "  '2',\n",
       "  'Nintendo',\n",
       "  'Super',\n",
       "  'System',\n",
       "  'Laserdisc'],\n",
       " 'PHY': ['Current',\n",
       "  'earthquake',\n",
       "  'tsunami',\n",
       "  'and',\n",
       "  'disaster',\n",
       "  'Indian',\n",
       "  '2004',\n",
       "  'Tōhoku',\n",
       "  'Ocean',\n",
       "  '2011'],\n",
       " 'BIO': ['coli',\n",
       "  'Escherichia',\n",
       "  'E.',\n",
       "  'Plasmodium',\n",
       "  'HIV',\n",
       "  'Pseudomonas',\n",
       "  'Aspergillus',\n",
       "  'Salmonella',\n",
       "  'Streptococcus',\n",
       "  'Agrobacterium']}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinerd_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "litbank_entities = {}\n",
    "for entity in entities_ans:\n",
    "    temp = entities_ans[entity].most_common()[:10]\n",
    "    litbank_entities[entity] = list()\n",
    "    for item in temp:\n",
    "        litbank_entities[entity].append(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PER': ['Mr.',\n",
       "  'Miss',\n",
       "  'Mrs.',\n",
       "  'sir',\n",
       "  'Sir',\n",
       "  'my mother',\n",
       "  'men',\n",
       "  'Cameron',\n",
       "  'his wife',\n",
       "  'Mr'],\n",
       " 'FAC': ['home',\n",
       "  'the house',\n",
       "  'there',\n",
       "  'here',\n",
       "  'the room',\n",
       "  'the garden',\n",
       "  'the street',\n",
       "  'the hall',\n",
       "  'the road',\n",
       "  'the place'],\n",
       " 'LOC': ['the world',\n",
       "  'the sea',\n",
       "  'the river',\n",
       "  'the country',\n",
       "  'there',\n",
       "  'the earth',\n",
       "  'sea',\n",
       "  'the valley',\n",
       "  'this world',\n",
       "  'the woods'],\n",
       " 'ORG': ['the army',\n",
       "  'the Committee of Public Safety',\n",
       "  'the Colonial Office',\n",
       "  'the Church',\n",
       "  'Harvard',\n",
       "  'college',\n",
       "  'the hospital',\n",
       "  'the C.C.H.',\n",
       "  \"the Bank of Leichardt 's Land\",\n",
       "  'a regiment of regulars'],\n",
       " 'GPE': ['London',\n",
       "  'England',\n",
       "  'there',\n",
       "  'the town',\n",
       "  'New York',\n",
       "  'town',\n",
       "  'France',\n",
       "  'Europe',\n",
       "  'the country',\n",
       "  'Rome'],\n",
       " 'VEH': ['the ship',\n",
       "  'the car',\n",
       "  'the train',\n",
       "  'boats',\n",
       "  'the boat',\n",
       "  'a carriage',\n",
       "  'the waggon',\n",
       "  'the carriage',\n",
       "  'the coach',\n",
       "  'the Fuwalda']}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "litbank_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "PER\n",
      "Litbank:\n",
      "['Mr.', 'Miss', 'Mrs.', 'sir', 'Sir', 'my mother', 'men', 'Cameron', 'his wife', 'Mr']\n",
      "Multinerd:\n",
      "['John', 'George', 'David', 'William', 'James', 'Michael', 'Robert', 'Paul', 'Charles', 'Richard']\n",
      "----------------------------\n",
      "LOC\n",
      "Litbank:\n",
      "['the world', 'the sea', 'the river', 'the country', 'there', 'the earth', 'sea', 'the valley', 'this world', 'the woods']\n",
      "Multinerd:\n",
      "['United', 'New', 'States', 'South', 'Australia', 'America', 'of', 'North', 'Africa', 'River']\n",
      "----------------------------\n",
      "ORG\n",
      "Litbank:\n",
      "['the army', 'the Committee of Public Safety', 'the Colonial Office', 'the Church', 'Harvard', 'college', 'the hospital', 'the C.C.H.', \"the Bank of Leichardt 's Land\", 'a regiment of regulars']\n",
      "Multinerd:\n",
      "['University', 'of', 'United', 'Party', 'City', 'New', 'FC', 'National', 'Town', 'Union']\n"
     ]
    }
   ],
   "source": [
    "for entity in list(set(litbank_entities) & set(multinerd_entities)):\n",
    "    print(\"----------------------------\")\n",
    "    print(entity)\n",
    "    print(\"Litbank:\")\n",
    "    print(litbank_entities[entity])\n",
    "    print(\"Multinerd:\")\n",
    "    print(multinerd_entities[entity])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение: одинаковые сущности в разных датасетах трактуются по-разному. Видим что в датасете multinerd большую популярность среди сущностей персон(PER) и локаций(LOC) имеют имена собственные, нежели в датасете litbank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Топ 10 частотных триггеров событий для корпуса Litbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_events(path_to_folder):\n",
    "    cnt = Counter()\n",
    "\n",
    "    for filename in os.listdir(path_to_folder):\n",
    "        if filename.endswith(\".ann\"):\n",
    "            entities, relations, attributes, groups = get_entities_relations_attributes_groups(os.path.join(path_to_folder, filename))\n",
    "            for item in entities:\n",
    "                cnt[entities[item].text] += 1 \n",
    "\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 464),\n",
       " ('came', 95),\n",
       " ('looked', 92),\n",
       " ('went', 92),\n",
       " ('asked', 69),\n",
       " ('heard', 63),\n",
       " ('cried', 59),\n",
       " ('saw', 59),\n",
       " ('took', 56),\n",
       " ('turned', 55)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "litbank_events = count_events(events_folder_path).most_common()[:10]\n",
    "litbank_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['War',\n",
       " 'World',\n",
       " 'II',\n",
       " 'Civil',\n",
       " 'Cup',\n",
       " 'American',\n",
       " 'Revolution',\n",
       " 'Festival',\n",
       " 'League',\n",
       " 'Film']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinerd_entities[\"EVE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравневние: видим что тут тоже по-разному трактуется понятие event. В litbank это больше определяется по совершенному общему действию, а в multinerd это больше похоже на какое-то конкретное событие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
