{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 3\n",
    "## Yes/No Questions\n",
    "\n",
    "deadline: 4 декабря 2022, 23:59 МСК\n",
    "\n",
    "В этом домашнем задании вы будете работать с корпусом DaNetQA. Корпус состоит из вопросов, предполагающих бинарный ответ (да / нет), абзацев из Википедии, содержащих ответ на вопрос, и непосредственно ответа (true / false).\n",
    "\n",
    "Корпус описан в статье:\n",
    "\n",
    "Glushkova, T., Machnev, A., Fenogenova, A., Shavrina, T., Artemova, E., & Ignatov, D. I. (2020, October). Danetqa: a yes/no question answering dataset for the russian language. In International Conference on Analysis of Images, Social Networks and Texts (pp. 57-68). Springer, Cham.\n",
    "\n",
    "https://arxiv.org/abs/2010.02605\n",
    "\n",
    "\n",
    "Корпус (train-val-test split) доступен по ссылке: https://russiansuperglue.com/ru/tasks/task_info/DaNetQA\n",
    "\n",
    "Используйте для обучения train часть корпуса, для валидации val и тестирования – test часть. \n",
    "\n",
    "Каждый бонус пункт оценивается в 1 балл. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример вопроса: \n",
    "question: Был ли человек на луне?\n",
    "\n",
    "label (answer): true\n",
    "\n",
    "text (passage): В период с 1969 по 1972 год по программе «Аполлон» было выполнено 6 полётов с посадкой на Луне. Всего на Луне высаживались 12 астронавтов США. Список космонавтов Список космонавтов — участников орбитальных космических полётов Список астронавтов США — участников орбитальных космических полётов Список космонавтов СССР и России — участников космических полётов Список женщин-космонавтов Список космонавтов, посещавших МКС Энциклопедия астронавтики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ПРАВИЛА\n",
    "1. Домашнее задание выполняется в группе до 4-х человек.\n",
    "2. Домашнее задание оформляется в виде отчета либо в .pdf файле, либо в ipython-тетрадке. При этом ipynb-файл прилагается обязательно. \n",
    "3. Отчет должен содержать: нумерацию заданий и пунктов, которые вы выполнили, код решения, и понятное пошаговое описание того, что вы сделали. Отчет должен быть написан в академическом стиле, без излишнего использования сленга и с соблюдением норм русского языка.\n",
    "4. Не стоит копировать фрагменты лекций, статей и Википедии в ваш отчет.\n",
    "5. Отчеты, состоящие исключительно из кода, не будут проверены и будут автоматически оценены нулевой оценкой.\n",
    "6. Плагиат и любое недобросовестное цитирование приводит к обнулению оценки. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. [1 балл] Эксплоративный анализ\n",
    "1. Посчитайте долю yes и no классов в корпусе.\n",
    "2. Оцените среднюю длину вопроса.\n",
    "3. Оцените среднюю длину параграфа.\n",
    "4. Предположите, по каким эвристикам были собраны вопросы. Продемонстрируйте, как эти эвристики повлияли на структуру корпуса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/train.jsonl\"\n",
    "val_path = \"data/val.jsonl\"\n",
    "test_path = \"data/test.jsonl\"\n",
    "\n",
    "def read_data(path_data):\n",
    "    with open(path_data, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        data = []\n",
    "        for line in lines:\n",
    "            data.append(json.loads(line))\n",
    "        return data\n",
    "\n",
    "train_data = read_data(train_path)\n",
    "val_data = read_data(val_path)\n",
    "test_data = read_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1749\n",
      "821\n",
      "805\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame.from_records(train_data)\n",
    "df_val = pd.DataFrame.from_records(val_data)\n",
    "df_test = pd.DataFrame.from_records(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вднх - это выставочный центр?</td>\n",
       "      <td>«Вы́ставочный центр» — станция Московского мон...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Вднх - это выставочный центр?</td>\n",
       "      <td>Вы́ставка достиже́ний наро́дного хозя́йства  ,...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Был ли джиган в black star?</td>\n",
       "      <td>Вместе с этим треком они выступили на церемони...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xiaomi конкурент apple?</td>\n",
       "      <td>Xiaomi — китайская компания, основанная в 2010...</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Был ли автомат калашникова в вов?</td>\n",
       "      <td>Отметив некоторые недостатки и в целом удачную...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question  \\\n",
       "0      Вднх - это выставочный центр?   \n",
       "1      Вднх - это выставочный центр?   \n",
       "2        Был ли джиган в black star?   \n",
       "3            Xiaomi конкурент apple?   \n",
       "4  Был ли автомат калашникова в вов?   \n",
       "\n",
       "                                             passage  label  idx  \n",
       "0  «Вы́ставочный центр» — станция Московского мон...   True    0  \n",
       "1  Вы́ставка достиже́ний наро́дного хозя́йства  ,...   True    1  \n",
       "2  Вместе с этим треком они выступили на церемони...   True    2  \n",
       "3  Xiaomi — китайская компания, основанная в 2010...   True    3  \n",
       "4  Отметив некоторые недостатки и в целом удачную...  False    4  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1061\n",
       "False     688\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"label\"] = df_train[\"label\"].astype(int)\n",
    "df_train = df_train.drop([\"idx\"], axis=1)\n",
    "df_val[\"label\"] = df_val[\"label\"].astype(int)\n",
    "df_val = df_val.drop([\"idx\"], axis=1)\n",
    "df_test = df_test.drop([\"idx\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вднх - это выставочный центр?</td>\n",
       "      <td>«Вы́ставочный центр» — станция Московского мон...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Вднх - это выставочный центр?</td>\n",
       "      <td>Вы́ставка достиже́ний наро́дного хозя́йства  ,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Был ли джиган в black star?</td>\n",
       "      <td>Вместе с этим треком они выступили на церемони...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xiaomi конкурент apple?</td>\n",
       "      <td>Xiaomi — китайская компания, основанная в 2010...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Был ли автомат калашникова в вов?</td>\n",
       "      <td>Отметив некоторые недостатки и в целом удачную...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question  \\\n",
       "0      Вднх - это выставочный центр?   \n",
       "1      Вднх - это выставочный центр?   \n",
       "2        Был ли джиган в black star?   \n",
       "3            Xiaomi конкурент apple?   \n",
       "4  Был ли автомат калашникова в вов?   \n",
       "\n",
       "                                             passage  label  \n",
       "0  «Вы́ставочный центр» — станция Московского мон...      1  \n",
       "1  Вы́ставка достиже́ний наро́дного хозя́йства  ,...      1  \n",
       "2  Вместе с этим треком они выступили на церемони...      1  \n",
       "3  Xiaomi — китайская компания, основанная в 2010...      1  \n",
       "4  Отметив некоторые недостатки и в целом удачную...      0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean len for passages: 723.1149228130361\n",
      "mean len for questions: 41.63064608347627\n"
     ]
    }
   ],
   "source": [
    "print(f'mean len for passages: {df_train[\"passage\"].apply(len).mean()}')\n",
    "print(f'mean len for questions: {df_train[\"question\"].apply(len).mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вднх - это выставочный центр?</td>\n",
       "      <td>«Вы́ставочный центр» — станция Московского мон...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Вднх - это выставочный центр?</td>\n",
       "      <td>Вы́ставка достиже́ний наро́дного хозя́йства  ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Был ли джиган в black star?</td>\n",
       "      <td>Вместе с этим треком они выступили на церемони...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xiaomi конкурент apple?</td>\n",
       "      <td>Xiaomi — китайская компания, основанная в 2010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Был ли автомат калашникова в вов?</td>\n",
       "      <td>Отметив некоторые недостатки и в целом удачную...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Может ли автомобиль ездить на газу?</td>\n",
       "      <td>Автомобиль на природном газе — один из видов а...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Может ли автомобиль ездить на газу?</td>\n",
       "      <td>Для работы на газообразных топливах транспортн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Был ли автомобиль принцессы дианы в дтп?</td>\n",
       "      <td>Несмотря на продолжительные реанимационные поп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Есть ли в индийском океане акулы?</td>\n",
       "      <td>Обыкновенная акула-молот, или молот-рыба  — од...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Есть ли в индийском океане акулы?</td>\n",
       "      <td>Ри́фовая аку́ла  — единственный вид рода рифов...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Вреден ли алкоголь на первых неделях беременно...</td>\n",
       "      <td>А Бакингем-Хоуз и её коллеги суммировали после...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Бывает ли аллергия на алкоголь?</td>\n",
       "      <td>Врождённая непереносимость алкоголя, покраснен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Бывает ли аллергия на алкоголь?</td>\n",
       "      <td>Лица, имеющие врождённую непереносимость алког...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Был ли ссср участником бернской конвенции?</td>\n",
       "      <td>Бе́рнская конве́нция по охра́не литерату́рных ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Был ли ссср участником бернской конвенции?</td>\n",
       "      <td>Российская империя планировала присоединиться ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Был ли ленинград в блокаде?</td>\n",
       "      <td>В этой статье описывается хронология событий п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Правда ли что слоны боятся мышей?</td>\n",
       "      <td>Слоновые хорошо слышат в области низких частот...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Есть ли свидетельства о браке в сша?</td>\n",
       "      <td>Свидетельство о заключении брака — официальный...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Были ли у иисуса братья?</td>\n",
       "      <td>Эту Марию видим в первый раз при распятии, зат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Были ли у сулеймана братья?</td>\n",
       "      <td>Ещё одной из причин отступления Ахмеда от прав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Были ли у сулеймана братья?</td>\n",
       "      <td>Шехзаде́ Сулейма́н  — сын османского султана А...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Был ли бриллиант на титанике?</td>\n",
       "      <td>5 апреля 2012 года, в год 100-летия легендарно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Был ли бунин в эмиграции?</td>\n",
       "      <td>«Тёмные алле́и» — сборник рассказов о любви И....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Был на зоне бунт?</td>\n",
       "      <td>Бунт заключённых в следственном изоляторе горо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Был на зоне бунт в 1990 году?</td>\n",
       "      <td>Восстание в тюрьме Спач  — восстание заключённ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Был ли бурито в группе бандерос?</td>\n",
       "      <td>Игорь Юрьевич Бурнышев  — российский автор-исп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Были ли у андрея болконского прототип?</td>\n",
       "      <td>I, 1, III. Не имеет ярко выраженных прототипов...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Были ли у андрея болконского прототип?</td>\n",
       "      <td>Андре́й Никола́евич Болко́нский  — один из цен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Были ли гладиаторы в древней италии?</td>\n",
       "      <td>Гладиа́тор  — боец в Древнем Риме, который сра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Были ли гладиаторы в древней италии?</td>\n",
       "      <td>Спарта́к  — руководитель восстания рабов и гла...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0                       Вднх - это выставочный центр?   \n",
       "1                       Вднх - это выставочный центр?   \n",
       "2                         Был ли джиган в black star?   \n",
       "3                             Xiaomi конкурент apple?   \n",
       "4                   Был ли автомат калашникова в вов?   \n",
       "5                 Может ли автомобиль ездить на газу?   \n",
       "6                 Может ли автомобиль ездить на газу?   \n",
       "7            Был ли автомобиль принцессы дианы в дтп?   \n",
       "8                   Есть ли в индийском океане акулы?   \n",
       "9                   Есть ли в индийском океане акулы?   \n",
       "10  Вреден ли алкоголь на первых неделях беременно...   \n",
       "11                    Бывает ли аллергия на алкоголь?   \n",
       "12                    Бывает ли аллергия на алкоголь?   \n",
       "13         Был ли ссср участником бернской конвенции?   \n",
       "14         Был ли ссср участником бернской конвенции?   \n",
       "15                        Был ли ленинград в блокаде?   \n",
       "16                  Правда ли что слоны боятся мышей?   \n",
       "17               Есть ли свидетельства о браке в сша?   \n",
       "18                           Были ли у иисуса братья?   \n",
       "19                        Были ли у сулеймана братья?   \n",
       "20                        Были ли у сулеймана братья?   \n",
       "21                      Был ли бриллиант на титанике?   \n",
       "22                          Был ли бунин в эмиграции?   \n",
       "23                                  Был на зоне бунт?   \n",
       "24                      Был на зоне бунт в 1990 году?   \n",
       "25                   Был ли бурито в группе бандерос?   \n",
       "26             Были ли у андрея болконского прототип?   \n",
       "27             Были ли у андрея болконского прототип?   \n",
       "28               Были ли гладиаторы в древней италии?   \n",
       "29               Были ли гладиаторы в древней италии?   \n",
       "\n",
       "                                              passage  \n",
       "0   «Вы́ставочный центр» — станция Московского мон...  \n",
       "1   Вы́ставка достиже́ний наро́дного хозя́йства  ,...  \n",
       "2   Вместе с этим треком они выступили на церемони...  \n",
       "3   Xiaomi — китайская компания, основанная в 2010...  \n",
       "4   Отметив некоторые недостатки и в целом удачную...  \n",
       "5   Автомобиль на природном газе — один из видов а...  \n",
       "6   Для работы на газообразных топливах транспортн...  \n",
       "7   Несмотря на продолжительные реанимационные поп...  \n",
       "8   Обыкновенная акула-молот, или молот-рыба  — од...  \n",
       "9   Ри́фовая аку́ла  — единственный вид рода рифов...  \n",
       "10  А Бакингем-Хоуз и её коллеги суммировали после...  \n",
       "11  Врождённая непереносимость алкоголя, покраснен...  \n",
       "12  Лица, имеющие врождённую непереносимость алког...  \n",
       "13  Бе́рнская конве́нция по охра́не литерату́рных ...  \n",
       "14  Российская империя планировала присоединиться ...  \n",
       "15  В этой статье описывается хронология событий п...  \n",
       "16  Слоновые хорошо слышат в области низких частот...  \n",
       "17  Свидетельство о заключении брака — официальный...  \n",
       "18  Эту Марию видим в первый раз при распятии, зат...  \n",
       "19  Ещё одной из причин отступления Ахмеда от прав...  \n",
       "20  Шехзаде́ Сулейма́н  — сын османского султана А...  \n",
       "21  5 апреля 2012 года, в год 100-летия легендарно...  \n",
       "22  «Тёмные алле́и» — сборник рассказов о любви И....  \n",
       "23  Бунт заключённых в следственном изоляторе горо...  \n",
       "24  Восстание в тюрьме Спач  — восстание заключённ...  \n",
       "25  Игорь Юрьевич Бурнышев  — российский автор-исп...  \n",
       "26  I, 1, III. Не имеет ярко выраженных прототипов...  \n",
       "27  Андре́й Никола́евич Болко́нский  — один из цен...  \n",
       "28  Гладиа́тор  — боец в Древнем Риме, который сра...  \n",
       "29  Спарта́к  — руководитель восстания рабов и гла...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[[\"question\", \"passage\"]].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что вопросы все достаточно похожи по своей структуре. Скорее всего они построены на основе каких-либо шаблонов. Авторы в своей статье пишут, что для создания вопросов они использовали Яндекс Толоку, где указали около 50 шаблонов для создания вопросов к тексту. Ну и плюс они все являются да/нет вопросами из-за этого понятно почему у них более менее схожая структура"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Вднх - это выставочный центр?',\n",
       "  'passage': '«Вы́ставочный центр» — станция Московского монорельса. Расположена между станциями «Улица Академика Королёва» и «Улица Сергея Эйзенштейна». Находится на территории Останкинского района Северо-Восточного административного округа города Москвы. Переход на станцию  ВДНХ Калужско-Рижской линии. Названа в честь Всероссийского выставочного центра — названия ВДНХ с 1992 по 2014 год. 20 ноября 2004 года линия монорельса начала работать в «экскурсионном режиме» и перевезла первых пассажиров .',\n",
       "  'label': True,\n",
       "  'idx': 0},\n",
       " {'question': 'Вднх - это выставочный центр?',\n",
       "  'passage': 'Вы́ставка достиже́ний наро́дного хозя́йства  , в 1959—1991 годах — Вы́ставка достиже́ний наро́дного хозя́йства СССР , в 1992—2014 годах — Всеросси́йский вы́ставочный центр ) — выставочный комплекс в Останкинском районе Северо-Восточного административного округа города Москвы, второй по величине выставочный комплекс в городе. Входит в 50 крупнейших выставочных центров мира. Ежегодно ВДНХ посещают 30 млн гостей. 1 августа 2019 года выставка отпраздновала 80-летний юбилей. Территориально ВДНХ объединена с парком «Останкино» и Главным ботаническим садом , их общая площадь составляет почти 700 га: 240,2 га — площадь ВДНХ, 75,6 га — площадь парка «Останкино», 361 га — площадь ГБС, 9,5 га музейно-выставочный центр «Рабочий и колхозница» и площадь перед аркой Главного входа. На территории Выставки расположено множество шедевров архитектуры — 49 объектов ВДНХ признаны памятниками культурного наследия.',\n",
       "  'label': True,\n",
       "  'idx': 1}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, что passage взяты с Википедии. Авторы в статье описали каким образом они собирали passage: с помощью Google API они отправляли полученный с толоки вопрос и находили несколько страниц с Wikipedia. Далее с помощью предобученныего Bert они могли извлекать нужный кусок текста для ответа на вопрос."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. [1 балл] Baseline\n",
    "1. Оцените accuracy совсем простого базового решения: присвоить каждой паре вопрос-ответ в test части самый частый класс из train части.\n",
    "2. Оцените accuracy чуть более сложного базового решения: fasttext на текстах, состоящих из склеенных вопросов и абзацев (' '.join([question, passage])).\n",
    "\n",
    "Сравните полученные результаты и опишите, почему они получились именно такими."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for constant prediction: 0.5018270401948843\n"
     ]
    }
   ],
   "source": [
    "## Для test части нет лейблов. Используем валидационную часть.\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred = np.ones(df_val.shape[0])\n",
    "acc = accuracy_score(df_val['label'], pred)\n",
    "print('Accuracy for constant prediction:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5018270401948843"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['label'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество для константного прогноза равно доле предсказываемого класса в валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вднх - это выставочный центр?</td>\n",
       "      <td>«Вы́ставочный центр» — станция Московского мон...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Вднх - это выставочный центр?</td>\n",
       "      <td>Вы́ставка достиже́ний наро́дного хозя́йства  ,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Был ли джиган в black star?</td>\n",
       "      <td>Вместе с этим треком они выступили на церемони...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xiaomi конкурент apple?</td>\n",
       "      <td>Xiaomi — китайская компания, основанная в 2010...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Был ли автомат калашникова в вов?</td>\n",
       "      <td>Отметив некоторые недостатки и в целом удачную...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>Разрешен ли такой вид ловли акул в настоящее в...</td>\n",
       "      <td>Для человека они потенциально полезны в медици...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>Закреплено ли Гражданство в Конституции</td>\n",
       "      <td>Гражданство является одним из институтов конст...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>Существуют ли примеры, когда не совсем достато...</td>\n",
       "      <td>В философии под эффективностью понимается спос...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>Решен ли вопрос о подлинности Диалога Тацита?</td>\n",
       "      <td>В XIX веке Диалог считали первым произведением...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>Существует ли Новый завет на нижнелужицком языке?</td>\n",
       "      <td>Древнейший памятник серболужицкой письменности...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1749 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0                         Вднх - это выставочный центр?   \n",
       "1                         Вднх - это выставочный центр?   \n",
       "2                           Был ли джиган в black star?   \n",
       "3                               Xiaomi конкурент apple?   \n",
       "4                     Был ли автомат калашникова в вов?   \n",
       "...                                                 ...   \n",
       "1744  Разрешен ли такой вид ловли акул в настоящее в...   \n",
       "1745            Закреплено ли Гражданство в Конституции   \n",
       "1746  Существуют ли примеры, когда не совсем достато...   \n",
       "1747      Решен ли вопрос о подлинности Диалога Тацита?   \n",
       "1748  Существует ли Новый завет на нижнелужицком языке?   \n",
       "\n",
       "                                                passage  label  \n",
       "0     «Вы́ставочный центр» — станция Московского мон...      1  \n",
       "1     Вы́ставка достиже́ний наро́дного хозя́йства  ,...      1  \n",
       "2     Вместе с этим треком они выступили на церемони...      1  \n",
       "3     Xiaomi — китайская компания, основанная в 2010...      1  \n",
       "4     Отметив некоторые недостатки и в целом удачную...      0  \n",
       "...                                                 ...    ...  \n",
       "1744  Для человека они потенциально полезны в медици...      1  \n",
       "1745  Гражданство является одним из институтов конст...      1  \n",
       "1746  В философии под эффективностью понимается спос...      1  \n",
       "1747  В XIX веке Диалог считали первым произведением...      0  \n",
       "1748  Древнейший памятник серболужицкой письменности...      1  \n",
       "\n",
       "[1749 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "with open('data.train.txt', 'w', encoding='utf-8') as outfile:\n",
    "    for _, value in df_train.iterrows():\n",
    "        outfile.write('__label__' + str(value['label']) + ' ' + ' '.join([value['question'], value['passage']]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Есть ли вода на марсе? Гидросфера Марса — это ...\n",
       "1      Состоит ли англия в евросоюзе? В полночь с 31 ...\n",
       "2      Действительно ли в ссср не было адвокатов? Сем...\n",
       "3      Была ли чума в оране? Чума — это и абсурд, что...\n",
       "4      Был ли кетчуп в читосе? Текущий каталог продук...\n",
       "                             ...                        \n",
       "816    Живет ли впч в крови? ДНК вируса многократно д...\n",
       "817    Вредна ли фотоэпиляция в домашних условиях? Пр...\n",
       "818    Были ли бездетными мария и иосиф? О жизни его,...\n",
       "819    Есть ли у луны ядро? Это движение является пре...\n",
       "820    Был ли в ссср налог на бездетность? Налог на б...\n",
       "Length: 821, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['question'] + ' ' + df_val['passage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5956151035322778\n"
     ]
    }
   ],
   "source": [
    "classifier = fasttext.train_supervised('data.train.txt', epoch=30)\n",
    "\n",
    "data_val = (df_val['question'] + ' ' + df_val['passage']).tolist()\n",
    "y_pred = classifier.predict(data_val)\n",
    "acc = accuracy_score(\n",
    "    np.array(list(map(lambda x : \"__label__\" + x, df_val['label'].astype(str).tolist()))), np.array(y_pred[0]).squeeze()\n",
    ")\n",
    "print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество fasttext чуть лучше, чем у константного прогноза."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. [3 балла] Используем эмбеддинги предложений\n",
    "1. Постройте BERT эмбеддинги вопроса и абзаца на основе двух моделей: векторизации русского языка и multilingual модели векторизации. Обучите логистическую регрессию на конкатенированных эмбеддингах вопроса и абзаца и оцените различия в accuracy моделей, обученных на векторах \"разного происхождения\". \n",
    "\n",
    "2. Векторизуйте данные корпуса BoolQ (https://github.com/google-research-datasets/boolean-questions) с помощью multilingual модели из п. 1 и аналогично обучите логистическую регрессию на конкатенированных эмбеддингах вопроса и абзаца. Оцените её качество (обучаем на train, проверяем на test).\n",
    "\n",
    "3. Примените модель из п. 2 к данным DaNetQA и наоборот - модель на основе multilingual векторизации, обученную на DaNetQA, к данным BoolQ. Сравните полученные результаты по точности предсказаний.\n",
    "\n",
    "4. Объедините train в единую обучающую выборку (взять конкатенированные multilingual эмбеддинги) и обучите модель по аналогии с п. 1. Рассчитайте точность на обеих тестовых подвыборках отдельно и сравните результаты с теми, которые были получены в рамках предыдущих пунктов.\n",
    "\n",
    "\n",
    "[бонус] Используйте другие модели эмбеддингов, доступные, например, в библиотеке Transformers. Какая модель эмбеддингов даст лучшие результаты?\n",
    "\n",
    "[бонус] Предложите метод аугментации данных и продемонстрируйте его эффективность. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "def tokenize(df, tokenizer):\n",
    "    question_tokenized = tokenizer(df['question'].tolist(), return_tensors='pt', padding=True)\n",
    "    passage_tokenized = tokenizer(df['passage'].tolist(), return_tensors='pt', padding=True)\n",
    "    return question_tokenized, passage_tokenized\n",
    "\n",
    "def get_embeds(df, tokenizer, model):\n",
    "    question_tokenized, passage_tokenized = tokenize(df, tokenizer)\n",
    "    with torch.no_grad():\n",
    "        question_embedding = model(**question_tokenized)\n",
    "        passage_embedding = model(**passage_tokenized)\n",
    "        question_embedding = question_embedding.last_hidden_state.mean(axis=1)\n",
    "        passage_embedding = passage_embedding.last_hidden_state.mean(axis=1)\n",
    "        embedding = torch.cat([question_embedding, passage_embedding], axis=1)\n",
    "    return embedding\n",
    "\n",
    "def evaluate(df_train, df_val, MODEL_NAME):\n",
    "    tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "    bert = BertModel.from_pretrained(MODEL_NAME)\n",
    "    train_embedding = get_embeds(df_train, tokenizer, bert)\n",
    "    val_embedding = get_embeds(df_val, tokenizer, bert)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(train_embedding, df_train['label'])\n",
    "    pred = model.predict(val_embedding)\n",
    "    acc = accuracy_score(df_val['label'], pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 36s\n",
      "Wall time: 42.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "MODEL_NAME = \"DeepPavlov/rubert-base-cased\"\n",
    "acc1 = evaluate(df_train, df_val, MODEL_NAME)\n",
    "\n",
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "acc2 = evaluate(df_train, df_val, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for DeepPavlov/rubert-base-cased: 0.7\n",
      "Accuracy for bert-base-multilingual-cased: 0.7\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for DeepPavlov/rubert-base-cased:', acc1)\n",
    "print(f'Accuracy for bert-base-multilingual-cased:', acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "## **Вывод на полных данных**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/BoolQ/train.jsonl\"\n",
    "val_path = \"data/BoolQ/dev.jsonl\"\n",
    "\n",
    "boolq_train_data = read_data(train_path)\n",
    "boolq_val_data = read_data(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolq_df_train = pd.DataFrame.from_records(boolq_train_data)\n",
    "boolq_df_val = pd.DataFrame.from_records(boolq_val_data)\n",
    "\n",
    "boolq_df_train['label'] = boolq_df_train['answer'].astype(int)\n",
    "boolq_df_val['label'] = boolq_df_val['answer'].astype(int)\n",
    "boolq_df_train = boolq_df_train.drop(['title', 'answer'], axis=1)\n",
    "boolq_df_val = boolq_df_val.drop(['title', 'answer'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do iran and afghanistan speak the same language</td>\n",
       "      <td>Persian (/ˈpɜːrʒən, -ʃən/), also known by its ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do good samaritan laws protect those who help ...</td>\n",
       "      <td>Good Samaritan laws offer legal protection to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is windows movie maker part of windows essentials</td>\n",
       "      <td>Windows Movie Maker (formerly known as Windows...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is confectionary sugar the same as powdered sugar</td>\n",
       "      <td>Powdered sugar, also called confectioners' sug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is elder scrolls online the same as skyrim</td>\n",
       "      <td>As with other games in The Elder Scrolls serie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0    do iran and afghanistan speak the same language   \n",
       "1  do good samaritan laws protect those who help ...   \n",
       "2  is windows movie maker part of windows essentials   \n",
       "3  is confectionary sugar the same as powdered sugar   \n",
       "4         is elder scrolls online the same as skyrim   \n",
       "\n",
       "                                             passage  label  \n",
       "0  Persian (/ˈpɜːrʒən, -ʃən/), also known by its ...      1  \n",
       "1  Good Samaritan laws offer legal protection to ...      1  \n",
       "2  Windows Movie Maker (formerly known as Windows...      1  \n",
       "3  Powdered sugar, also called confectioners' sug...      1  \n",
       "4  As with other games in The Elder Scrolls serie...      0  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolq_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 8s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "acc = evaluate(boolq_df_train, boolq_df_val, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for BoolQ: 0.6\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for BoolQ:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "acc = evaluate(boolq_df_train, df_val, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on DaNetQA dataset for model trained on BoolQ: 0.7\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on DaNetQA dataset for model trained on BoolQ:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "acc = evaluate(df_train, boolq_df_val, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on BoolQ dataset for model trained on DaNetQA: 0.36\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on BoolQ dataset for model trained on DaNetQA:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "concat_df_train = pd.concat([df_train, boolq_df_train], axis=0)\n",
    "\n",
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "acc1 = evaluate(concat_df_train, df_val, MODEL_NAME)\n",
    "acc2 = evaluate(concat_df_train, boolq_df_val, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on DaNetQA dataset for model trained on concatination of 2 datasets: 0.7\n",
      "Accuracy on BoolQ dataset for model trained on concatination of 2 datasets: 0.8\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on DaNetQA dataset for model trained on concatination of 2 datasets:', acc1)\n",
    "print(f'Accuracy on BoolQ dataset for model trained on concatination of 2 datasets:', acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. [4 балла] Модель на основе архитектуры Transformer\n",
    "\n",
    "Выберите две модели на основе архитектуры transformer (BERT, RoBERTa, XLM etc.) - русскоязычную и мультиязычную и дообучите их на корпусах DaNetQA и BoolQ. \n",
    "\n",
    "Оцените качество этих моделей для решения задачи. Сравните их работоспособность между собой на основе метрик качества\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 4. [1 балл] Итоги\n",
    "Напишите краткое резюме проделанной работы. Сравните результаты всех разработанных моделей. Что помогло вам в выполнении работы, чего не хватало?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
