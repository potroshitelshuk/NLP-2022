{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZY7kcPjTtIk"
      },
      "source": [
        "# Домашнее задание 2\n",
        "## Named Entity Recognition and Event Extraction\n",
        "\n",
        "deadline: 06 ноября 2022, 23:59\n",
        "\n",
        "В этом домашнем задании вы будете работать с двумя корпусами - LitBank и MultiNERD_EN.\n",
        "Первый корпус (LitBank) собран из популярных художественных произведений на английском языке и содержит разметку по именованным сущностям и событиям, корпус состоит из 100 текстов по примерно 2000 слов каждый. \n",
        "\n",
        "Корпус описан в статьях:\n",
        "* David Bamman, Sejal Popat, Sheng Shen, An Annotated Dataset of Literary Entities http://people.ischool.berkeley.edu/~dbamman/pubs/pdf/naacl2019_literary_entities.pdf\n",
        "* Matthew Sims, Jong Ho Park, David Bamman, Literary Event Detection,  http://people.ischool.berkeley.edu/~dbamman/pubs/pdf/acl2019_literary_events.pdf\n",
        "\n",
        "Корпус доступен в репозитории проекта:  https://github.com/dbamman/litbank\n",
        "\n",
        "Статья и код, использованный для извлечения именованных сущностей: \n",
        "* Meizhi Ju, Makoto Miwa and Sophia Ananiadou, A Neural Layered Model for Nested Named Entity Recognition, https://github.com/meizhiju/layered-bilstm-crf\n",
        "\n",
        "Структура корпуса устроена так. \n",
        "Первый уровень: \n",
        "* entities -- разметка по сущностям\n",
        "* events -- разметка по сущностям\n",
        "\n",
        "\n",
        "В корпусе используются 6 типов именованных сущностей: PER, LOC, ORG, FAC, GPE, VEH (имена, локации, организации, помещения, топонимы, средства перемещения), допускаются вложенные сущности. \n",
        "\n",
        "События выражается одним словом - *триггером*, которое может быть глаголом, прилагательным и существительным. В корпусе описаны события, которые действительно происходят и не имеют гипотетического характера. \n",
        "Пример: she *walked* rapidly and resolutely, здесь *walked* -- триггер события. Типы событий не заданы. \n",
        "\n",
        "\n",
        "Второй уровень:\n",
        "* brat -- рабочие файлы инструмента разметки brat, ann-файлы содержат разметку, txt-файлы – сырые тексты \n",
        "* tsv -- tsv-файлы содержат разметку в IOB формате,\n",
        "\n",
        "Второй корпус (MultiNERD_EN) состоит из 164 тысяч предложений по различным тематикам. От предыдущего корпуса он отличается большим числом (15) типов именованных сущностей. Также одной из сущностей является сущность-событие (EVE). Каждая сущность может состоять как из одного, так и нескольких слов.\n",
        "\n",
        "Корпус доступен в репозитории проекта:  https://github.com/Babelscape/multinerd\n",
        "\n",
        "В статьях и репозиториях вы найдете идеи, которые помогут вам выполнить домашнее задание. Их стоит воспринимать как руководство к действию, и не стоит их копировать и использовать повторно. Обученные модели использовать не нужно, код для их обучения можно использовать как подсказку. \n",
        "\n",
        "## ПРАВИЛА\n",
        "1. Домашнее задание выполняется в группе до 4-х человек.\n",
        "2. Домашнее задание оформляется в виде отчета либо в .pdf файле, либо в ipython-тетрадке. При этом прикладывать ipynb-файл обязательно. \n",
        "43. Отчет должен содержать: нумерацию заданий и пунктов, которые вы выполнили, код решения, и понятное пошаговое описание того, что вы сделали. Отчет должен быть написан в академическом стиле, без излишнего использования сленга и с соблюдением норм русского языка.\n",
        "4. Не стоит копировать фрагменты лекций, статей и Википедии в ваш отчет.\n",
        "5. Отчеты, состоящие исключительно из кода, не будут проверены и будут автоматически оценены нулевой оценкой.\n",
        "6. Плагиат и любое недобросовестное цитирование приводит к обнулению оценки. \n",
        "\n",
        "\n",
        "## Часть 1. [2.5 балла] Эксплоративный анализ \n",
        "1. [0.4 балла] Найдите топ 10 (по частоте) именованных сущностей каждого из типов для каждого корпуса. Произведите сравнение частотности по совпадающим сущностям при сопоставлении корпусов друг с другом.\n",
        "2. [0.4 балла] Найдите топ 10 (по частоте) частотных триггеров событий (на основе LitBank). Произведите анализ из пункта 1 для именованной сущности типа EVE (на основе MultiNERD_EN). \n",
        "3. [0.9 балла] Кластеризуйте все уникальные триггеры событий (LitBank), используя эмбеддинги слов и любой алгоритм кластеризации (например, аггломеративный иерархический алгоритм кластеризации) и попробуйте проинтерпретировать кластеры: есть ли очевидные типы событий? \n",
        "4. [0.8 балла] Отдельно произведите анализ из п. 3 для сущностей типа EVE (на основе MultiNERD_EN). Сравните результаты из п. 3 и п. 4.\n",
        "\n",
        "[бонус] Визуализируйте полученные кластеры с помощью TSNE или UMAP\n",
        "\n",
        "[бонус] Постройте тематическую модель по корпусу LitBank и сравните кластеры триггеров и выделенные темы: есть ли схожие паттерны в тематической модели и в структуре кластеров?\n",
        "\n",
        "В следующих частях домашнего задания вам понадобится train-test-dev разбиения. Авторы статей предлагают следующую структуру разбиения для корпуса LitBank: обучающее множество – 80 книг, валидационное – 10 книг, тестовое – 10 книг. Предложения из одного источника не должны попадать в разные сегменты разбиения.\n",
        "Для корпуса MultiNERD_EN произведите стратифицированное разбиение по предложениям в соотношении 80%:10%:10%. Стратификацию производить в отношении пропорции по именованным сущностям (понятно, что с учётом всех вводных идеального разбиения не получится, но старайтесь сохранить распределения по типам сущностей для каждой и подвыборок).\n",
        "\n",
        "\n",
        "## Часть 2. [4 балла] Извлечение именованных сущностей\n",
        "Для каждой корпуса необходимо осуществить раздельно следующую процедуру:\n",
        "1. [0.75 балла] Обучите стандартную модель для извлечения именованных сущностей, CNN-BiLSTM-CRF, для извлечения именованных *низкоуровневых именованных сущностей*, т.е. для самых коротких из вложенных сущностей. Модель устроена так: сверточная сеть на символах + эмбеддинги слов + двунаправленная LSTM сеть (модель последовательности) + CRF (глобальная нормализация). \n",
        "2. [0.75 балла] Замените часть модели на символах и словах (CNN + эмбеддинги словах) на ELMo и / или BERT. Должна получиться модель ELMo / BERT + BiLSTM + CRF. \n",
        "3. [2.5 балла] Замените модель последовательности (BiLSTM) на другой слой, например, на Transformer. Должна получиться модель Transformer + CRF.\n",
        "В результате у вас будет 2 набора моделей - проверьте качество извлечения на тестовых данных.\n",
        "- Примените модели первого корпуса ко всем (!!!) предложениям второго корпуса и наоборот.\n",
        "- Составьте отчёт по качеству работы моделей в терминах извлечения по типам сущностей, которые встречаются в обоих корпусах. Метрику выберите самостоятельно.\n",
        "- Проанализируйте ошибки моделей в терминах предсказания сущностям первого корпуса специфических типов для второго корпуса. И наоборот - когда специфическим типам второго корпуса модель, обученная на LitBank, прсваивает одну из своих категорий.\n",
        "\n",
        "[бонус] Дообучите BERT для извлечения именованных сущностей.\n",
        "\n",
        "[бонус] Используйте модель для извлечения вложенных именованных сущностей [Ju et al., 2018]\n",
        "\n",
        "[бонус] Модифицируйте модель для извлечения вложенных именованных сущностей [Ju et al., 2018]: вместо эмбеддингов слов используйте ELMo и/или BERT. \n",
        "\n",
        "## Часть 3. [2.5 балла] Извлечение событий \n",
        "\n",
        "1. [0.75 балла] Используйте BiLSTM на эмбеддингах слов для извлечения триггеров событий (на основе LitBank). \n",
        "\n",
        "2. [1.25 балла] Замените часть модели на словах на ELMo и/или BERT. Должна получиться модель ELMo / BERT + BiLSTM.\n",
        "\n",
        "3. [0.5 балла] Проверьте \"извлекающую\" силу модели на данных MultiNERD_EN для событий типа EVE. \n",
        "\n",
        "[бонус] Предобучите BiLSTM как языковую модель. Дообучите ее для извлечения триггеров. \n",
        "\n",
        "[бонус] Дообучите BERT для извлечения триггеров событий.  \n",
        "\n",
        "## Часть 4. Одновременное извлечение именованных сущностей и событий \n",
        "1. [0.75 бонуса] Обучите модель для совместного извлечения именованных сущностей и триггеров событий только на основе LitBank (!). У модели должен быть общий энкодер (например, CNN + BiLSMT, ELMo + BiLSTM, BERT + BiLSTM) и два декодера: один отвечает за извлечение именованных сущностей, другой отвечает за извлечение триггеров событий.\n",
        "\n",
        "2. [0.75 бонуса] Создайте единую обучающую подвыборку, единую валидационную и единую тестовую на основе разбиений, которые вы произвели в первой части и обучите модель. (Единую - то есть на основе обоих корпусов сразу)\n",
        "\n",
        "3. [0.5 бонуса] Сравните предсказательную силу модели из п.1 и модели из п.2 как на совместных подвыборках, так и на раздельных. Проанализируйте полученный результат. Приводит ли обогащение дополнительными данными к улучшению \"извлекающей\" способности модели?\n",
        "\n",
        "[бонус] Добавьте в модель механизм внимания, таким способом, который покажется вам разумным.\n",
        "\n",
        "[бонус] Визуализируйте карты механизма внимания (attention). \n",
        "\n",
        "## Часть 5. [1 балл] Итоги\n",
        "Напишите краткое резюме проделанной работы. Сравните результаты всех разработанных моделей. Что помогло вам в выполнении работы, чего не хватало?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRSIxh8eYLgo",
        "outputId": "6a2adc58-8782-4b44-e101-8d4f431edf57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOx45S5JXD9A"
      },
      "source": [
        "<span style=\"color:pink\">Авторы работы: Токкожин Арсен, Соколов Ян, Екимов Егор, Гвасалия Лукас</span>\n",
        "# Решение:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQsdTZtpXD9B"
      },
      "source": [
        "## Часть 1. [2.5 балла] Эксплоративный анализ \n",
        "1. [0.4 балла] Найдите топ 10 (по частоте) именованных сущностей каждого из типов для каждого корпуса. Произведите сравнение частотности по совпадающим сущностям при сопоставлении корпусов друг с другом.\n",
        "2. [0.4 балла] Найдите топ 10 (по частоте) частотных триггеров событий (на основе LitBank). Произведите анализ из пункта 1 для именованной сущности типа EVE (на основе MultiNERD_EN). \n",
        "3. [0.9 балла] Кластеризуйте все уникальные триггеры событий (LitBank), используя эмбеддинги слов и любой алгоритм кластеризации (например, аггломеративный иерархический алгоритм кластеризации) и попробуйте проинтерпретировать кластеры: есть ли очевидные типы событий? \n",
        "4. [0.8 балла] Отдельно произведите анализ из п. 3 для сущностей типа EVE (на основе MultiNERD_EN). Сравните результаты из п. 3 и п. 4.\n",
        "\n",
        "[бонус] Визуализируйте полученные кластеры с помощью TSNE или UMAP\n",
        "\n",
        "[бонус] Постройте тематическую модель по корпусу LitBank и сравните кластеры триггеров и выделенные темы: есть ли схожие паттерны в тематической модели и в структуре кластеров?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqpRAq4y5YHT",
        "outputId": "6ea1c4bd-b8bf-4c04-d90d-0cff484b852e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mendelai-brat-parser\n",
            "  Downloading mendelai_brat_parser-0.0.11.tar.gz (4.6 kB)\n",
            "Building wheels for collected packages: mendelai-brat-parser\n",
            "  Building wheel for mendelai-brat-parser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mendelai-brat-parser: filename=mendelai_brat_parser-0.0.11-py3-none-any.whl size=4945 sha256=290620b7bc4b7517083fec90502034b634c0f5db950d29265e889ad03daa5272\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/40/73/4f68f4fa597be33e250400cd56c28c85862b1cba5b3c7c33f1\n",
            "Successfully built mendelai-brat-parser\n",
            "Installing collected packages: mendelai-brat-parser\n",
            "Successfully installed mendelai-brat-parser-0.0.11\n"
          ]
        }
      ],
      "source": [
        "!pip install mendelai-brat-parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NPO5KzexXD9B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from brat_parser import get_entities_relations_attributes_groups\n",
        "from collections import Counter\n",
        "\n",
        "# paths for local initialization:\n",
        "# entities_folder_path = \"litbank_entities/brat\"\n",
        "# events_folder_path = \"litbank_events/brat\"\n",
        "# multinerd_path = \"multinerd_en.tsv\"\n",
        "\n",
        "# paths for colab initialization:\n",
        "entities_folder_path = \"/content/drive/MyDrive/litbank_entities/brat\"\n",
        "events_folder_path = \"/content/drive/MyDrive/litbank_events/brat\"\n",
        "multinerd_path = \"/content/drive/MyDrive/multinerd_en.tsv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXkO4iIdXD9C"
      },
      "source": [
        "#### Топ 10 именованных сущностей для корпуса Litbank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JdFC_UQzXD9D"
      },
      "outputs": [],
      "source": [
        "entities = [\"PER\", \"FAC\", \"LOC\", \"ORG\", \"GPE\", \"VEH\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_UNo5M_pXD9D"
      },
      "outputs": [],
      "source": [
        "def count_entities(path_to_folder, entities_names):\n",
        "    result = {}\n",
        "    for entity in entities_names:\n",
        "        result[entity] = Counter()\n",
        "\n",
        "    for filename in os.listdir(path_to_folder):\n",
        "        if filename.endswith(\".ann\"):\n",
        "            entities, relations, attributes, groups = get_entities_relations_attributes_groups(os.path.join(path_to_folder, filename))\n",
        "            for item in entities:\n",
        "                result[entities[item].type][entities[item].text] += 1 \n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Moq7O0y_XD9E",
        "outputId": "fbf096f5-7ffe-4d60-ef66-6c21f1278fc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------\n",
            "PER\n",
            "('Mr.', 148)\n",
            "('Miss', 133)\n",
            "('Mrs.', 132)\n",
            "('sir', 50)\n",
            "('Sir', 45)\n",
            "('my mother', 40)\n",
            "('men', 40)\n",
            "('Cameron', 38)\n",
            "('his wife', 37)\n",
            "('Mr', 37)\n",
            "-------------------------------------\n",
            "FAC\n",
            "('home', 65)\n",
            "('the house', 52)\n",
            "('there', 39)\n",
            "('here', 39)\n",
            "('the room', 34)\n",
            "('the garden', 23)\n",
            "('the street', 14)\n",
            "('the hall', 13)\n",
            "('the road', 13)\n",
            "('the place', 12)\n",
            "-------------------------------------\n",
            "LOC\n",
            "('the world', 72)\n",
            "('the sea', 27)\n",
            "('the river', 22)\n",
            "('the country', 20)\n",
            "('there', 18)\n",
            "('the earth', 16)\n",
            "('sea', 16)\n",
            "('the valley', 13)\n",
            "('this world', 12)\n",
            "('the woods', 9)\n",
            "-------------------------------------\n",
            "ORG\n",
            "('the army', 7)\n",
            "('the Committee of Public Safety', 4)\n",
            "('the Colonial Office', 4)\n",
            "('the Church', 4)\n",
            "('Harvard', 3)\n",
            "('college', 3)\n",
            "('the hospital', 2)\n",
            "('the C.C.H.', 2)\n",
            "(\"the Bank of Leichardt 's Land\", 2)\n",
            "('a regiment of regulars', 2)\n",
            "-------------------------------------\n",
            "GPE\n",
            "('London', 40)\n",
            "('England', 32)\n",
            "('there', 21)\n",
            "('the town', 21)\n",
            "('New York', 16)\n",
            "('town', 14)\n",
            "('France', 14)\n",
            "('Europe', 12)\n",
            "('the country', 10)\n",
            "('Rome', 10)\n",
            "-------------------------------------\n",
            "VEH\n",
            "('the ship', 11)\n",
            "('the car', 9)\n",
            "('the train', 6)\n",
            "('boats', 4)\n",
            "('the boat', 4)\n",
            "('a carriage', 3)\n",
            "('the waggon', 3)\n",
            "('the carriage', 3)\n",
            "('the coach', 3)\n",
            "('the Fuwalda', 3)\n"
          ]
        }
      ],
      "source": [
        "entities_ans = count_entities(entities_folder_path, entities)\n",
        "for entity in entities_ans:\n",
        "    print(\"-------------------------------------\")\n",
        "    print(entity)\n",
        "    temp = entities_ans[entity].most_common()[:10]\n",
        "    for item in temp:\n",
        "        print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnsQLhcFXD9E"
      },
      "source": [
        "#### Топ 10 именованных сущностей для корпуса MultiNERD_EN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RSWOVUrEXD9F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "col_names = [\"Index\", \"Token\", \"Label\", \"BabelNet ID\", \"Wikidata ID\", \"Wikipedia ID\", \"Wikipedia Title\", \"Definition\", \"Image URL\", \"Smth\"]\n",
        "multinerd_data = pd.read_csv(multinerd_path, sep=\"\\t\", names=col_names, index_col=False , quoting=csv.QUOTE_NONE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "3Be9RKyRXD9F",
        "outputId": "7359c432-f8c5-46ee-b2fd-ab19d47685b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>Token</th>\n",
              "      <th>Label</th>\n",
              "      <th>BabelNet ID</th>\n",
              "      <th>Wikidata ID</th>\n",
              "      <th>Wikipedia ID</th>\n",
              "      <th>Wikipedia Title</th>\n",
              "      <th>Definition</th>\n",
              "      <th>Image URL</th>\n",
              "      <th>Smth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Created</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>by</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>James</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>bn:00786804n</td>\n",
              "      <td>Q42574</td>\n",
              "      <td>15622.0</td>\n",
              "      <td>James_Cameron</td>\n",
              "      <td>James Francis Cameron is a Canadian film direc...</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Cameron</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Index    Token  Label   BabelNet ID Wikidata ID  Wikipedia ID  \\\n",
              "0      0  Created      O           NaN         NaN           NaN   \n",
              "1      1       by      O           NaN         NaN           NaN   \n",
              "2      2    James  B-PER  bn:00786804n      Q42574       15622.0   \n",
              "3      3  Cameron  I-PER           NaN         NaN           NaN   \n",
              "4      4      and      O           NaN         NaN           NaN   \n",
              "\n",
              "  Wikipedia Title                                         Definition  \\\n",
              "0             NaN                                                NaN   \n",
              "1             NaN                                                NaN   \n",
              "2   James_Cameron  James Francis Cameron is a Canadian film direc...   \n",
              "3             NaN                                                NaN   \n",
              "4             NaN                                                NaN   \n",
              "\n",
              "                                           Image URL  Smth  \n",
              "0                                                NaN   NaN  \n",
              "1                                                NaN   NaN  \n",
              "2  https://upload.wikimedia.org/wikipedia/commons...   NaN  \n",
              "3                                                NaN   NaN  \n",
              "4                                                NaN   NaN  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multinerd_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wujEqghjXD9F",
        "outputId": "f0e7327c-a7ce-41b0-b029-41a6255ba8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3568155\n",
            "3568155\n"
          ]
        }
      ],
      "source": [
        "print(multinerd_data[\"Smth\"].size)\n",
        "print(multinerd_data[\"Smth\"].isna().count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K-1EtwzXD9G"
      },
      "source": [
        "видим что последняя колонка полнстью состоит из пропусков, так что ее можно удалить"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ynQrX0KzXD9G"
      },
      "outputs": [],
      "source": [
        "multinerd_data=multinerd_data.drop([\"Smth\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "RBrWJaVWXD9G",
        "outputId": "35db4895-9e2c-4a09-c807-78b71ecb1dc9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9bf54c65-9ce7-47c3-8997-a6e2a7bb0754\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>Token</th>\n",
              "      <th>Label</th>\n",
              "      <th>BabelNet ID</th>\n",
              "      <th>Wikidata ID</th>\n",
              "      <th>Wikipedia ID</th>\n",
              "      <th>Wikipedia Title</th>\n",
              "      <th>Definition</th>\n",
              "      <th>Image URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Created</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>by</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>James</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>bn:00786804n</td>\n",
              "      <td>Q42574</td>\n",
              "      <td>15622.0</td>\n",
              "      <td>James_Cameron</td>\n",
              "      <td>James Francis Cameron is a Canadian film direc...</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Cameron</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bf54c65-9ce7-47c3-8997-a6e2a7bb0754')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9bf54c65-9ce7-47c3-8997-a6e2a7bb0754 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9bf54c65-9ce7-47c3-8997-a6e2a7bb0754');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Index    Token  Label   BabelNet ID Wikidata ID  Wikipedia ID  \\\n",
              "0      0  Created      O           NaN         NaN           NaN   \n",
              "1      1       by      O           NaN         NaN           NaN   \n",
              "2      2    James  B-PER  bn:00786804n      Q42574       15622.0   \n",
              "3      3  Cameron  I-PER           NaN         NaN           NaN   \n",
              "4      4      and      O           NaN         NaN           NaN   \n",
              "\n",
              "  Wikipedia Title                                         Definition  \\\n",
              "0             NaN                                                NaN   \n",
              "1             NaN                                                NaN   \n",
              "2   James_Cameron  James Francis Cameron is a Canadian film direc...   \n",
              "3             NaN                                                NaN   \n",
              "4             NaN                                                NaN   \n",
              "\n",
              "                                           Image URL  \n",
              "0                                                NaN  \n",
              "1                                                NaN  \n",
              "2  https://upload.wikimedia.org/wikipedia/commons...  \n",
              "3                                                NaN  \n",
              "4                                                NaN  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multinerd_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtz2pf5rXD9H",
        "outputId": "968b1f8d-3a41-4eb8-854e-6ab48dacdcba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['O', 'B-PER', 'I-PER', 'B-LOC', 'B-MEDIA', 'I-MEDIA', 'B-TIME',\n",
              "       'B-EVE', 'I-EVE', 'I-TIME', 'I-LOC', 'B-ORG', 'I-ORG', 'B-PLANT',\n",
              "       'B-ANIM', 'I-ANIM', 'I-PLANT', 'B-FOOD', 'B-DIS', 'I-DIS', 'B-CEL',\n",
              "       'B-SUPER', 'I-SUPER', 'I-FOOD', 'B-VEHI', 'I-VEHI', 'B-INST',\n",
              "       'I-INST', 'I-CEL', 'B-PHY', 'I-PHY', 'B-BIO', 'I-BIO'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multinerd_data[\"Label\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YdQpWUb6XD9H",
        "outputId": "0ecd81c4-f482-45fd-891d-353e2857b49f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6b9c270f-eff6-4455-8d41-7a5e373449e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>James</td>\n",
              "      <td>B-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cameron</td>\n",
              "      <td>I-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Charles</td>\n",
              "      <td>B-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>H.</td>\n",
              "      <td>I-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Eglee</td>\n",
              "      <td>I-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3568089</th>\n",
              "      <td>United</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3568090</th>\n",
              "      <td>Kingdom</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3568106</th>\n",
              "      <td>North</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3568107</th>\n",
              "      <td>Korea</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3568128</th>\n",
              "      <td>Japan</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>456268 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b9c270f-eff6-4455-8d41-7a5e373449e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b9c270f-eff6-4455-8d41-7a5e373449e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b9c270f-eff6-4455-8d41-7a5e373449e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           Token  Label\n",
              "2          James  B-PER\n",
              "3        Cameron  I-PER\n",
              "5        Charles  B-PER\n",
              "6             H.  I-PER\n",
              "7          Eglee  I-PER\n",
              "...          ...    ...\n",
              "3568089   United  B-LOC\n",
              "3568090  Kingdom  I-LOC\n",
              "3568106    North  B-LOC\n",
              "3568107    Korea  I-LOC\n",
              "3568128    Japan  B-LOC\n",
              "\n",
              "[456268 rows x 2 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = multinerd_data[[\"Token\", \"Label\"]][multinerd_data[[\"Token\", \"Label\"]][\"Label\"] != \"O\"]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiZXtMypXD9H",
        "outputId": "6761b89a-21b9-4662-ff62-13f2807ccbda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['B-PER', 'I-PER', 'B-LOC', 'B-MEDIA', 'I-MEDIA', 'B-TIME', 'B-EVE',\n",
              "       'I-EVE', 'I-TIME', 'I-LOC', 'B-ORG', 'I-ORG', 'B-PLANT', 'B-ANIM',\n",
              "       'I-ANIM', 'I-PLANT', 'B-FOOD', 'B-DIS', 'I-DIS', 'B-CEL',\n",
              "       'B-SUPER', 'I-SUPER', 'I-FOOD', 'B-VEHI', 'I-VEHI', 'B-INST',\n",
              "       'I-INST', 'I-CEL', 'B-PHY', 'I-PHY', 'B-BIO', 'I-BIO'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.Label.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdXDUV5pHMsu"
      },
      "source": [
        "Обработаем multinerd датасет, для подсчета топ популярных сущностей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "yFBMc5jqXD9H",
        "outputId": "c90f5ad0-75af-4f42-9f05-d1b9c1d9bc44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 456268/456268 [00:22<00:00, 19948.83it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a4645c31-e5f2-404f-bc2f-abbb8b661247\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>James Cameron</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Charles H. Eglee</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jessica Alba</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Seattle</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253517</th>\n",
              "      <td>Libya</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253518</th>\n",
              "      <td>Bashar al-Assad</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253519</th>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253520</th>\n",
              "      <td>North Korea</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253521</th>\n",
              "      <td>Japan</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>253522 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4645c31-e5f2-404f-bc2f-abbb8b661247')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4645c31-e5f2-404f-bc2f-abbb8b661247 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4645c31-e5f2-404f-bc2f-abbb8b661247');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                   Token Label\n",
              "0                             \n",
              "1          James Cameron   PER\n",
              "2       Charles H. Eglee   PER\n",
              "3           Jessica Alba   PER\n",
              "4                Seattle   LOC\n",
              "...                  ...   ...\n",
              "253517             Libya   LOC\n",
              "253518   Bashar al-Assad   PER\n",
              "253519    United Kingdom   LOC\n",
              "253520       North Korea   LOC\n",
              "253521             Japan   LOC\n",
              "\n",
              "[253522 rows x 2 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "ans = []\n",
        "curr_token = \"\"\n",
        "curr_label = \"\"\n",
        "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
        "    label = str(row[\"Label\"])\n",
        "    token = str(row[\"Token\"])\n",
        "    if label[0] == \"B\":\n",
        "        curr_df = {\n",
        "            \"Token\" : curr_token,\n",
        "            \"Label\" : curr_label\n",
        "        }\n",
        "        ans.append(curr_df)\n",
        "        curr_token = token\n",
        "        curr_label = label[2:]\n",
        "    elif label[2:] == curr_label:\n",
        "        curr_token = curr_token + \" \" + token\n",
        "    if index == 3568128:\n",
        "        curr_df = {\n",
        "            \"Token\" : curr_token,\n",
        "            \"Label\" : curr_label\n",
        "        }\n",
        "        ans.append(curr_df)\n",
        "ans = pd.DataFrame(ans)\n",
        "ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ryWPS1-sXD9I"
      },
      "outputs": [],
      "source": [
        "ans = ans.iloc[1: , :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "UUdZCcV1XD9I",
        "outputId": "2c9f1339-e7da-4bc8-933e-f6c16a56264f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6f4e0bbb-cf30-4027-98d0-e3b24b8ccf94\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>James Cameron</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Charles H. Eglee</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jessica Alba</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Seattle</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CSI : Crime Scene Investigation</td>\n",
              "      <td>MEDIA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253517</th>\n",
              "      <td>Libya</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253518</th>\n",
              "      <td>Bashar al-Assad</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253519</th>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253520</th>\n",
              "      <td>North Korea</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253521</th>\n",
              "      <td>Japan</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>253521 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f4e0bbb-cf30-4027-98d0-e3b24b8ccf94')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f4e0bbb-cf30-4027-98d0-e3b24b8ccf94 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f4e0bbb-cf30-4027-98d0-e3b24b8ccf94');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                  Token  Label\n",
              "1                         James Cameron    PER\n",
              "2                      Charles H. Eglee    PER\n",
              "3                          Jessica Alba    PER\n",
              "4                               Seattle    LOC\n",
              "5       CSI : Crime Scene Investigation  MEDIA\n",
              "...                                 ...    ...\n",
              "253517                            Libya    LOC\n",
              "253518                  Bashar al-Assad    PER\n",
              "253519                   United Kingdom    LOC\n",
              "253520                      North Korea    LOC\n",
              "253521                            Japan    LOC\n",
              "\n",
              "[253521 rows x 2 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "CGaSbIjCXD9I",
        "outputId": "85cdfef2-8a5d-4a88-9ee3-3f6d8dca7240"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-76a88fab-b032-4867-b0cb-ea317d650cea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ANIM</td>\n",
              "      <td>15474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BIO</td>\n",
              "      <td>162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CEL</td>\n",
              "      <td>2820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DIS</td>\n",
              "      <td>11156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EVE</td>\n",
              "      <td>3176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>FOOD</td>\n",
              "      <td>10965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>INST</td>\n",
              "      <td>425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LOC</td>\n",
              "      <td>78539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>MEDIA</td>\n",
              "      <td>7458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ORG</td>\n",
              "      <td>33687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>PER</td>\n",
              "      <td>75759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>PHY</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>PLANT</td>\n",
              "      <td>9510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>SUPER</td>\n",
              "      <td>657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>TIME</td>\n",
              "      <td>3151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>VEHI</td>\n",
              "      <td>516</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76a88fab-b032-4867-b0cb-ea317d650cea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76a88fab-b032-4867-b0cb-ea317d650cea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76a88fab-b032-4867-b0cb-ea317d650cea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Label  Token\n",
              "0    ANIM  15474\n",
              "1     BIO    162\n",
              "2     CEL   2820\n",
              "3     DIS  11156\n",
              "4     EVE   3176\n",
              "5    FOOD  10965\n",
              "6    INST    425\n",
              "7     LOC  78539\n",
              "8   MEDIA   7458\n",
              "9     ORG  33687\n",
              "10    PER  75759\n",
              "11    PHY     66\n",
              "12  PLANT   9510\n",
              "13  SUPER    657\n",
              "14   TIME   3151\n",
              "15   VEHI    516"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ans.groupby([\"Label\"]).count().reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj7uYR7oHcET"
      },
      "source": [
        "Посмотрим на все сущности в нашем получившемся датасете"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lHiwFBNXD9J",
        "outputId": "e3b7d385-0154-439a-cbe8-998523a96195"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['PER',\n",
              " 'LOC',\n",
              " 'MEDIA',\n",
              " 'TIME',\n",
              " 'EVE',\n",
              " 'ORG',\n",
              " 'PLANT',\n",
              " 'ANIM',\n",
              " 'FOOD',\n",
              " 'DIS',\n",
              " 'CEL',\n",
              " 'SUPER',\n",
              " 'VEHI',\n",
              " 'INST',\n",
              " 'PHY',\n",
              " 'BIO']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "entities_names_multinerd = list(ans[\"Label\"].unique())\n",
        "entities_names_multinerd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "JZOHxfltvayI",
        "outputId": "cceed9d0-cd5b-4adb-fd4c-2954eed6443c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-272d1d9d-1d77-442e-9a47-bdc71fb5a8ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>James Cameron</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Charles H. Eglee</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jessica Alba</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Seattle</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CSI : Crime Scene Investigation</td>\n",
              "      <td>MEDIA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253517</th>\n",
              "      <td>Libya</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253518</th>\n",
              "      <td>Bashar al-Assad</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253519</th>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253520</th>\n",
              "      <td>North Korea</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253521</th>\n",
              "      <td>Japan</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>253521 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-272d1d9d-1d77-442e-9a47-bdc71fb5a8ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-272d1d9d-1d77-442e-9a47-bdc71fb5a8ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-272d1d9d-1d77-442e-9a47-bdc71fb5a8ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                  Token  Label\n",
              "1                         James Cameron    PER\n",
              "2                      Charles H. Eglee    PER\n",
              "3                          Jessica Alba    PER\n",
              "4                               Seattle    LOC\n",
              "5       CSI : Crime Scene Investigation  MEDIA\n",
              "...                                 ...    ...\n",
              "253517                            Libya    LOC\n",
              "253518                  Bashar al-Assad    PER\n",
              "253519                   United Kingdom    LOC\n",
              "253520                      North Korea    LOC\n",
              "253521                            Japan    LOC\n",
              "\n",
              "[253521 rows x 2 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaebHr_AHkNX"
      },
      "source": [
        "Выведем топ 10 популярных слов или словосочетаний для каждого вида сущностей в датасете multinerd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9cUPkiEXD9J",
        "outputId": "aa0700c8-4816-41b9-8ddb-023796322b1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PER:\n",
            "George Hampson\n",
            "Edward Meyrick\n",
            "Breuning\n",
            "Roger Ebert\n",
            "Francis Walker\n",
            "Aristotle\n",
            "Barack Obama\n",
            "Plato\n",
            "Charles Darwin\n",
            "George W. Bush\n",
            "--------------------------------\n",
            "LOC:\n",
            "United States\n",
            "Australia\n",
            "United Kingdom\n",
            "Brazil\n",
            "China\n",
            "India\n",
            "Mexico\n",
            "Japan\n",
            "Canada\n",
            "Ecuador\n",
            "--------------------------------\n",
            "MEDIA:\n",
            "Rotten Tomatoes\n",
            "Oxford English Dictionary\n",
            "TV Guide\n",
            "Rolling Stone\n",
            "Entertainment Weekly\n",
            "American Idol\n",
            "Chicago Sun-Times\n",
            "Mystery Science Theater 3000\n",
            "Computer Gaming World\n",
            "Diagnostic and Statistical Manual of Mental Disorders\n",
            "--------------------------------\n",
            "TIME:\n",
            "Middle Ages\n",
            "Great Depression\n",
            "Renaissance\n",
            "Bronze Age\n",
            "Christmas\n",
            "half-life\n",
            "Neolithic\n",
            "puberty\n",
            "Iron Age\n",
            "Enlightenment\n",
            "--------------------------------\n",
            "EVE:\n",
            "World War II\n",
            "World War I\n",
            "American Civil War\n",
            "FA Cup\n",
            "Vietnam War\n",
            "French Revolution\n",
            "UEFA Champions League\n",
            "World Series\n",
            "Second World War\n",
            "American Revolutionary War\n",
            "--------------------------------\n",
            "ORG:\n",
            "European Union\n",
            "BBC\n",
            "New York Yankees\n",
            "Boston Red Sox\n",
            "Pittsburgh Pirates\n",
            "Chicago White Sox\n",
            "Chicago Cubs\n",
            "Los Angeles Dodgers\n",
            "ABC\n",
            "New York Mets\n",
            "--------------------------------\n",
            "PLANT:\n",
            "plant\n",
            "rice\n",
            "wheat\n",
            "shrub\n",
            "deciduous\n",
            "oak\n",
            "garlic\n",
            "cinnamon\n",
            "evergreen\n",
            "maize\n",
            "--------------------------------\n",
            "ANIM:\n",
            "moth\n",
            "sea snail\n",
            "Erebidae\n",
            "Noctuidae\n",
            "mine\n",
            "fish\n",
            "bird\n",
            "livestock\n",
            "ant\n",
            "cattle\n",
            "--------------------------------\n",
            "FOOD:\n",
            "sugar\n",
            "salt\n",
            "fruit\n",
            "milk\n",
            "beef\n",
            "pork\n",
            "flour\n",
            "honey\n",
            "butter\n",
            "food\n",
            "--------------------------------\n",
            "DIS:\n",
            "cancer\n",
            "anxiety\n",
            "tuberculosis\n",
            "schizophrenia\n",
            "Alzheimer 's disease\n",
            "obesity\n",
            "Parkinson 's disease\n",
            "asthma\n",
            "stroke\n",
            "diarrhea\n",
            "--------------------------------\n",
            "CEL:\n",
            "Earth\n",
            "Sun\n",
            "Jupiter\n",
            "Moon\n",
            "Mars\n",
            "Milky Way\n",
            "Venus\n",
            "white dwarf\n",
            "sun\n",
            "Earth 's\n",
            "--------------------------------\n",
            "SUPER:\n",
            "Thomas Aquinas\n",
            "Zeus\n",
            "Satan\n",
            "Ra\n",
            "Apollo\n",
            "Aphrodite\n",
            "John the Baptist\n",
            "Poseidon\n",
            "Athena\n",
            "Artemis\n",
            "--------------------------------\n",
            "VEHI:\n",
            "Airbus A380\n",
            "Titanic\n",
            "Boeing 747\n",
            "Ford Model T\n",
            "GE Dash 8 Series\n",
            "Mayflower\n",
            "Wright Flyer\n",
            "Porsche 911\n",
            "Eurofighter Typhoon\n",
            "EMD Dash 2\n",
            "--------------------------------\n",
            "INST:\n",
            "Android\n",
            "LaserDisc\n",
            "Voyager 1\n",
            "Voyager 2\n",
            "Laserdisc\n",
            "Apple II\n",
            "Super Nintendo Entertainment System\n",
            "Nintendo Switch\n",
            "AIM-9 Sidewinder\n",
            "Nasdaq\n",
            "--------------------------------\n",
            "PHY:\n",
            "2011 Tōhoku earthquake and tsunami\n",
            "Hillsborough disaster\n",
            "California Current\n",
            "Antarctic Circumpolar Current\n",
            "Agulhas Current\n",
            "Canary Current\n",
            "2004 Indian Ocean earthquake and tsunami\n",
            "Kuroshio Current\n",
            "Leeuwin Current\n",
            "Benguela Current\n",
            "--------------------------------\n",
            "BIO:\n",
            "Escherichia coli\n",
            "E. coli\n",
            "Plasmodium\n",
            "HIV\n",
            "Aspergillus\n",
            "Pseudomonas\n",
            "Salmonella\n",
            "Penicillium\n",
            "Streptococcus pneumoniae\n",
            "Agrobacterium\n",
            "--------------------------------\n"
          ]
        }
      ],
      "source": [
        "for entity in entities_names_multinerd:\n",
        "    print(f\"{entity}:\")\n",
        "    temp = ans[ans[\"Label\"] == entity][['Token']].value_counts()[:10].index.tolist()\n",
        "    for item in temp:\n",
        "        print(item[0])\n",
        "    print(\"--------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUZy9IdsH0K-"
      },
      "source": [
        "Выведем топ 10 популярных слов или словосочетаний для каждого вида сущностей в датасете litbank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xFIzXv9DXD9J"
      },
      "outputs": [],
      "source": [
        "litbank_entities = {}\n",
        "for entity in entities_ans:\n",
        "    temp = entities_ans[entity].most_common()[:10]\n",
        "    litbank_entities[entity] = list()\n",
        "    for item in temp:\n",
        "        litbank_entities[entity].append(item[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN3Wmp9SXD9J",
        "outputId": "b7a6edc4-9a46-4cfe-c94f-ed0b42ac41bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'PER': ['Mr.',\n",
              "  'Miss',\n",
              "  'Mrs.',\n",
              "  'sir',\n",
              "  'Sir',\n",
              "  'men',\n",
              "  'my mother',\n",
              "  'Cameron',\n",
              "  'Mr',\n",
              "  'his wife'],\n",
              " 'FAC': ['home',\n",
              "  'the house',\n",
              "  'here',\n",
              "  'there',\n",
              "  'the room',\n",
              "  'the garden',\n",
              "  'the street',\n",
              "  'the hall',\n",
              "  'the road',\n",
              "  'upstairs'],\n",
              " 'LOC': ['the world',\n",
              "  'the sea',\n",
              "  'the river',\n",
              "  'the country',\n",
              "  'there',\n",
              "  'sea',\n",
              "  'the earth',\n",
              "  'the valley',\n",
              "  'this world',\n",
              "  'the forest'],\n",
              " 'ORG': ['the army',\n",
              "  'the Church',\n",
              "  'the Colonial Office',\n",
              "  'the Committee of Public Safety',\n",
              "  'college',\n",
              "  'Harvard',\n",
              "  \"the Bank of Leichardt 's Land\",\n",
              "  'a regiment of regulars',\n",
              "  'the hospital',\n",
              "  'the C.C.H.'],\n",
              " 'GPE': ['London',\n",
              "  'England',\n",
              "  'the town',\n",
              "  'there',\n",
              "  'New York',\n",
              "  'France',\n",
              "  'town',\n",
              "  'Europe',\n",
              "  'Rome',\n",
              "  'the country'],\n",
              " 'VEH': ['the ship',\n",
              "  'the car',\n",
              "  'the train',\n",
              "  'boats',\n",
              "  'the boat',\n",
              "  'the Fuwalda',\n",
              "  'a carriage',\n",
              "  'ships',\n",
              "  'the carriage',\n",
              "  'the waggon']}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "litbank_entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjSdGohfyhPs",
        "outputId": "c507ba3e-e75d-4560-e335-0ccfbb7a85ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "ORG\n",
            "Litbank:\n",
            "['the army', 'the Church', 'the Colonial Office', 'the Committee of Public Safety', 'college', 'Harvard', \"the Bank of Leichardt 's Land\", 'a regiment of regulars', 'the hospital', 'the C.C.H.']\n",
            "Multinerd:\n",
            "['European Union', 'BBC', 'New York Yankees', 'Boston Red Sox', 'Pittsburgh Pirates', 'Chicago White Sox', 'Chicago Cubs', 'Los Angeles Dodgers', 'ABC', 'New York Mets']\n",
            "----------------------------\n",
            "LOC\n",
            "Litbank:\n",
            "['the world', 'the sea', 'the river', 'the country', 'there', 'sea', 'the earth', 'the valley', 'this world', 'the forest']\n",
            "Multinerd:\n",
            "['United States', 'Australia', 'United Kingdom', 'Brazil', 'China', 'India', 'Mexico', 'Japan', 'Canada', 'Ecuador']\n",
            "----------------------------\n",
            "PER\n",
            "Litbank:\n",
            "['Mr.', 'Miss', 'Mrs.', 'sir', 'Sir', 'men', 'my mother', 'Cameron', 'Mr', 'his wife']\n",
            "Multinerd:\n",
            "['George Hampson', 'Edward Meyrick', 'Breuning', 'Roger Ebert', 'Francis Walker', 'Aristotle', 'Barack Obama', 'Plato', 'Charles Darwin', 'George W. Bush']\n"
          ]
        }
      ],
      "source": [
        "for entity in list(set(litbank_entities) & set(entities_names_multinerd)):\n",
        "    print(\"----------------------------\")\n",
        "    print(entity)\n",
        "    print(\"Litbank:\")\n",
        "    print(litbank_entities[entity])\n",
        "    print(\"Multinerd:\")\n",
        "    temp = ans[ans[\"Label\"] == entity][['Token']].value_counts()[:10].index.tolist()\n",
        "    res = []\n",
        "    for item in temp:\n",
        "        res.append(item[0])\n",
        "    print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_-GO2L7XD9K"
      },
      "source": [
        "Сравнение: одинаковые сущности в разных датасетах трактуются по-разному. Видим что в датасете multinerd большую популярность среди сущностей персон(PER) и локаций(LOC) имеют имена собственные, нежели в датасете litbank."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwTv2wpLXD9K"
      },
      "source": [
        "#### Топ 10 частотных триггеров событий для корпуса Litbank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xQcRJrcsXD9K"
      },
      "outputs": [],
      "source": [
        "def count_events(path_to_folder):\n",
        "    cnt = Counter()\n",
        "\n",
        "    for filename in os.listdir(path_to_folder):\n",
        "        if filename.endswith(\".ann\"):\n",
        "            entities, relations, attributes, groups = get_entities_relations_attributes_groups(os.path.join(path_to_folder, filename))\n",
        "            for item in entities:\n",
        "                cnt[entities[item].text] += 1 \n",
        "\n",
        "    return cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-UtB23PXD9L",
        "outputId": "7773d61d-d2ac-4c50-d392-f032ef527f48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "said\n",
            "came\n",
            "looked\n",
            "went\n",
            "asked\n",
            "heard\n",
            "saw\n",
            "cried\n",
            "took\n",
            "turned\n"
          ]
        }
      ],
      "source": [
        "litbank_events = count_events(events_folder_path).most_common()[:10]\n",
        "for item in litbank_events:\n",
        "    print(item[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9gDjHs2XD9L",
        "outputId": "4787f60a-af45-4b13-cd43-937537f537e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "World War II\n",
            "World War I\n",
            "American Civil War\n",
            "FA Cup\n",
            "Vietnam War\n",
            "French Revolution\n",
            "UEFA Champions League\n",
            "World Series\n",
            "Second World War\n",
            "American Revolutionary War\n"
          ]
        }
      ],
      "source": [
        "temp = ans[ans[\"Label\"] == \"EVE\"][[\"Token\"]].value_counts()[:10].index.tolist()\n",
        "for item in temp:\n",
        "    print(item[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW82Vt3wXD9L"
      },
      "source": [
        "Сравневние: видим что тут тоже по-разному трактуется понятие event. В litbank это больше определяется по совершенному общему действию, а в multinerd это больше похоже на какое-то конкретное событие."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3HDR0W2XD9L"
      },
      "source": [
        "#### Кластеризация событий"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWrKFd0_XD9L"
      },
      "source": [
        "**litbank**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Gva0LbBXD9M",
        "outputId": "5298e1f9-ef81-4666-9e9f-111a2d38b50c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gensim==4.2.0\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 421 kB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (1.21.6)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim==4.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUvOVKPPXD9M",
        "outputId": "fb6e8ca3-1831-4748-9167-822c38549c84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader\n",
        "\n",
        "w2v = gensim.downloader.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "LgNDqTDdXD9M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "events = list(count_events(events_folder_path).keys())\n",
        "\n",
        "embedded = []\n",
        "presented_events = []\n",
        "for event in events:\n",
        "    if event in w2v:\n",
        "        presented_events.append(event)\n",
        "        embedded.append(w2v[event])\n",
        "embedded = np.array(embedded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "gl8VU6shXD9M"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "model = KMeans()\n",
        "model.fit(embedded)\n",
        "cluster_df = pd.DataFrame({\"event\" : presented_events, \"cluster\" : model.labels_})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP_tIXd_XD9M",
        "outputId": "1fe9bca4-0422-4574-dfad-d0893de8e260"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cluster 0 sample: melted skirted breakfasted showered trodden shot whirled sank dressed trod\n",
            "Cluster 1 sample: interposed reflected ticketed repelled visited wounded sampled expressed spent wrought\n",
            "Cluster 2 sample: fervid consternation desire interest disapproval impulse presentiment perplexity scandal thoughts\n",
            "Cluster 3 sample: relieving flocking sliding preparing making milking returning lifting cutting fleeing\n",
            "Cluster 4 sample: recognition song command fair dispute escapade blunder possession orders regard\n",
            "Cluster 5 sample: signalised flow recover stand secure rain bind still sweeping left\n",
            "Cluster 6 sample: hugging whistling barking groaning hushed mewing flickering coughing gasped glances\n",
            "Cluster 7 sample: deduce averred referring accept frowned infuriated recollect reassured expecting proud\n"
          ]
        }
      ],
      "source": [
        "for cluster in range(model.n_clusters):\n",
        "    print(f\"Cluster {cluster} sample:\", *cluster_df[cluster_df['cluster'] == cluster].sample(10)['event'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHjNGY8vXD9N"
      },
      "source": [
        "На первый взгляд выделяющихся кластеров для litbank нет."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMYxZfjbXD9N"
      },
      "source": [
        "**multinerd**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "UAXTpMvSXD9N"
      },
      "outputs": [],
      "source": [
        "events = ans[ans['Label'] == \"EVE\"]['Token'].values\n",
        "\n",
        "embedded = []\n",
        "presented_events = []\n",
        "for event in events:\n",
        "    if event in w2v:\n",
        "        presented_events.append(event)\n",
        "        embedded.append(w2v[event])\n",
        "embedded = np.array(embedded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "hWMdqZFVXD9O"
      },
      "outputs": [],
      "source": [
        "model = KMeans()\n",
        "model.fit(embedded)\n",
        "cluster_df = pd.DataFrame({\"event\" : presented_events, \"cluster\" : model.labels_})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS7ioMGoXD9O",
        "outputId": "b99c145e-a56c-476b-e1a8-96382f87496b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cluster 0 sample: EuroLeague Euroleague EuroLeague EuroLeague EuroLeague\n",
            "Cluster 1 sample: Olympic Olympics Olympic Olympics\n",
            "Cluster 2 sample: Superleague Superleague Superleague Superleague Superleague\n",
            "Cluster 3 sample: DTM Bundesliga Bundesliga\n",
            "Cluster 4 sample: First Brown Fes Masters Munster Finals Corunna Revolution\n",
            "Cluster 5 sample: Melodifestivalen\n",
            "Cluster 6 sample: WSOP\n",
            "Cluster 7 sample: Brasileirão Clausura\n"
          ]
        }
      ],
      "source": [
        "for cluster in range(model.n_clusters):\n",
        "    temp = cluster_df[cluster_df['cluster'] == cluster]\n",
        "    print(f\"Cluster {cluster} sample:\", *temp['event'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL_uAlV5XD9O"
      },
      "source": [
        "Для multinerd кластеры получились более разношерстными. В каких-то представлены различные лиги, в каких-то различные спортивные соревнования."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVC24tkEXD9O"
      },
      "source": [
        "**Визуализация кластеров**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOfU0XENXD9O",
        "outputId": "e32197cb-f2ab-4ef0-ddfe-5274bff3603f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "events = list(count_events(events_folder_path).keys())\n",
        "\n",
        "embedded = []\n",
        "presented_events = []\n",
        "for event in events:\n",
        "    if event in w2v:\n",
        "        presented_events.append(event)\n",
        "        embedded.append(w2v[event])\n",
        "embedded = np.array(embedded)\n",
        "\n",
        "model = KMeans()\n",
        "model.fit(embedded)\n",
        "cluster_df = pd.DataFrame({\"event\" : presented_events, \"cluster\" : model.labels_})\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=0)\n",
        "top_words_tsne = tsne.fit_transform(embedded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "sUNzrjbDXD9P"
      },
      "outputs": [],
      "source": [
        "colors = ['red', 'yellow', 'green', 'pink', 'black', 'gray', 'blue', 'brown']\n",
        "\n",
        "def to_colors(label):\n",
        "    return colors[label]\n",
        "\n",
        "to_colors = np.vectorize(to_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "61Q0Lo-FXD9P",
        "outputId": "16354bfd-32ab-408b-dbca-50b2bc8b23fc"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  var JS_MIME_TYPE = 'application/javascript';\n  var HTML_MIME_TYPE = 'text/html';\n  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  var CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    var script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    var cell = handle.cell;\n\n    var id = cell.output_area._bokeh_element_id;\n    var server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd, {\n        iopub: {\n          output: function(msg) {\n            var id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    var output_area = handle.output_area;\n    var output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      var bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      var script_attrs = bk_div.children[0].attributes;\n      for (var i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      var toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
            "application/vnd.bokehjs_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "  <div class=\"bk-root\" id=\"7a0c7475-d922-402f-9e56-3928608bbd93\" data-root-id=\"1002\"></div>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "(function(root) {\n  function embed_document(root) {\n    \n  var docs_json = {\"4eaaefec-10d8-4226-861a-5c5efddeca1b\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1013\"}],\"center\":[{\"id\":\"1016\"},{\"id\":\"1020\"},{\"id\":\"1036\"}],\"left\":[{\"id\":\"1017\"}],\"renderers\":[{\"id\":\"1034\"}],\"title\":{\"id\":\"1003\"},\"toolbar\":{\"id\":\"1025\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"1005\"},\"x_scale\":{\"id\":\"1009\"},\"y_range\":{\"id\":\"1007\"},\"y_scale\":{\"id\":\"1011\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"field\":\"color\"},\"size\":{\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1033\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1018\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1040\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{\"axis\":{\"id\":\"1017\"},\"dimension\":1,\"ticker\":null},\"id\":\"1020\",\"type\":\"Grid\"},{\"attributes\":{\"data_source\":{\"id\":\"1030\"},\"glyph\":{\"id\":\"1032\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1033\"},\"view\":{\"id\":\"1035\"}},\"id\":\"1034\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"formatter\":{\"id\":\"1040\"},\"major_label_policy\":{\"id\":\"1041\"},\"ticker\":{\"id\":\"1018\"}},\"id\":\"1017\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data\":{\"color\":[\"green\",\"brown\",\"green\",\"red\",\"brown\",\"red\",\"brown\",\"brown\",\"red\",\"black\",\"gray\",\"black\",\"black\",\"red\",\"gray\",\"red\",\"red\",\"gray\",\"red\",\"black\",\"green\",\"red\",\"gray\",\"black\",\"red\",\"black\",\"red\",\"yellow\",\"green\",\"brown\",\"gray\",\"pink\",\"brown\",\"black\",\"brown\",\"yellow\",\"pink\",\"pink\",\"red\",\"brown\",\"yellow\",\"red\",\"green\",\"yellow\",\"green\",\"gray\",\"gray\",\"gray\",\"gray\",\"green\",\"brown\",\"gray\",\"black\",\"brown\",\"yellow\",\"red\",\"black\",\"yellow\",\"gray\",\"green\",\"black\",\"brown\",\"green\",\"red\",\"black\",\"blue\",\"blue\",\"brown\",\"brown\",\"red\",\"red\",\"black\",\"black\",\"green\",\"yellow\",\"brown\",\"brown\",\"yellow\",\"yellow\",\"green\",\"black\",\"green\",\"pink\",\"gray\",\"red\",\"brown\",\"black\",\"brown\",\"brown\",\"red\",\"blue\",\"brown\",\"yellow\",\"brown\",\"brown\",\"green\",\"brown\",\"brown\",\"black\",\"black\",\"red\",\"brown\",\"brown\",\"yellow\",\"brown\",\"black\",\"gray\",\"green\",\"red\",\"red\",\"green\",\"black\",\"green\",\"yellow\",\"gray\",\"brown\",\"red\",\"brown\",\"brown\",\"yellow\",\"green\",\"gray\",\"brown\",\"brown\",\"black\",\"yellow\",\"red\",\"yellow\",\"black\",\"brown\",\"gray\",\"black\",\"pink\",\"red\",\"blue\",\"brown\",\"black\",\"black\",\"red\",\"black\",\"yellow\",\"gray\",\"red\",\"red\",\"gray\",\"gray\",\"brown\",\"yellow\",\"black\",\"green\",\"green\",\"green\",\"black\",\"red\",\"gray\",\"black\",\"gray\",\"blue\",\"black\",\"gray\",\"yellow\",\"blue\",\"gray\",\"pink\",\"red\",\"black\",\"gray\",\"brown\",\"blue\",\"green\",\"blue\",\"gray\",\"blue\",\"yellow\",\"red\",\"gray\",\"black\",\"pink\",\"brown\",\"black\",\"brown\",\"green\",\"black\",\"blue\",\"blue\",\"yellow\",\"yellow\",\"gray\",\"gray\",\"pink\",\"blue\",\"brown\",\"black\",\"black\",\"black\",\"black\",\"pink\",\"blue\",\"blue\",\"red\",\"gray\",\"brown\",\"yellow\",\"pink\",\"gray\",\"yellow\",\"gray\",\"yellow\",\"black\",\"black\",\"brown\",\"yellow\",\"yellow\",\"red\",\"green\",\"red\",\"brown\",\"yellow\",\"red\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"brown\",\"red\",\"red\",\"yellow\",\"red\",\"yellow\",\"green\",\"blue\",\"pink\",\"pink\",\"brown\",\"green\",\"yellow\",\"brown\",\"brown\",\"red\",\"yellow\",\"pink\",\"red\",\"yellow\",\"green\",\"brown\",\"black\",\"pink\",\"red\",\"red\",\"green\",\"gray\",\"pink\",\"brown\",\"pink\",\"green\",\"pink\",\"red\",\"black\",\"brown\",\"brown\",\"green\",\"gray\",\"brown\",\"red\",\"brown\",\"black\",\"black\",\"yellow\",\"pink\",\"red\",\"black\",\"green\",\"pink\",\"green\",\"brown\",\"brown\",\"gray\",\"brown\",\"yellow\",\"yellow\",\"yellow\",\"pink\",\"red\",\"red\",\"green\",\"red\",\"green\",\"black\",\"yellow\",\"brown\",\"gray\",\"red\",\"brown\",\"brown\",\"black\",\"black\",\"black\",\"black\",\"gray\",\"gray\",\"black\",\"pink\",\"brown\",\"gray\",\"pink\",\"yellow\",\"yellow\",\"yellow\",\"gray\",\"gray\",\"yellow\",\"gray\",\"brown\",\"red\",\"yellow\",\"brown\",\"red\",\"green\",\"blue\",\"brown\",\"brown\",\"gray\",\"red\",\"green\",\"blue\",\"green\",\"yellow\",\"red\",\"yellow\",\"black\",\"yellow\",\"yellow\",\"red\",\"red\",\"black\",\"green\",\"green\",\"red\",\"gray\",\"red\",\"red\",\"yellow\",\"green\",\"blue\",\"blue\",\"black\",\"black\",\"green\",\"red\",\"black\",\"gray\",\"brown\",\"green\",\"yellow\",\"blue\",\"blue\",\"green\",\"green\",\"green\",\"black\",\"red\",\"gray\",\"green\",\"green\",\"red\",\"brown\",\"red\",\"yellow\",\"black\",\"green\",\"red\",\"pink\",\"yellow\",\"green\",\"brown\",\"green\",\"gray\",\"yellow\",\"gray\",\"brown\",\"yellow\",\"red\",\"yellow\",\"gray\",\"red\",\"black\",\"brown\",\"green\",\"yellow\",\"green\",\"yellow\",\"green\",\"green\",\"red\",\"yellow\",\"brown\",\"green\",\"green\",\"red\",\"red\",\"yellow\",\"gray\",\"gray\",\"red\",\"red\",\"brown\",\"yellow\",\"yellow\",\"gray\",\"green\",\"gray\",\"black\",\"yellow\",\"black\",\"yellow\",\"yellow\",\"red\",\"brown\",\"gray\",\"black\",\"green\",\"green\",\"gray\",\"gray\",\"yellow\",\"gray\",\"blue\",\"pink\",\"gray\",\"yellow\",\"yellow\",\"brown\",\"red\",\"green\",\"red\",\"gray\",\"yellow\",\"red\",\"gray\",\"green\",\"black\",\"red\",\"black\",\"black\",\"yellow\",\"brown\",\"yellow\",\"red\",\"red\",\"pink\",\"green\",\"yellow\",\"red\",\"green\",\"red\",\"yellow\",\"green\",\"green\",\"gray\",\"pink\",\"red\",\"red\",\"green\",\"gray\",\"pink\",\"green\",\"yellow\",\"blue\",\"green\",\"red\",\"brown\",\"red\",\"blue\",\"red\",\"black\",\"brown\",\"green\",\"green\",\"brown\",\"red\",\"blue\",\"blue\",\"gray\",\"red\",\"pink\",\"green\",\"green\",\"black\",\"red\",\"green\",\"brown\",\"black\",\"black\",\"red\",\"red\",\"pink\",\"gray\",\"red\",\"black\",\"black\",\"green\",\"pink\",\"red\",\"pink\",\"green\",\"red\",\"yellow\",\"green\",\"green\",\"gray\",\"red\",\"pink\",\"black\",\"brown\",\"red\",\"gray\",\"pink\",\"brown\",\"red\",\"gray\",\"gray\",\"gray\",\"yellow\",\"green\",\"brown\",\"yellow\",\"brown\",\"gray\",\"pink\",\"green\",\"pink\",\"green\",\"brown\",\"yellow\",\"red\",\"black\",\"pink\",\"green\",\"gray\",\"gray\",\"gray\",\"brown\",\"gray\",\"pink\",\"red\",\"brown\",\"black\",\"brown\",\"blue\",\"yellow\",\"green\",\"yellow\",\"yellow\",\"red\",\"black\",\"red\",\"gray\",\"red\",\"gray\",\"red\",\"pink\",\"red\",\"red\",\"red\",\"red\",\"gray\",\"yellow\",\"black\",\"red\",\"red\",\"black\",\"yellow\",\"gray\",\"pink\",\"brown\",\"pink\",\"yellow\",\"pink\",\"yellow\",\"brown\",\"gray\",\"gray\",\"black\",\"black\",\"gray\",\"gray\",\"gray\",\"blue\",\"yellow\",\"gray\",\"red\",\"brown\",\"yellow\",\"red\",\"yellow\",\"pink\",\"red\",\"pink\",\"yellow\",\"blue\",\"brown\",\"red\",\"yellow\",\"brown\",\"pink\",\"red\",\"brown\",\"green\",\"yellow\",\"red\",\"gray\",\"red\",\"brown\",\"pink\",\"black\",\"black\",\"red\",\"red\",\"gray\",\"gray\",\"green\",\"brown\",\"blue\",\"brown\",\"green\",\"yellow\",\"red\",\"black\",\"yellow\",\"yellow\",\"gray\",\"green\",\"brown\",\"black\",\"pink\",\"yellow\",\"red\",\"green\",\"yellow\",\"red\",\"yellow\",\"red\",\"yellow\",\"yellow\",\"red\",\"pink\",\"pink\",\"blue\",\"red\",\"black\",\"black\",\"green\",\"green\",\"green\",\"green\",\"red\",\"green\",\"green\",\"black\",\"black\",\"red\",\"green\",\"green\",\"green\",\"black\",\"black\",\"green\",\"green\",\"red\",\"green\",\"black\",\"red\",\"yellow\",\"blue\",\"green\",\"green\",\"green\",\"black\",\"red\",\"green\",\"black\",\"brown\",\"yellow\",\"green\",\"gray\",\"yellow\",\"red\",\"green\",\"blue\",\"yellow\",\"red\",\"pink\",\"brown\",\"brown\",\"yellow\",\"brown\",\"brown\",\"red\",\"brown\",\"gray\",\"pink\",\"green\",\"pink\",\"black\",\"red\",\"black\",\"pink\",\"pink\",\"brown\",\"pink\",\"gray\",\"red\",\"red\",\"pink\",\"red\",\"red\",\"green\",\"yellow\",\"brown\",\"brown\",\"brown\",\"brown\",\"gray\",\"black\",\"red\",\"black\",\"green\",\"black\",\"black\",\"brown\",\"pink\",\"gray\",\"black\",\"brown\",\"red\",\"yellow\",\"red\",\"red\",\"red\",\"red\",\"yellow\",\"red\",\"red\",\"blue\",\"black\",\"red\",\"green\",\"yellow\",\"brown\",\"yellow\",\"pink\",\"gray\",\"yellow\",\"red\",\"red\",\"gray\",\"brown\",\"brown\",\"green\",\"yellow\",\"blue\",\"brown\",\"yellow\",\"yellow\",\"yellow\",\"brown\",\"red\",\"black\",\"red\",\"red\",\"black\",\"pink\",\"pink\",\"black\",\"black\",\"pink\",\"gray\",\"black\",\"brown\",\"black\",\"black\",\"pink\",\"black\",\"pink\",\"yellow\",\"brown\",\"gray\",\"pink\",\"gray\",\"green\",\"gray\",\"red\",\"brown\",\"brown\",\"red\",\"yellow\",\"yellow\",\"red\",\"yellow\",\"yellow\",\"red\",\"gray\",\"gray\",\"gray\",\"brown\",\"yellow\",\"brown\",\"brown\",\"yellow\",\"green\",\"yellow\",\"green\",\"green\",\"brown\",\"pink\",\"green\",\"black\",\"red\",\"brown\",\"red\",\"yellow\",\"red\",\"pink\",\"black\",\"brown\",\"green\",\"black\",\"red\",\"green\",\"yellow\",\"black\",\"blue\",\"pink\",\"green\",\"red\",\"red\",\"brown\",\"brown\",\"pink\",\"red\",\"yellow\",\"blue\",\"red\",\"brown\",\"yellow\",\"yellow\",\"yellow\",\"red\",\"gray\",\"yellow\",\"red\",\"gray\",\"red\",\"yellow\",\"gray\",\"gray\",\"gray\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"blue\",\"red\",\"red\",\"gray\",\"blue\",\"yellow\",\"yellow\",\"brown\",\"yellow\",\"black\",\"black\",\"black\",\"black\",\"red\",\"gray\",\"yellow\",\"brown\",\"green\",\"yellow\",\"red\",\"green\",\"yellow\",\"gray\",\"black\",\"yellow\",\"brown\",\"yellow\",\"red\",\"brown\",\"black\",\"brown\",\"yellow\",\"yellow\",\"yellow\",\"black\",\"yellow\",\"gray\",\"black\",\"black\",\"brown\",\"brown\",\"black\",\"black\",\"red\",\"green\",\"brown\",\"gray\",\"red\",\"gray\",\"red\",\"green\",\"black\",\"blue\",\"black\",\"black\",\"black\",\"pink\",\"pink\",\"red\",\"gray\",\"gray\",\"gray\",\"black\",\"black\",\"pink\",\"black\",\"green\",\"green\",\"brown\",\"blue\",\"yellow\",\"brown\",\"green\",\"red\",\"green\",\"red\",\"pink\",\"black\",\"yellow\",\"red\",\"black\",\"gray\",\"gray\",\"gray\",\"pink\",\"gray\",\"brown\",\"gray\",\"black\",\"black\",\"black\",\"gray\",\"yellow\",\"pink\",\"green\",\"red\",\"brown\",\"brown\",\"black\",\"black\",\"blue\",\"red\",\"brown\",\"green\",\"blue\",\"brown\",\"green\",\"brown\",\"blue\",\"gray\",\"red\",\"blue\",\"blue\",\"brown\",\"blue\",\"red\",\"red\",\"gray\",\"yellow\",\"red\",\"green\",\"blue\",\"brown\",\"black\",\"brown\",\"gray\",\"red\",\"blue\",\"brown\",\"red\",\"brown\",\"black\",\"pink\",\"yellow\",\"yellow\",\"gray\",\"black\",\"gray\",\"yellow\",\"red\",\"gray\",\"brown\",\"gray\",\"black\",\"black\",\"black\",\"brown\",\"red\",\"brown\",\"gray\",\"red\",\"black\",\"black\",\"pink\",\"blue\",\"pink\",\"brown\",\"brown\",\"green\",\"pink\",\"blue\",\"pink\",\"brown\",\"gray\",\"gray\",\"gray\",\"pink\",\"brown\",\"pink\",\"red\",\"pink\",\"gray\",\"green\",\"pink\",\"black\",\"pink\",\"pink\",\"yellow\",\"pink\",\"black\",\"gray\",\"green\",\"green\",\"yellow\",\"yellow\",\"red\",\"red\",\"brown\",\"pink\",\"brown\",\"brown\",\"gray\",\"red\",\"green\",\"gray\",\"red\",\"blue\",\"brown\",\"gray\",\"red\",\"yellow\",\"brown\",\"gray\",\"yellow\",\"brown\",\"blue\",\"gray\",\"yellow\",\"gray\",\"brown\",\"yellow\",\"green\",\"black\",\"red\",\"green\",\"black\",\"green\",\"red\",\"black\",\"green\",\"green\",\"red\",\"red\",\"red\",\"green\",\"brown\",\"green\",\"yellow\",\"brown\",\"brown\",\"yellow\",\"blue\",\"brown\",\"green\",\"brown\",\"green\",\"black\",\"black\",\"black\",\"black\",\"blue\",\"gray\",\"gray\",\"gray\",\"red\",\"green\",\"yellow\",\"black\",\"red\",\"yellow\",\"red\",\"black\",\"red\",\"black\",\"yellow\",\"pink\",\"yellow\",\"yellow\",\"red\",\"blue\",\"green\",\"gray\",\"brown\",\"brown\",\"pink\",\"gray\",\"gray\",\"red\",\"gray\",\"gray\",\"red\",\"gray\",\"blue\",\"blue\",\"brown\",\"yellow\",\"red\",\"blue\",\"yellow\",\"blue\",\"brown\",\"red\",\"gray\",\"gray\",\"green\",\"gray\",\"gray\",\"red\",\"yellow\",\"red\",\"gray\",\"gray\",\"brown\",\"green\",\"red\",\"yellow\",\"yellow\",\"yellow\",\"red\",\"pink\",\"green\",\"red\",\"yellow\",\"gray\",\"gray\",\"red\",\"red\",\"brown\",\"gray\",\"blue\",\"yellow\",\"red\",\"yellow\",\"gray\",\"black\",\"yellow\",\"red\",\"green\",\"red\",\"blue\",\"blue\",\"red\",\"red\",\"red\",\"red\",\"red\",\"yellow\",\"red\",\"red\",\"yellow\",\"black\",\"red\",\"red\",\"gray\",\"black\",\"green\",\"blue\",\"red\",\"blue\",\"green\",\"red\",\"blue\",\"red\",\"brown\",\"red\",\"brown\",\"gray\",\"red\",\"gray\",\"red\",\"pink\",\"pink\",\"red\",\"brown\",\"yellow\",\"red\",\"red\",\"red\",\"yellow\",\"red\",\"green\",\"black\",\"red\",\"yellow\",\"brown\",\"gray\",\"blue\",\"brown\",\"gray\",\"red\",\"yellow\",\"gray\",\"gray\",\"brown\",\"red\",\"brown\",\"green\",\"red\",\"red\",\"brown\",\"brown\",\"black\",\"blue\",\"black\",\"blue\",\"black\",\"yellow\",\"green\",\"blue\",\"red\",\"gray\",\"green\",\"yellow\",\"brown\",\"red\",\"red\",\"green\",\"blue\",\"red\",\"gray\",\"red\",\"gray\",\"yellow\",\"red\",\"yellow\",\"green\",\"red\",\"green\",\"red\",\"gray\",\"red\",\"yellow\",\"blue\",\"blue\",\"blue\",\"green\",\"gray\",\"green\",\"red\",\"red\",\"gray\",\"green\",\"yellow\",\"brown\",\"red\",\"gray\",\"blue\",\"gray\",\"gray\",\"brown\",\"gray\",\"blue\",\"red\",\"red\",\"red\",\"gray\",\"gray\",\"red\",\"red\",\"black\",\"brown\",\"red\",\"red\",\"yellow\",\"brown\",\"black\",\"gray\",\"pink\",\"black\",\"yellow\",\"gray\",\"red\",\"gray\",\"black\",\"black\",\"black\",\"red\",\"green\",\"black\",\"gray\",\"green\",\"brown\",\"black\",\"yellow\",\"black\",\"gray\",\"green\",\"green\",\"black\",\"black\",\"black\",\"yellow\",\"black\",\"black\",\"gray\",\"brown\",\"red\",\"pink\",\"gray\",\"green\",\"yellow\",\"black\",\"brown\",\"green\",\"green\",\"green\",\"red\",\"green\",\"pink\",\"red\",\"green\",\"yellow\",\"pink\",\"green\",\"gray\",\"red\",\"black\",\"green\",\"pink\",\"green\",\"gray\",\"gray\",\"red\",\"red\",\"gray\",\"black\",\"gray\",\"red\",\"red\",\"red\",\"yellow\",\"yellow\",\"red\",\"red\",\"red\",\"blue\",\"gray\",\"gray\",\"red\",\"blue\",\"black\",\"red\",\"green\",\"red\",\"black\",\"gray\",\"red\",\"red\",\"red\",\"red\",\"red\",\"brown\",\"red\",\"gray\",\"green\",\"blue\",\"brown\",\"yellow\",\"yellow\",\"yellow\",\"gray\",\"red\",\"gray\",\"red\",\"red\",\"green\",\"yellow\",\"pink\",\"black\",\"black\",\"black\",\"pink\",\"green\",\"gray\",\"pink\",\"brown\",\"red\",\"green\",\"red\",\"black\",\"green\",\"gray\",\"yellow\",\"blue\",\"red\",\"red\",\"blue\",\"red\",\"black\",\"red\",\"brown\",\"black\",\"red\",\"yellow\",\"black\",\"black\",\"black\",\"red\",\"red\",\"yellow\",\"yellow\",\"pink\",\"gray\",\"brown\",\"pink\",\"pink\",\"red\",\"pink\",\"yellow\",\"red\",\"yellow\",\"yellow\",\"red\",\"black\",\"brown\",\"green\",\"gray\",\"green\",\"red\",\"pink\",\"pink\",\"yellow\",\"gray\",\"yellow\",\"pink\",\"brown\",\"gray\",\"red\",\"black\",\"pink\",\"black\",\"red\",\"black\",\"brown\",\"gray\",\"brown\",\"black\",\"red\",\"red\",\"brown\",\"gray\",\"black\",\"brown\",\"green\",\"brown\",\"pink\",\"green\",\"gray\",\"blue\",\"green\",\"red\",\"blue\",\"gray\",\"black\",\"black\",\"green\",\"yellow\",\"black\",\"black\",\"gray\",\"yellow\",\"brown\",\"pink\",\"black\",\"green\",\"blue\",\"blue\",\"yellow\",\"pink\",\"gray\",\"black\",\"gray\",\"red\",\"black\",\"red\",\"yellow\",\"black\",\"yellow\",\"blue\",\"blue\",\"red\",\"brown\",\"pink\",\"black\",\"yellow\",\"red\",\"pink\",\"red\",\"yellow\",\"pink\",\"red\",\"gray\",\"green\",\"yellow\",\"red\",\"pink\",\"red\",\"blue\",\"black\",\"green\",\"red\",\"red\",\"brown\",\"pink\",\"green\",\"brown\",\"black\",\"blue\",\"red\",\"brown\",\"gray\",\"gray\",\"gray\",\"green\",\"yellow\",\"black\",\"red\",\"red\",\"gray\",\"red\",\"brown\",\"brown\",\"black\",\"pink\",\"brown\",\"red\",\"gray\",\"green\",\"red\",\"gray\",\"blue\",\"brown\",\"blue\",\"green\",\"red\",\"gray\",\"gray\",\"black\",\"red\",\"yellow\",\"pink\",\"yellow\",\"red\",\"green\",\"black\",\"blue\",\"black\",\"red\",\"red\",\"gray\",\"red\",\"red\",\"yellow\",\"brown\",\"black\",\"black\",\"green\",\"blue\",\"black\",\"red\",\"red\",\"gray\",\"green\",\"yellow\",\"yellow\",\"red\",\"gray\",\"blue\",\"brown\",\"black\",\"black\",\"green\",\"black\",\"green\",\"brown\",\"green\",\"green\",\"black\",\"yellow\",\"brown\",\"green\",\"red\",\"red\",\"blue\",\"yellow\",\"red\",\"black\",\"pink\",\"green\",\"brown\",\"red\",\"red\",\"red\",\"green\",\"red\",\"green\",\"red\",\"yellow\",\"gray\",\"black\",\"red\",\"black\",\"yellow\",\"red\",\"brown\",\"gray\",\"red\",\"red\",\"red\",\"yellow\",\"yellow\",\"green\",\"red\",\"blue\",\"red\",\"red\",\"red\",\"pink\",\"black\",\"green\",\"green\",\"yellow\",\"red\",\"green\",\"gray\",\"black\",\"green\",\"yellow\",\"brown\",\"green\",\"red\",\"green\",\"pink\",\"yellow\",\"gray\",\"red\",\"green\",\"red\",\"blue\",\"red\",\"red\",\"gray\",\"red\",\"yellow\",\"yellow\",\"yellow\",\"green\",\"red\",\"blue\",\"brown\",\"red\",\"red\",\"red\",\"yellow\",\"blue\",\"red\",\"red\",\"gray\",\"pink\",\"blue\",\"yellow\",\"yellow\",\"green\",\"green\",\"red\",\"blue\",\"red\",\"green\",\"brown\",\"green\",\"yellow\",\"red\",\"red\",\"brown\",\"black\",\"green\",\"green\",\"red\",\"red\",\"green\",\"yellow\",\"black\",\"pink\",\"yellow\",\"gray\",\"brown\",\"red\",\"red\",\"black\",\"red\",\"gray\",\"black\",\"blue\",\"red\",\"green\",\"black\",\"red\",\"brown\",\"gray\",\"gray\",\"red\",\"gray\",\"red\",\"gray\",\"green\",\"black\",\"brown\",\"black\",\"gray\",\"black\",\"black\",\"brown\",\"black\",\"black\",\"gray\",\"black\",\"black\",\"red\",\"red\",\"green\",\"red\",\"red\",\"red\",\"red\",\"brown\",\"gray\",\"black\",\"brown\",\"green\",\"red\",\"yellow\",\"green\",\"black\",\"red\",\"brown\",\"red\",\"red\",\"red\",\"red\",\"brown\",\"yellow\",\"gray\",\"black\",\"gray\",\"black\",\"gray\",\"red\",\"green\",\"black\",\"black\",\"yellow\",\"yellow\",\"red\",\"yellow\",\"black\",\"black\",\"gray\",\"gray\",\"red\",\"yellow\",\"brown\",\"pink\",\"red\",\"yellow\",\"gray\",\"pink\",\"pink\",\"yellow\",\"green\",\"gray\",\"black\",\"red\",\"gray\",\"yellow\",\"blue\",\"black\",\"black\",\"black\",\"red\",\"red\",\"red\",\"green\",\"green\",\"green\",\"black\",\"black\",\"yellow\",\"green\",\"red\",\"pink\",\"brown\",\"red\",\"black\",\"black\",\"green\",\"gray\",\"blue\",\"brown\",\"red\",\"red\",\"yellow\",\"yellow\",\"green\",\"yellow\",\"red\",\"brown\",\"black\",\"green\",\"yellow\",\"brown\",\"red\",\"black\",\"green\",\"red\",\"green\",\"blue\",\"blue\",\"gray\",\"blue\",\"green\",\"red\",\"yellow\",\"red\",\"red\",\"red\",\"yellow\",\"black\",\"brown\",\"red\",\"blue\",\"brown\",\"green\",\"red\",\"yellow\",\"gray\",\"gray\",\"blue\",\"black\",\"brown\",\"red\",\"pink\",\"green\",\"gray\",\"gray\",\"black\",\"brown\",\"brown\",\"pink\",\"blue\",\"red\",\"yellow\",\"red\",\"yellow\",\"gray\",\"red\",\"pink\",\"gray\",\"red\",\"green\",\"red\",\"red\",\"black\",\"red\",\"red\",\"green\",\"gray\",\"pink\",\"black\",\"blue\",\"gray\",\"red\",\"gray\",\"yellow\",\"gray\",\"black\",\"red\",\"red\",\"brown\",\"black\",\"black\",\"yellow\",\"blue\",\"yellow\",\"gray\",\"blue\",\"brown\",\"brown\",\"black\",\"black\",\"pink\",\"green\",\"green\",\"gray\",\"green\",\"gray\",\"green\",\"pink\",\"green\",\"red\",\"gray\",\"red\",\"black\",\"pink\",\"green\",\"red\",\"brown\",\"black\",\"black\",\"red\",\"blue\",\"brown\",\"green\",\"black\",\"green\",\"red\",\"green\",\"green\",\"pink\",\"green\",\"black\",\"green\",\"black\",\"pink\",\"black\",\"black\",\"red\",\"black\",\"black\",\"pink\",\"red\",\"brown\",\"red\",\"yellow\",\"red\",\"green\",\"red\",\"black\",\"black\",\"brown\",\"pink\",\"gray\",\"black\",\"black\",\"black\",\"red\",\"brown\",\"red\",\"green\",\"yellow\",\"brown\",\"gray\",\"red\",\"green\",\"gray\",\"red\",\"gray\",\"green\",\"red\",\"black\",\"brown\",\"green\",\"blue\",\"yellow\",\"red\",\"red\",\"blue\",\"red\",\"red\",\"gray\",\"black\",\"gray\",\"black\",\"green\",\"red\",\"pink\",\"blue\",\"black\",\"pink\",\"red\",\"brown\",\"yellow\",\"yellow\",\"brown\",\"yellow\",\"yellow\",\"gray\",\"yellow\",\"blue\",\"red\",\"red\",\"yellow\",\"red\",\"yellow\",\"yellow\",\"red\",\"yellow\",\"blue\",\"red\",\"red\",\"red\",\"red\",\"black\",\"red\",\"brown\",\"black\",\"red\",\"brown\",\"red\",\"red\",\"green\",\"red\",\"red\",\"red\",\"pink\",\"blue\",\"red\",\"green\",\"red\",\"green\",\"green\",\"green\",\"green\",\"blue\",\"blue\",\"brown\",\"yellow\",\"black\",\"brown\",\"black\",\"black\",\"brown\",\"green\",\"yellow\",\"brown\",\"brown\",\"black\",\"brown\",\"red\",\"red\",\"brown\",\"green\",\"gray\",\"blue\",\"brown\",\"gray\",\"gray\",\"yellow\",\"black\",\"brown\",\"black\",\"black\",\"yellow\",\"yellow\",\"red\",\"green\",\"green\",\"gray\",\"red\",\"brown\",\"brown\",\"brown\",\"yellow\",\"gray\",\"yellow\",\"red\",\"green\",\"black\",\"red\",\"blue\",\"red\",\"brown\",\"green\",\"pink\",\"black\",\"black\",\"gray\",\"black\",\"pink\",\"blue\",\"pink\",\"black\",\"brown\",\"green\",\"brown\",\"green\",\"brown\",\"brown\",\"black\",\"yellow\",\"red\",\"red\",\"gray\",\"green\",\"black\",\"red\",\"red\",\"red\",\"black\",\"red\",\"red\",\"black\",\"red\",\"yellow\",\"red\",\"black\",\"pink\",\"red\",\"brown\",\"green\",\"black\",\"yellow\",\"green\",\"green\",\"red\",\"red\",\"green\",\"yellow\",\"red\",\"brown\",\"yellow\",\"red\",\"yellow\",\"brown\",\"black\",\"red\",\"green\",\"red\",\"red\",\"red\",\"gray\",\"yellow\",\"red\",\"yellow\",\"yellow\",\"black\",\"black\",\"green\",\"yellow\",\"brown\",\"green\",\"blue\",\"blue\",\"green\",\"red\",\"red\",\"gray\",\"black\",\"red\",\"yellow\",\"yellow\",\"red\",\"gray\",\"yellow\",\"blue\",\"brown\",\"red\",\"black\",\"red\",\"brown\",\"black\",\"black\",\"blue\",\"yellow\",\"brown\",\"green\",\"red\",\"green\",\"yellow\",\"green\",\"black\",\"black\",\"red\",\"blue\",\"black\",\"black\",\"brown\",\"gray\",\"red\",\"yellow\",\"red\",\"yellow\",\"green\",\"red\",\"yellow\",\"yellow\",\"green\",\"red\",\"red\",\"red\",\"gray\",\"green\",\"brown\",\"yellow\",\"yellow\",\"brown\",\"brown\",\"black\",\"black\",\"black\",\"black\",\"green\",\"black\",\"brown\",\"black\",\"green\",\"black\",\"yellow\",\"yellow\",\"red\",\"yellow\",\"gray\",\"red\",\"red\",\"yellow\",\"red\",\"black\",\"black\",\"blue\",\"black\",\"yellow\",\"brown\",\"pink\",\"green\",\"black\",\"red\",\"black\",\"black\",\"black\",\"red\",\"gray\",\"black\",\"green\",\"black\",\"red\",\"brown\",\"red\",\"red\",\"blue\",\"blue\",\"blue\",\"red\",\"red\",\"black\",\"blue\",\"yellow\",\"yellow\",\"black\",\"black\",\"red\",\"black\",\"black\",\"gray\",\"green\",\"gray\",\"gray\",\"brown\",\"red\",\"pink\",\"pink\",\"green\",\"red\",\"yellow\",\"black\",\"red\",\"red\",\"gray\",\"brown\",\"red\",\"brown\",\"red\",\"gray\",\"red\",\"red\",\"brown\",\"yellow\",\"red\",\"yellow\",\"black\",\"brown\",\"brown\",\"gray\",\"red\",\"green\",\"brown\",\"red\",\"red\",\"brown\",\"black\",\"red\",\"green\",\"red\",\"red\",\"gray\",\"red\",\"yellow\",\"red\",\"yellow\",\"red\",\"red\",\"red\",\"yellow\",\"red\",\"pink\",\"red\",\"red\",\"gray\",\"blue\",\"yellow\",\"blue\",\"yellow\",\"red\",\"black\",\"red\",\"black\",\"green\",\"black\",\"blue\",\"red\",\"pink\",\"red\",\"yellow\",\"pink\",\"gray\",\"red\",\"red\",\"red\",\"brown\",\"yellow\",\"blue\",\"yellow\",\"gray\",\"red\",\"red\",\"red\",\"yellow\",\"black\",\"green\",\"brown\",\"blue\",\"red\",\"red\",\"pink\",\"green\",\"green\",\"green\",\"red\",\"red\",\"black\",\"blue\",\"red\",\"pink\",\"black\",\"yellow\",\"black\",\"red\",\"brown\",\"brown\",\"red\",\"blue\",\"red\",\"yellow\",\"red\",\"black\",\"blue\",\"pink\",\"red\",\"red\",\"green\",\"yellow\",\"red\",\"yellow\",\"brown\",\"yellow\",\"yellow\",\"green\",\"red\",\"green\",\"black\",\"brown\",\"black\",\"black\",\"red\",\"gray\",\"red\",\"brown\",\"brown\",\"green\",\"red\",\"brown\",\"green\",\"brown\",\"red\",\"red\",\"green\",\"brown\",\"pink\",\"black\",\"brown\",\"black\",\"brown\",\"red\",\"yellow\",\"brown\",\"green\",\"green\",\"green\",\"gray\",\"gray\",\"yellow\",\"brown\",\"green\",\"brown\",\"pink\",\"red\",\"green\",\"black\",\"brown\",\"red\",\"black\",\"brown\",\"brown\",\"brown\",\"gray\",\"black\",\"black\",\"green\",\"black\",\"red\",\"gray\",\"yellow\",\"red\",\"gray\",\"black\",\"green\",\"red\",\"black\",\"brown\",\"red\",\"brown\",\"green\",\"brown\",\"red\",\"black\",\"brown\",\"black\",\"yellow\",\"brown\",\"blue\",\"red\",\"brown\",\"green\",\"red\",\"red\",\"red\",\"gray\",\"black\",\"black\",\"brown\",\"brown\",\"gray\",\"brown\",\"yellow\",\"blue\",\"blue\",\"black\",\"yellow\",\"gray\",\"gray\",\"green\",\"red\",\"blue\",\"red\",\"green\",\"yellow\",\"green\",\"red\",\"green\",\"green\",\"green\",\"blue\",\"red\",\"red\",\"red\",\"black\",\"black\",\"red\",\"yellow\",\"red\",\"red\",\"black\",\"red\",\"red\",\"red\",\"green\",\"black\",\"black\",\"green\"],\"names\":[\"writing\",\"looked\",\"watching\",\"come\",\"walked\",\"see\",\"went\",\"came\",\"cut\",\"smelling\",\"heard\",\"noise\",\"sneezing\",\"stop\",\"hear\",\"comes\",\"exercises\",\"says\",\"goes\",\"reappears\",\"looking\",\"inflict\",\"said\",\"amuse\",\"watch\",\"gong\",\"keep\",\"folded\",\"setting\",\"knocked\",\"did\",\"glanced\",\"pushed\",\"hush\",\"opened\",\"met\",\"waved\",\"laughed\",\"expedition\",\"crossed\",\"seen\",\"wasted\",\"eating\",\"taken\",\"stopping\",\"liked\",\"insisting\",\"ask\",\"asked\",\"put\",\"broke\",\"listened\",\"sounds\",\"picked\",\"ruined\",\"restoration\",\"sight\",\"prevented\",\"remember\",\"kicking\",\"whinnied\",\"jumped\",\"catching\",\"box\",\"roar\",\"pain\",\"surprise\",\"saw\",\"trotted\",\"chase\",\"circumstance\",\"frost\",\"mist\",\"feeding\",\"raised\",\"pricked\",\"cantered\",\"followed\",\"found\",\"tearing\",\"voices\",\"galloping\",\"snorted\",\"wanted\",\"away\",\"left\",\"barking\",\"ran\",\"lost\",\"straight\",\"fright\",\"rushed\",\"made\",\"burst\",\"leaped\",\"dashing\",\"tried\",\"turned\",\"cries\",\"shriek\",\"end\",\"rode\",\"whipped\",\"held\",\"torn\",\"bleeding\",\"astonished\",\"going\",\"look\",\"down\",\"struggling\",\"groaning\",\"getting\",\"covered\",\"saying\",\"gone\",\"raise\",\"fell\",\"hung\",\"carried\",\"riding\",\"felt\",\"shook\",\"broken\",\"bang\",\"won\",\"still\",\"suspected\",\"asleep\",\"struck\",\"talking\",\"drowsy\",\"whispered\",\"pause\",\"buzz\",\"rolled\",\"nap\",\"brood\",\"change\",\"brooding\",\"separated\",\"thought\",\"conversation\",\"dining\",\"invited\",\"objected\",\"gave\",\"ordered\",\"contented\",\"leaning\",\"playing\",\"enjoying\",\"mots\",\"dinner\",\"agreeable\",\"staid\",\"overheard\",\"feeling\",\"whisper\",\"expressed\",\"given\",\"presentiment\",\"urged\",\"sighed\",\"engagement\",\"glow\",\"pretended\",\"coaxed\",\"pleasure\",\"marrying\",\"words\",\"replied\",\"interest\",\"married\",\"set\",\"refuse\",\"voice\",\"cried\",\"sank\",\"exertion\",\"stepped\",\"receiving\",\"bark\",\"pity\",\"grumbling\",\"exhibited\",\"brought\",\"remembered\",\"recollected\",\"tears\",\"grief\",\"hid\",\"bidden\",\"quietly\",\"sleeping\",\"hushed\",\"sobs\",\"fear\",\"regret\",\"idea\",\"familiar\",\"dropped\",\"introduced\",\"danced\",\"recommending\",\"submitted\",\"promised\",\"planted\",\"imitation\",\"watered\",\"caught\",\"presented\",\"sent\",\"catastrophe\",\"settling\",\"accident\",\"died\",\"assembled\",\"settlement\",\"marked\",\"borne\",\"occupied\",\"fastened\",\"shone\",\"sentence\",\"scandal\",\"added\",\"warrant\",\"interposed\",\"holding\",\"shame\",\"exclaimed\",\"flung\",\"appeared\",\"Stretching\",\"laid\",\"drew\",\"repelled\",\"action\",\"bore\",\"winked\",\"acquaintance\",\"revealed\",\"judging\",\"took\",\"blush\",\"smile\",\"glance\",\"effect\",\"coming\",\"told\",\"sang\",\"played\",\"clapped\",\"swarming\",\"shouting\",\"charge\",\"thud\",\"flew\",\"kept\",\"feigning\",\"answered\",\"crept\",\"runs\",\"shaken\",\"fluttering\",\"breeze\",\"driven\",\"waving\",\"scrimmage\",\"flashing\",\"bent\",\"rubbing\",\"stamping\",\"dodged\",\"stopped\",\"wondered\",\"thrown\",\"called\",\"shown\",\"buried\",\"shivered\",\"shoulder\",\"jump\",\"sitting\",\"fire\",\"waiting\",\"smell\",\"taught\",\"closed\",\"glad\",\"go\",\"washed\",\"pulled\",\"sound\",\"cold\",\"hot\",\"chilled\",\"wrote\",\"confused\",\"flutter\",\"laughing\",\"cracked\",\"thinking\",\"fluttered\",\"worked\",\"passed\",\"located\",\"stated\",\"decided\",\"determined\",\"agreed\",\"packed\",\"bidding\",\"mounted\",\"started\",\"departure\",\"picking\",\"glimpses\",\"topped\",\"entered\",\"surprised\",\"note\",\"arming\",\"suspense\",\"strapped\",\"reached\",\"continued\",\"discovered\",\"darkness\",\"forced\",\"await\",\"following\",\"walk\",\"trot\",\"finding\",\"pursuing\",\"positive\",\"hoping\",\"report\",\"shots\",\"forged\",\"entering\",\"consternation\",\"dismay\",\"riveted\",\"narration\",\"charging\",\"shooting\",\"whooping\",\"convinced\",\"fled\",\"routing\",\"disclosed\",\"apprehension\",\"rage\",\"Riding\",\"grasping\",\"putting\",\"dash\",\"distinguish\",\"mentioned\",\"knocking\",\"learning\",\"breakfast\",\"finished\",\"drinking\",\"served\",\"lit\",\"walking\",\"thrust\",\"paused\",\"selected\",\"depositing\",\"poked\",\"pronouncing\",\"perceived\",\"counted\",\"amused\",\"rejoined\",\"pursued\",\"reply\",\"declared\",\"thanked\",\"compliment\",\"astride\",\"attacked\",\"advancing\",\"drawn\",\"straightening\",\"converted\",\"springing\",\"scattering\",\"announcement\",\"observed\",\"got\",\"throwing\",\"standing\",\"hearing\",\"observation\",\"bought\",\"responded\",\"speak\",\"death\",\"loss\",\"resumed\",\"abducted\",\"discharged\",\"pleaded\",\"approaching\",\"pressed\",\"shudder\",\"detected\",\"darkened\",\"showed\",\"interrupted\",\"protest\",\"brightened\",\"demanded\",\"accents\",\"sinking\",\"rising\",\"protested\",\"wish\",\"belied\",\"say\",\"sigh\",\"muttered\",\"tired\",\"supported\",\"assisted\",\"returned\",\"desirable\",\"leading\",\"gesture\",\"declined\",\"proffered\",\"bit\",\"aloof\",\"making\",\"wandering\",\"wind\",\"clouds\",\"rain\",\"dispensed\",\"slipped\",\"possessed\",\"care\",\"gathering\",\"sat\",\"turning\",\"studied\",\"cloud\",\"sweeping\",\"blast\",\"formed\",\"surveying\",\"calling\",\"wished\",\"trembled\",\"answer\",\"seating\",\"thrusting\",\"mused\",\"tottered\",\"regaining\",\"retired\",\"impudence\",\"answering\",\"reading\",\"fetched\",\"lift\",\"poise\",\"stand\",\"cry\",\"hit\",\"striking\",\"cutting\",\"bled\",\"terror\",\"climax\",\"feelings\",\"intimated\",\"sharp\",\"glancing\",\"pinning\",\"repeating\",\"exclamation\",\"Seating\",\"quitting\",\"withdrew\",\"whistling\",\"bustling\",\"orders\",\"directions\",\"crinkled\",\"telling\",\"mass\",\"croquet\",\"smoke\",\"drag\",\"gaze\",\"approach\",\"seated\",\"facing\",\"plunge\",\"surveyed\",\"drawing\",\"Looking\",\"reminded\",\"understanding\",\"clasping\",\"laugh\",\"sparkled\",\"adventure\",\"realized\",\"yawned\",\"stretched\",\"proposed\",\"admitted\",\"instructed\",\"prepared\",\"accepted\",\"lifting\",\"descended\",\"halted\",\"shrugged\",\"understood\",\"nodding\",\"starting\",\"kissed\",\"saving\",\"gathered\",\"reflected\",\"fan\",\"puffs\",\"chatted\",\"performing\",\"talked\",\"spoke\",\"read\",\"disappeared\",\"supposed\",\"strolled\",\"entrance\",\"awoke\",\"undressed\",\"piled\",\"utterances\",\"arose\",\"leaving\",\"assumed\",\"engaged\",\"wedding\",\"sleep\",\"sit\",\"think\",\"event\",\"recalled\",\"marriage\",\"smiled\",\"maintain\",\"exertions\",\"flow\",\"ideas\",\"hoped\",\"placed\",\"animated\",\"inquiries\",\"call\",\"nestled\",\"awakened\",\"happy\",\"cuddled\",\"stood\",\"sob\",\"handed\",\"sobbed\",\"ceased\",\"lifted\",\"guessed\",\"approached\",\"pulse\",\"shake\",\"hesitated\",\"forgot\",\"ready\",\"emotion\",\"deprived\",\"anxious\",\"opportunity\",\"limped\",\"changed\",\"opening\",\"disengaged\",\"bade\",\"permission\",\"crying\",\"enjoyed\",\"sensation\",\"waited\",\"funeral\",\"led\",\"arrived\",\"moaned\",\"luncheon\",\"raced\",\"lurking\",\"increased\",\"open\",\"recollect\",\"exploit\",\"wandered\",\"startled\",\"echoes\",\"bewitched\",\"battle\",\"mention\",\"remarked\",\"warned\",\"letting\",\"touched\",\"panic\",\"stampeded\",\"rolling\",\"obtained\",\"confession\",\"tales\",\"wrought\",\"dismissed\",\"wondering\",\"spread\",\"drove\",\"uncurled\",\"peering\",\"rung\",\"up\",\"packing\",\"completed\",\"write\",\"inserted\",\"visit\",\"commanded\",\"extracted\",\"inscription\",\"trembling\",\"blushing\",\"passion\",\"send\",\"Smoke\",\"drizzle\",\"jostling\",\"losing\",\"slipping\",\"sliding\",\"deposits\",\"sticking\",\"accumulating\",\"Fog\",\"fog\",\"flows\",\"rolls\",\"creeping\",\"hovering\",\"drooping\",\"wheezing\",\"pinching\",\"peeping\",\"Gas\",\"looming\",\"lighted\",\"gas\",\"addressed\",\"contemplation\",\"tripping\",\"groping\",\"running\",\"yawning\",\"plants\",\"keeps\",\"drones\",\"blew\",\"handled\",\"correcting\",\"tickled\",\"acquired\",\"infection\",\"lowering\",\"temper\",\"born\",\"crosser\",\"stammered\",\"beat\",\"kicked\",\"repeated\",\"slunk\",\"hurried\",\"play\",\"stuck\",\"angry\",\"muttering\",\"grinding\",\"stared\",\"wrung\",\"party\",\"wailing\",\"clutched\",\"shivering\",\"grew\",\"gasped\",\"explained\",\"cholera\",\"ill\",\"wailed\",\"dead\",\"run\",\"dying\",\"forgotten\",\"slept\",\"ate\",\"drank\",\"shut\",\"frightened\",\"sleepy\",\"lay\",\"wails\",\"hurrying\",\"rustling\",\"gliding\",\"watched\",\"frowning\",\"hungry\",\"wakened\",\"stayed\",\"footsteps\",\"neglected\",\"Left\",\"glimpse\",\"impression\",\"supper\",\"visited\",\"search\",\"find\",\"dreams\",\"howling\",\"drink\",\"rushing\",\"faced\",\"bowed\",\"received\",\"mumbled\",\"refused\",\"mixed\",\"follow\",\"questions\",\"implored\",\"rose\",\"dried\",\"taking\",\"offered\",\"excitement\",\"burned\",\"cleansed\",\"built\",\"erected\",\"shrank\",\"contact\",\"wakes\",\"fair\",\"work\",\"whine\",\"staring\",\"shouted\",\"tooting\",\"braying\",\"quivered\",\"wrong\",\"whining\",\"trudged\",\"cracks\",\"screeching\",\"shouts\",\"screeches\",\"gazing\",\"killed\",\"spent\",\"lamented\",\"smelled\",\"let\",\"pacing\",\"assure\",\"deliberate\",\"plunged\",\"drowned\",\"task\",\"unearthed\",\"commenced\",\"give\",\"commissioned\",\"appointed\",\"appointment\",\"elated\",\"appalled\",\"insisted\",\"sailed\",\"chartered\",\"vanished\",\"weighed\",\"cleared\",\"scouring\",\"witnessed\",\"washing\",\"working\",\"tripped\",\"sprawled\",\"overturning\",\"drenched\",\"oaths\",\"regained\",\"blow\",\"felled\",\"act\",\"crouched\",\"snarl\",\"sprang\",\"crushing\",\"white\",\"mutiny\",\"firing\",\"lodged\",\"flash\",\"Words\",\"strode\",\"assisting\",\"word\",\"speech\",\"limping\",\"wounding\",\"glowering\",\"commencement\",\"dispelled\",\"reflections\",\"agitation\",\"began\",\"inherited\",\"resolved\",\"dedicated\",\"own\",\"entreated\",\"hired\",\"complaints\",\"acquainted\",\"secure\",\"consented\",\"confessing\",\"reassured\",\"informed\",\"abandoned\",\"bestowed\",\"solicited\",\"quitted\",\"thoughts\",\"undertaking\",\"enterprise\",\"proud\",\"enthusiasm\",\"sold\",\"adapted\",\"settled\",\"established\",\"dapple\",\"perfume\",\"intoxicating\",\"whispering\",\"heightened\",\"suggested\",\"transplanted\",\"plucked\",\"returning\",\"chosen\",\"substitution\",\"suffering\",\"examined\",\"wonder\",\"typing\",\"altered\",\"rattled\",\"appended\",\"snap\",\"tramped\",\"planked\",\"tore\",\"inspected\",\"tackled\",\"despatched\",\"scented\",\"sorted\",\"phrased\",\"sinister\",\"sullen\",\"wheeled\",\"melted\",\"murmuring\",\"listening\",\"split\",\"closing\",\"harkened\",\"fearing\",\"music\",\"impelled\",\"power\",\"shrinking\",\"song\",\"laughter\",\"illumined\",\"dancing\",\"twined\",\"twirled\",\"flickered\",\"motion\",\"dazzled\",\"bewildered\",\"fascinated\",\"whirl\",\"panting\",\"peered\",\"blurred\",\"crowding\",\"stumbling\",\"toiled\",\"haste\",\"exhausted\",\"drifted\",\"sifting\",\"vision\",\"flying\",\"determination\",\"gazed\",\"dreaming\",\"abstracted\",\"alert\",\"quizzical\",\"challenged\",\"bridled\",\"scoffed\",\"hugged\",\"asserted\",\"tossed\",\"scornful\",\"soft\",\"waking\",\"daydream\",\"noting\",\"announced\",\"glinting\",\"fumbling\",\"Untying\",\"bounded\",\"flitted\",\"swaying\",\"dripping\",\"shock\",\"meeting\",\"rained\",\"brightening\",\"mischief\",\"hopped\",\"pointing\",\"faded\",\"joy\",\"puzzled\",\"tear\",\"warmth\",\"cheer\",\"fared\",\"amazement\",\"offer\",\"decline\",\"acknowledge\",\"planned\",\"invitation\",\"studying\",\"witticism\",\"dragged\",\"whimpering\",\"tucked\",\"deploring\",\"escapade\",\"longing\",\"fought\",\"objections\",\"woke\",\"racket\",\"dressed\",\"explored\",\"sought\",\"persuasive\",\"hypnotized\",\"excited\",\"had\",\"present\",\"consider\",\"clashed\",\"intend\",\"snowy\",\"sunny\",\"sparkling\",\"struggled\",\"spending\",\"tiptoed\",\"accept\",\"return\",\"blinking\",\"meditating\",\"bellied\",\"wistfulness\",\"leaned\",\"dipped\",\"flared\",\"fleeing\",\"arched\",\"love\",\"giggling\",\"Trailing\",\"indignant\",\"frowned\",\"grumbled\",\"glowed\",\"rammed\",\"jerked\",\"rid\",\"clenching\",\"admit\",\"begging\",\"darted\",\"yawn\",\"patted\",\"stroked\",\"regarded\",\"fidgeting\",\"bell\",\"apologize\",\"bending\",\"punching\",\"resurrected\",\"calculated\",\"seize\",\"arrest\",\"hovered\",\"whirled\",\"snatched\",\"scrambled\",\"tell\",\"through\",\"stealing\",\"Said\",\"scare\",\"suspicion\",\"searched\",\"flattered\",\"reflect\",\"forestalled\",\"pumped\",\"vexed\",\"overlooked\",\"missed\",\"inspiration\",\"forgive\",\"miscarried\",\"sorry\",\"stumbled\",\"checked\",\"stifles\",\"puffing\",\"detect\",\"dragging\",\"chirps\",\"drags\",\"notion\",\"fancy\",\"passing\",\"tapping\",\"float\",\"bring\",\"choose\",\"steadying\",\"helped\",\"inclining\",\"pacified\",\"staggered\",\"groped\",\"kindled\",\"glimmer\",\"trod\",\"Placing\",\"untied\",\"skinning\",\"munching\",\"scent\",\"smells\",\"vapor\",\"gloom\",\"unnerved\",\"fancies\",\"pondered\",\"conclusion\",\"acting\",\"reined\",\"thrilling\",\"request\",\"considered\",\"experiment\",\"uplifted\",\"show\",\"Shaking\",\"scanned\",\"Noticing\",\"conducted\",\"encountered\",\"heighten\",\"sentiments\",\"stirring\",\"accosted\",\"threw\",\"ushered\",\"greeted\",\"doubted\",\"awed\",\"deepen\",\"speculating\",\"spoken\",\"counsel\",\"expostulated\",\"persuasions\",\"discourse\",\"moved\",\"affected\",\"resolution\",\"expressions\",\"reported\",\"concern\",\"prompting\",\"rise\",\"sick\",\"terrified\",\"abandoning\",\"entreaties\",\"reproached\",\"question\",\"paid\",\"postpone\",\"prompted\",\"feel\",\"disembarked\",\"nearing\",\"taste\",\"stolen\",\"invoked\",\"consorted\",\"evasion\",\"winced\",\"touching\",\"delay\",\"pronounced\",\"confronted\",\"noticed\",\"Recognition\",\"catch\",\"wound\",\"aware\",\"rejoinder\",\"been\",\"qualification\",\"removed\",\"shirked\",\"muffled\",\"forsaken\",\"protection\",\"presenting\",\"preparation\",\"impulse\",\"sense\",\"survey\",\"address\",\"response\",\"remark\",\"comparison\",\"produced\",\"recognition\",\"case\",\"begun\",\"flatter\",\"abuse\",\"Observing\",\"scolding\",\"coughing\",\"adjusting\",\"astonishment\",\"declare\",\"raptures\",\"trimming\",\"journey\",\"desire\",\"pass\",\"risen\",\"problem\",\"rang\",\"indicated\",\"observe\",\"deduce\",\"fail\",\"chuckled\",\"rubbed\",\"strikes\",\"scraped\",\"caused\",\"remove\",\"deduction\",\"lighting\",\"written\",\"out\",\"retiring\",\"tremble\",\"cast\",\"adopted\",\"scattered\",\"arguing\",\"encouragement\",\"deserted\",\"swear\",\"debate\",\"outlined\",\"opposed\",\"advocated\",\"clamored\",\"bids\",\"bustled\",\"disdaining\",\"comments\",\"discussions\",\"crawled\",\"shot\",\"wreathed\",\"rebellion\",\"winds\",\"rejoicing\",\"shiver\",\"enlisted\",\"milking\",\"silence\",\"milk\",\"disappointed\",\"primed\",\"destroyed\",\"peeled\",\"plan\",\"fill\",\"beating\",\"ecstasy\",\"trails\",\"discouraged\",\"imputes\",\"tells\",\"detained\",\"apprehend\",\"bequeathed\",\"addressing\",\"abandon\",\"applying\",\"aims\",\"pretend\",\"bid\",\"discontinued\",\"perplexity\",\"uneasiness\",\"remorse\",\"detaining\",\"persuaded\",\"complying\",\"birth\",\"fix\",\"infatuated\",\"conjuring\",\"recommended\",\"parted\",\"instigation\",\"enraged\",\"unkindness\",\"threatened\",\"Disappointed\",\"burnt\",\"denied\",\"anguish\",\"advice\",\"illness\",\"recovery\",\"remind\",\"foresee\",\"elopement\",\"outburst\",\"plumes\",\"ended\",\"signalised\",\"differing\",\"connected\",\"endured\",\"thunders\",\"inquired\",\"wagged\",\"sunset\",\"hunted\",\"learned\",\"ease\",\"mad\",\"pecking\",\"tiresome\",\"lonesome\",\"off\",\"trying\",\"shivers\",\"scared\",\"crawling\",\"flipped\",\"shriveled\",\"tied\",\"licks\",\"Says\",\"tiptoeing\",\"stooping\",\"itching\",\"itch\",\"itched\",\"reckoned\",\"breathe\",\"snore\",\"comfortable\",\"plodded\",\"resolutions\",\"cheering\",\"rebuking\",\"ascending\",\"collared\",\"whack\",\"swept\",\"producing\",\"breaking\",\"directing\",\"account\",\"pretending\",\"growled\",\"summons\",\"bursting\",\"inhabited\",\"shrieked\",\"carving\",\"pleased\",\"rush\",\"snorting\",\"choking\",\"screaming\",\"demolishing\",\"discuss\",\"confess\",\"misadventure\",\"explosion\",\"exhorted\",\"breath\",\"assured\",\"BORN\",\"record\",\"strike\",\"advertised\",\"withdrawn\",\"raffle\",\"pay\",\"separation\",\"tidings\",\"affronted\",\"welcomed\",\"arrival\",\"foreboding\",\"glowing\",\"proof\",\"pressing\",\"turn\",\"frown\",\"begged\",\"beginning\",\"begin\",\"hold\",\"mauling\",\"oath\",\"headed\",\"deposition\",\"cheated\",\"hunting\",\"fever\",\"trekked\",\"overcharged\",\"transhipped\",\"ascertained\",\"referring\",\"mistake\",\"anticipating\",\"trip\",\"ring\",\"Going\",\"filled\",\"leant\",\"dreary\",\"smoked\",\"smoking\",\"beamed\",\"placing\",\"talk\",\"murmured\",\"swung\",\"rest\",\"drifting\",\"flood\",\"haze\",\"toying\",\"satisfied\",\"exchanged\",\"sombre\",\"fall\",\"appear\",\"stir\",\"BIRTH\",\"gasping\",\"struggles\",\"breathed\",\"sneezed\",\"advertise\",\"imposed\",\"rustled\",\"warm\",\"rub\",\"tasting\",\"perspective\",\"deposited\",\"imprinted\",\"shuddered\",\"chafed\",\"fallen\",\"stooped\",\"pausing\",\"order\",\"shaking\",\"applied\",\"dress\",\"badged\",\"ticketed\",\"take\",\"plodding\",\"rapped\",\"lingering\",\"learn\",\"observing\",\"pipe\",\"flapped\",\"glared\",\"described\",\"speaking\",\"bearing\",\"intoned\",\"Halted\",\"blessed\",\"crosses\",\"gurgling\",\"peeped\",\"whistle\",\"attention\",\"whistles\",\"skipped\",\"pointed\",\"propped\",\"lathered\",\"Ceasing\",\"shave\",\"shaved\",\"raving\",\"moaning\",\"suffered\",\"pull\",\"wiped\",\"Leaning\",\"clearing\",\"fretted\",\"dream\",\"giving\",\"kills\",\"Laughter\",\"asks\",\"pinched\",\"Laughing\",\"Drawing\",\"linked\",\"clacking\",\"tease\",\"considering\",\"occurred\",\"TOOK\",\"flashed\",\"pop\",\"falling\",\"disappointment\",\"hope\",\"fitted\",\"knelt\",\"longed\",\"dozing\",\"nervous\",\"breakdown\",\"bored\",\"consumption\",\"sampled\",\"tipsy\",\"essayed\",\"exaltation\",\"reaction\",\"incident\",\"rejoiced\",\"hunched\",\"dreamy\",\"bound\",\"operation\",\"curled\",\"KISS\",\"preferred\",\"sauntered\",\"leave\",\"gratified\",\"preparing\",\"attracted\",\"cavalcade\",\"blushed\",\"ball\",\"recollection\",\"beholding\",\"driving\",\"proceed\",\"designs\",\"Arriving\",\"dismounted\",\"sending\",\"proceeded\",\"illuminated\",\"composure\",\"intention\",\"overtook\",\"compliments\",\"delighted\",\"ingratiate\",\"parting\",\"tapped\",\"rivetted\",\"fixed\",\"painting\",\"afraid\",\"drop\",\"blotted\",\"lurked\",\"cluttered\",\"clutching\",\"perished\",\"seizure\",\"listen\",\"filtering\",\"place\",\"encouraged\",\"chord\",\"roamed\",\"thrill\",\"shattering\",\"regarding\",\"offended\",\"resented\",\"irritability\",\"anticipated\",\"silenced\",\"grunted\",\"celebrated\",\"victory\",\"sniffing\",\"Smoking\",\"helplessness\",\"recoiling\",\"researches\",\"draft\",\"infuriated\",\"mount\",\"approval\",\"arranged\",\"streamed\",\"whirring\",\"rippling\",\"Reaching\",\"temptation\",\"shower\",\"enjoy\",\"answers\",\"assenting\",\"completing\",\"recorded\",\"effaced\",\"discovery\",\"vowed\",\"delight\",\"blossomed\",\"varnished\",\"flowered\",\"wringing\",\"mewing\",\"clinging\",\"chased\",\"wipe\",\"projecting\",\"mewed\",\"unwound\",\"bared\",\"blowing\",\"severity\",\"start\",\"predicament\",\"lowered\",\"ascent\",\"colder\",\"tearful\",\"tying\",\"stabbed\",\"miss\",\"errand\",\"excel\",\"pushing\",\"apply\",\"carrying\",\"conclusions\",\"meant\",\"suggest\",\"supposing\",\"presentation\",\"vanishes\",\"emerges\",\"inferences\",\"paced\",\"beg\",\"appearance\",\"occupation\",\"becomes\",\"mastered\",\"earned\",\"stretching\",\"inference\",\"expression\",\"die\",\"trail\",\"prayer\",\"weep\",\"cower\",\"lengthening\",\"spurring\",\"flogged\",\"emerge\",\"fastening\",\"wishing\",\"reverie\",\"Locking\",\"refilled\",\"ridden\",\"flocking\",\"tilt\",\"busy\",\"nodded\",\"warranted\",\"testify\",\"grant\",\"rowing\",\"pace\",\"dissatisfaction\",\"exchange\",\"recount\",\"condescended\",\"provision\",\"named\",\"adhered\",\"premised\",\"burying\",\"claim\",\"gratification\",\"escorted\",\"attendance\",\"sale\",\"promise\",\"awaiting\",\"lamentations\",\"step\",\"nod\",\"inclined\",\"hummed\",\"hesitation\",\"summoned\",\"concluded\",\"smacking\",\"tracing\",\"Concluding\",\"doubts\",\"retailing\",\"seeing\",\"quickened\",\"declining\",\"contemplated\",\"estimate\",\"investigations\",\"stirred\",\"murmur\",\"shouldering\",\"circling\",\"insistence\",\"disappearance\",\"tossing\",\"elevated\",\"whorls\",\"strolling\",\"ensconced\",\"insist\",\"landed\",\"agreement\",\"display\",\"affectionate\",\"happened\",\"know\",\"fragrance\",\"pride\",\"stroke\",\"ladling\",\"puff\",\"spat\",\"crammed\",\"alluding\",\"imagined\",\"desired\",\"disturbed\",\"check\",\"annoyed\",\"discovering\",\"toil\",\"beckoned\",\"beckon\",\"sounded\",\"flickering\",\"campfire\",\"fanned\",\"paling\",\"sparks\",\"echoed\",\"clink\",\"pads\",\"reach\",\"move\",\"waning\",\"halt\",\"preparations\",\"movements\",\"blaze\",\"departed\",\"grateful\",\"solitude\",\"traveled\",\"digging\",\"crack\",\"recognized\",\"halting\",\"slaps\",\"march\",\"camped\",\"travel\",\"reserve\",\"respond\",\"realization\",\"dug\",\"grasped\",\"amazed\",\"pitying\",\"curious\",\"quiver\",\"astounded\",\"force\",\"pulling\",\"ejaculated\",\"seep\",\"complied\",\"allowed\",\"touch\",\"indulged\",\"moist\",\"dark\",\"averred\",\"swore\",\"fit\",\"cured\",\"warmed\",\"beheld\",\"withdraw\",\"sheltered\",\"express\",\"wincing\",\"uttered\",\"preceded\",\"relieving\",\"conjectured\",\"ejaculation\",\"advent\",\"admire\",\"distinguished\",\"chatter\",\"clatter\",\"squealing\",\"haunted\",\"bestow\",\"decamp\",\"advanced\",\"attempting\",\"sneaking\",\"watering\",\"caress\",\"gnarl\",\"provoked\",\"checking\",\"punch\",\"striding\",\"dived\",\"guardianship\",\"imagining\",\"winking\",\"faces\",\"irritated\",\"fury\",\"leapt\",\"interpose\",\"proceeding\",\"aroused\",\"issued\",\"parrying\",\"constrained\",\"demand\",\"climbed\",\"yelping\",\"flourishing\",\"used\",\"subsided\",\"storm\",\"heaving\",\"eyeing\",\"treatment\",\"restoring\",\"doubt\",\"confusion\",\"overwhelmed\",\"tempest\",\"laying\",\"objects\",\"shelved\",\"discussion\",\"premise\",\"duel\",\"smuggled\",\"chill\",\"ascended\",\"explanation\",\"curiosity\",\"clinched\",\"declaring\",\"propitiated\",\"eaten\",\"saddened\",\"do\",\"generosity\",\"peevish\",\"wrangled\",\"guise\",\"glances\",\"repressing\",\"shocked\",\"sympathized\",\"repressed\",\"persisted\",\"thumped\",\"reddened\",\"displeasure\",\"toy\",\"censured\",\"decision\",\"reversed\",\"apologizing\",\"lateness\",\"exclaiming\",\"expect\",\"forward\",\"filling\",\"success\",\"bow\",\"breathless\",\"visitation\",\"consequence\",\"appearing\",\"asking\",\"grimace\",\"groan\",\"reproach\",\"charmed\",\"communicative\",\"wonders\",\"committed\",\"professed\",\"apparition\",\"kick\",\"episode\",\"boarded\",\"kiss\",\"clacked\",\"replaced\",\"conjectures\",\"termed\",\"conscious\",\"intuition\",\"prevailed\",\"sprung\",\"clew\",\"ache\",\"smiling\",\"mingling\",\"growing\",\"Surprised\",\"sowing\",\"spoiled\",\"knitting\",\"twitched\",\"jaunting\",\"headache\",\"dumb\",\"tea\",\"jolt\",\"glided\",\"disappearing\",\"blight\",\"pierced\",\"yelp\",\"twittering\",\"calls\",\"afterglow\",\"flooded\",\"flaring\",\"moan\",\"fading\",\"steps\",\"brewing\",\"trotting\",\"Peering\",\"moving\",\"deadened\",\"loom\",\"clinking\",\"jingled\",\"curses\",\"thuds\",\"strain\",\"heaves\",\"footstep\",\"drawled\",\"wave\",\"became\",\"crash\",\"attested\",\"click\",\"sputtering\",\"efforts\",\"crackling\",\"flame\",\"shuffled\",\"glittered\",\"queried\",\"comin\",\"raindrops\",\"pattered\",\"Silence\",\"blazed\",\"query\",\"showing\",\"backed\",\"Sent\",\"misinterpreted\",\"difference\",\"storming\",\"concerned\",\"assault\",\"believe\",\"treating\",\"wrangle\",\"sally\",\"forded\",\"fighting\",\"excesses\",\"loaded\",\"plunder\",\"conquest\",\"frenzy\",\"slaughter\",\"riot\",\"disgraced\",\"jests\",\"joke\",\"catchwords\",\"plundering\",\"break\",\"yelling\",\"dread\",\"crowded\",\"throng\",\"proclamation\",\"gained\",\"seized\",\"stripped\",\"escaped\",\"Preserved\",\"transported\",\"predicted\",\"polluted\",\"sacrilege\",\"possession\",\"STORMING\",\"Extracted\",\"revert\",\"stored\",\"entrusted\",\"build\",\"executed\",\"prophecy\",\"grasp\",\"punishment\",\"operations\",\"hard\",\"brackish\",\"execution\",\"wrested\",\"trodden\",\"crime\",\"blasted\",\"INCIDENT\",\"standstill\",\"hopping\",\"performance\",\"reflection\",\"deed\",\"smiles\",\"conjecture\",\"actions\",\"descending\",\"dispute\",\"stepping\",\"handing\",\"gaining\",\"retreating\",\"indifference\",\"madness\",\"snapped\",\"compromised\",\"fragrant\",\"showered\",\"chirping\",\"chirp\",\"scrape\",\"engaging\",\"rented\",\"lined\",\"clung\",\"flushed\",\"lain\",\"list\",\"command\",\"blocked\",\"blocking\",\"unpopular\",\"anxiety\",\"pounced\",\"persuade\",\"hinted\",\"collected\",\"rousing\",\"poured\",\"meditation\",\"bite\",\"Promoted\",\"promoted\",\"row\",\"affecting\",\"visiting\",\"confessed\",\"resume\",\"intervened\",\"combed\",\"wounded\",\"demobbed\",\"appealed\",\"launched\",\"Armistice\",\"Coming\",\"gossiping\",\"measure\",\"disapproval\",\"inspection\",\"sifted\",\"fanning\",\"bellowed\",\"irritating\",\"tickling\",\"sneered\",\"sprinkled\",\"slurred\",\"civility\",\"stare\",\"curl\",\"undid\",\"revealing\",\"straightened\",\"ignoring\",\"scratched\",\"ripped\",\"jingling\",\"discussed\",\"gamble\",\"tribute\",\"reminds\",\"Ambling\",\"blazing\",\"offense\",\"imprisonment\",\"deaths\",\"hissing\",\"drive\",\"puzzle\",\"snow\",\"snowfall\",\"stamped\",\"introduction\",\"melting\",\"dripped\",\"advances\",\"whisked\",\"mixing\",\"stabs\",\"cooked\",\"delaying\",\"gaping\",\"rigid\",\"recover\",\"messing\",\"done\",\"air\",\"unfolded\",\"extended\",\"tangent\",\"confirmed\",\"smouldered\",\"drunk\",\"acknowledgment\",\"snatching\",\"animation\",\"ARRIVAL\",\"fortune\",\"embarrassed\",\"charged\",\"attack\",\"christened\",\"joined\",\"sweating\",\"grunting\",\"purchasing\",\"graduated\",\"dallied\",\"surging\",\"seething\",\"carnage\",\"allowing\",\"slip\",\"escape\",\"aghast\",\"howl\",\"blunder\",\"routed\",\"saved\",\"disaster\",\"admonishing\",\"diminished\",\"certainty\",\"retreated\",\"defeat\",\"blows\",\"erection\",\"emerged\",\"shrunken\",\"verbiage\",\"resentment\",\"coined\",\"juggled\",\"poised\",\"regard\",\"wrapping\",\"disputed\",\"crashing\",\"gulps\",\"silent\",\"thoughtful\",\"sickness\",\"buttered\",\"glint\",\"donned\",\"teased\",\"issue\",\"improved\",\"adding\",\"Married\",\"inserting\",\"excursions\",\"expected\",\"purchased\",\"uniting\",\"pool\",\"tattoo\",\"Hearing\",\"echoing\",\"snapping\",\"coughed\",\"contracted\",\"controlled\",\"shoveled\",\"whistled\",\"cough\",\"glare\",\"soothed\",\"cosseted\",\"pouring\",\"breathing\",\"dusted\",\"breaths\",\"swinging\",\"brisker\",\"welded\",\"provisioned\",\"precautions\",\"provided\",\"entertained\",\"masquerade\",\"appearances\",\"projected\",\"f\\u00eate\",\"revel\",\"glitter\",\"piquancy\",\"phantasm\",\"unsuited\",\"stalked\",\"writhed\",\"causing\",\"chime\",\"depart\",\"floats\",\"swells\",\"writhe\",\"stream\",\"appals\",\"peal\",\"reaches\",\"sounding\",\"evolutions\",\"quieted\",\"cessation\",\"presence\",\"disapprobation\",\"horror\",\"disgust\",\"assume\",\"vows\",\"chiming\",\"disconcert\",\"painted\",\"harken\",\"pale\",\"clang\",\"strokes\",\"pestilence\",\"sniff\",\"agree\",\"examining\",\"complaining\",\"advised\",\"softened\",\"lecture\",\"stroking\",\"crackled\",\"lecturing\",\"gives\",\"shipwrecked\",\"swims\",\"sail\",\"voyage\",\"inform\",\"spied\",\"shift\",\"rowed\",\"computation\",\"trusted\",\"overset\",\"flurry\",\"swam\",\"directed\",\"tide\",\"abated\",\"awaked\",\"attempted\",\"roared\",\"hurt\",\"falls\",\"leaping\",\"ventured\",\"wrench\",\"bind\",\"loosened\",\"shout\",\"flight\",\"striving\",\"volley\",\"design\",\"knew\",\"oration\",\"attended\",\"support\",\"acted\",\"promises\",\"demands\",\"signify\",\"supplied\",\"sign\",\"slung\",\"signs\",\"warning\",\"tempted\",\"remembrance\",\"interpreted\",\"imaginations\",\"treated\",\"posture\",\"blisters\",\"tokens\",\"repetitions\",\"relaxing\",\"conjecturing\",\"torrent\",\"violence\",\"daubed\",\"smart\",\"disposed\",\"mingled\",\"consulted\",\"passage\",\"over\",\"marks\",\"Gets\",\"absent\",\"sadness\",\"revolved\",\"enlightened\",\"situation\",\"outbreaks\",\"apparent\",\"sketched\",\"rehearsed\",\"forgetting\",\"sped\",\"sorrow\",\"reversal\",\"hopes\",\"weeping\",\"reposing\",\"troublesome\",\"lessening\",\"ceremony\",\"crisis\",\"heaviness\",\"indignation\",\"overthrow\",\"wept\",\"mingle\",\"lessened\",\"eat\",\"grievance\",\"avenged\",\"swallowed\",\"draw\",\"embarrassment\",\"add\",\"conferred\",\"abrogation\",\"hint\",\"fervid\",\"gesticulating\",\"submission\",\"appeal\",\"resolving\",\"deemed\",\"favor\",\"registered\",\"traversed\",\"sentenced\",\"pardoned\",\"serving\",\"misdemeanor\",\"Leaving\",\"paces\",\"Retracing\",\"varnishing\",\"effusion\",\"gravity\",\"quoted\",\"remarks\",\"retraced\",\"converged\",\"seeking\",\"light\",\"emptied\",\"licking\",\"tilted\",\"dip\",\"roll\",\"keeping\",\"faltered\",\"hugging\",\"soaked\",\"smothered\",\"lamed\",\"stung\",\"INTRODUCED\",\"reposed\",\"dumped\",\"Getting\",\"dropping\",\"hitching\",\"excuse\",\"interested\",\"judged\",\"breakfasted\",\"marking\",\"skirted\",\"squatted\",\"investigate\",\"Look\",\"foamed\",\"boiled\",\"lunch\",\"singing\",\"dined\",\"lingered\",\"dawdled\",\"thrilled\",\"mantled\",\"suffused\",\"wooing\",\"flitting\",\"confusing\",\"guess\",\"pictured\",\"partial\",\"swayed\",\"waxing\",\"organizing\",\"arrive\",\"chinked\",\"doubled\",\"affirmative\",\"tightened\",\"shutting\",\"grappled\",\"twist\",\"lolling\",\"ebbed\",\"glazed\",\"flagged\",\"jolted\",\"anger\",\"quick\",\"choked\",\"hiding\",\"struggle\",\"filing\",\"nursing\",\"expecting\",\"twisted\",\"growl\",\"stormed\",\"raged\",\"assailed\",\"carted\",\"trucked\",\"amusement\",\"awkwardness\",\"thickened\",\"suspended\",\"remarking\",\"cursed\",\"compressing\",\"danger\",\"speculation\",\"hits\",\"lying\",\"depicted\",\"displaying\",\"control\",\"dealing\",\"rejecting\",\"controlling\",\"consolation\",\"increase\",\"opposition\",\"outbreak\",\"palpitating\",\"invisible\",\"jet\",\"compared\",\"eruption\",\"vigil\",\"vibrating\",\"activity\",\"projection\",\"streamer\",\"swimming\",\"gleam\",\"flaming\",\"jetting\"],\"x1\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[2538]},\"x2\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[2538]}},\"selected\":{\"id\":\"1045\"},\"selection_policy\":{\"id\":\"1046\"}},\"id\":\"1030\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"active_multi\":null,\"tools\":[{\"id\":\"1021\"},{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"}]},\"id\":\"1025\",\"type\":\"Toolbar\"},{\"attributes\":{\"formatter\":{\"id\":\"1043\"},\"major_label_policy\":{\"id\":\"1044\"},\"ticker\":{\"id\":\"1014\"}},\"id\":\"1013\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1044\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1041\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1043\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"axis\":{\"id\":\"1013\"},\"ticker\":null},\"id\":\"1016\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1007\",\"type\":\"DataRange1d\"},{\"attributes\":{\"source\":{\"id\":\"1030\"},\"text\":{\"field\":\"names\"},\"text_align\":{\"value\":\"center\"},\"text_color\":{\"value\":\"#555555\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"},\"y_offset\":{\"value\":6}},\"id\":\"1036\",\"type\":\"LabelSet\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"SaveTool\"},{\"attributes\":{\"source\":{\"id\":\"1030\"}},\"id\":\"1035\",\"type\":\"CDSView\"},{\"attributes\":{\"fill_color\":{\"field\":\"color\"},\"line_color\":{\"field\":\"color\"},\"size\":{\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1032\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{\"text\":\"clusters\"},\"id\":\"1003\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"LinearScale\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.3\"}};\n  var render_items = [{\"docid\":\"4eaaefec-10d8-4226-861a-5c5efddeca1b\",\"root_ids\":[\"1002\"],\"roots\":{\"1002\":\"7a0c7475-d922-402f-9e56-3928608bbd93\"}}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    var attempts = 0;\n    var timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "1002"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from bokeh.models import ColumnDataSource, LabelSet\n",
        "from bokeh.plotting import figure, show, output_file\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "output_notebook()\n",
        "\n",
        "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
        "           toolbar_location=\"above\",\n",
        "           title=\"clusters\")\n",
        "\n",
        "source = ColumnDataSource(data=dict(x1=top_words_tsne[:,0],\n",
        "                                    x2=top_words_tsne[:,1],\n",
        "                                    names=presented_events,\n",
        "                                    color=to_colors(model.labels_)))\n",
        "\n",
        "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source, color='color')\n",
        "\n",
        "labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
        "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
        "                  source=source, text_align='center')\n",
        "p.add_layout(labels)\n",
        "\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEIHCTYMXD9P"
      },
      "source": [
        "Визуализация сильно зависит от параметров TSNE, поэтому объекты внутри кластеров могут находиться далеко друг от друга. Однако некоторые скопления можно углядеть."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpqBdM5kXD9P",
        "outputId": "0bca98a0-a6a0-465e-9f28-da1875dcfee6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "events = ans[ans['Label'] == \"EVE\"]['Token'].values\n",
        "\n",
        "embedded = []\n",
        "presented_events = []\n",
        "for event in events:\n",
        "    if event in w2v:\n",
        "        presented_events.append(event)\n",
        "        embedded.append(w2v[event])\n",
        "embedded = np.array(embedded)\n",
        "\n",
        "model = KMeans()\n",
        "model.fit(embedded)\n",
        "cluster_df = pd.DataFrame({\"event\" : presented_events, \"cluster\" : model.labels_})\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=0)\n",
        "top_words_tsne = tsne.fit_transform(embedded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "zeANnU1VXD9Q",
        "outputId": "b14572a0-30a7-4ad1-fe68-e72cb6ea9031"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  var JS_MIME_TYPE = 'application/javascript';\n  var HTML_MIME_TYPE = 'text/html';\n  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  var CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    var script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    var cell = handle.cell;\n\n    var id = cell.output_area._bokeh_element_id;\n    var server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd, {\n        iopub: {\n          output: function(msg) {\n            var id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    var output_area = handle.output_area;\n    var output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      var bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      var script_attrs = bk_div.children[0].attributes;\n      for (var i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      var toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
            "application/vnd.bokehjs_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "  <div class=\"bk-root\" id=\"edc4effc-28ba-4215-9555-9560770d84e2\" data-root-id=\"1092\"></div>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "(function(root) {\n  function embed_document(root) {\n    \n  var docs_json = {\"d1792a48-0415-439e-acfc-1d350167735b\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1103\"}],\"center\":[{\"id\":\"1106\"},{\"id\":\"1110\"},{\"id\":\"1126\"}],\"left\":[{\"id\":\"1107\"}],\"renderers\":[{\"id\":\"1124\"}],\"title\":{\"id\":\"1093\"},\"toolbar\":{\"id\":\"1115\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"1095\"},\"x_scale\":{\"id\":\"1099\"},\"y_range\":{\"id\":\"1097\"},\"y_scale\":{\"id\":\"1101\"}},\"id\":\"1092\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1111\",\"type\":\"PanTool\"},{\"attributes\":{\"data\":{\"color\":[\"pink\",\"pink\",\"gray\",\"green\",\"green\",\"yellow\",\"pink\",\"pink\",\"green\",\"red\",\"blue\",\"blue\",\"black\",\"black\",\"yellow\",\"yellow\",\"yellow\",\"green\",\"black\",\"pink\",\"black\",\"yellow\",\"black\",\"pink\",\"pink\",\"brown\",\"yellow\",\"red\",\"pink\"],\"names\":[\"First\",\"Brown\",\"DTM\",\"Olympic\",\"Olympics\",\"EuroLeague\",\"Fes\",\"Masters\",\"Olympic\",\"Brasileir\\u00e3o\",\"Bundesliga\",\"Bundesliga\",\"Superleague\",\"Superleague\",\"Euroleague\",\"EuroLeague\",\"EuroLeague\",\"Olympics\",\"Superleague\",\"Munster\",\"Superleague\",\"EuroLeague\",\"Superleague\",\"Finals\",\"Corunna\",\"WSOP\",\"Melodifestivalen\",\"Clausura\",\"Revolution\"],\"x1\":{\"__ndarray__\":\"IqYOwzHoGML3ZmZCCU7XQt7pL0K9cOZCwG6OQbrhB0P0yrzC8Yd7wvirZML8WYtDkRcGwj+FiUJa8MHDGJKZwmyDOcNXukjDxUwEwMEKksGeRWnCj1gpQwHwvUKKOO/CrhcRw1KJL8OojetB9StpQRloWsM=\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[29]},\"x2\":{\"__ndarray__\":\"FtYQw3nyi0EY7wxC2t5twjJhiMJocIlBhL5BwbEgr0KUmpXB/cqaQm8wL0Pk44HByr5WwsMsBENKV+LCGRjQwhEtkkLS6D1DIHDpwsbM/kKjhjTDGTvawYmKBcMRB1tCjBCOwhoe+cDLAjbDeEuXQs8QQsM=\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[29]}},\"selected\":{\"id\":\"1144\"},\"selection_policy\":{\"id\":\"1145\"}},\"id\":\"1120\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"source\":{\"id\":\"1120\"}},\"id\":\"1125\",\"type\":\"CDSView\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"field\":\"color\"},\"size\":{\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1123\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1139\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"formatter\":{\"id\":\"1142\"},\"major_label_policy\":{\"id\":\"1143\"},\"ticker\":{\"id\":\"1104\"}},\"id\":\"1103\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1143\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1114\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1144\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1108\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1140\",\"type\":\"AllLabels\"},{\"attributes\":{\"fill_color\":{\"field\":\"color\"},\"line_color\":{\"field\":\"color\"},\"size\":{\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1122\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1099\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1112\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1104\",\"type\":\"BasicTicker\"},{\"attributes\":{\"source\":{\"id\":\"1120\"},\"text\":{\"field\":\"names\"},\"text_align\":{\"value\":\"center\"},\"text_color\":{\"value\":\"#555555\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"},\"y_offset\":{\"value\":6}},\"id\":\"1126\",\"type\":\"LabelSet\"},{\"attributes\":{},\"id\":\"1145\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"formatter\":{\"id\":\"1139\"},\"major_label_policy\":{\"id\":\"1140\"},\"ticker\":{\"id\":\"1108\"}},\"id\":\"1107\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data_source\":{\"id\":\"1120\"},\"glyph\":{\"id\":\"1122\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1123\"},\"view\":{\"id\":\"1125\"}},\"id\":\"1124\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1113\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1142\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1097\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1101\",\"type\":\"LinearScale\"},{\"attributes\":{\"active_multi\":null,\"tools\":[{\"id\":\"1111\"},{\"id\":\"1112\"},{\"id\":\"1113\"},{\"id\":\"1114\"}]},\"id\":\"1115\",\"type\":\"Toolbar\"},{\"attributes\":{\"axis\":{\"id\":\"1103\"},\"ticker\":null},\"id\":\"1106\",\"type\":\"Grid\"},{\"attributes\":{\"text\":\"word2vec T-SNE (eng model, top1000 words)\"},\"id\":\"1093\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1095\",\"type\":\"DataRange1d\"},{\"attributes\":{\"axis\":{\"id\":\"1107\"},\"dimension\":1,\"ticker\":null},\"id\":\"1110\",\"type\":\"Grid\"}],\"root_ids\":[\"1092\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.3\"}};\n  var render_items = [{\"docid\":\"d1792a48-0415-439e-acfc-1d350167735b\",\"root_ids\":[\"1092\"],\"roots\":{\"1092\":\"edc4effc-28ba-4215-9555-9560770d84e2\"}}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    var attempts = 0;\n    var timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "1092"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "output_notebook()\n",
        "\n",
        "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
        "           toolbar_location=\"above\",\n",
        "           title=\"word2vec T-SNE (eng model, top1000 words)\")\n",
        "\n",
        "source = ColumnDataSource(data=dict(x1=top_words_tsne[:,0],\n",
        "                                    x2=top_words_tsne[:,1],\n",
        "                                    names=presented_events,\n",
        "                                   color=to_colors(model.labels_)))\n",
        "\n",
        "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source, color='color')\n",
        "\n",
        "labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
        "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
        "                  source=source, text_align='center')\n",
        "p.add_layout(labels)\n",
        "\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faT3xLfPXD9Q"
      },
      "source": [
        "В следующих частях домашнего задания вам понадобится train-test-dev разбиения. Авторы статей предлагают следующую структуру разбиения для корпуса LitBank: обучающее множество – 80 книг, валидационное – 10 книг, тестовое – 10 книг. Предложения из одного источника не должны попадать в разные сегменты разбиения.\n",
        "Для корпуса MultiNERD_EN произведите стратифицированное разбиение по предложениям в соотношении 80%:10%:10%. Стратификацию производить в отношении пропорции по именованным сущностям (понятно, что с учётом всех вводных идеального разбиения не получится, но старайтесь сохранить распределения по типам сущностей для каждой и подвыборок)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVaW4Tz3XD9Q",
        "outputId": "5e885108-fc44-4920-9221-fa3fd5ca8643"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(80, 10, 10)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# local init\n",
        "# pathes = os.listdir('litbank_entities/tsv')\n",
        "\n",
        "# colab init\n",
        "pathes = os.listdir('/content/drive/MyDrive/litbank_events/tsv')\n",
        "\n",
        "train_pathes, test_pathes = train_test_split(pathes, train_size=0.8, random_state=1)\n",
        "val_pathes, test_pathes = train_test_split(test_pathes, train_size=0.5, random_state=1)\n",
        "len(train_pathes), len(val_pathes), len(test_pathes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCbh3jeiXD9Q"
      },
      "source": [
        "## Часть 2. [4 балла] Извлечение именованных сущностей\n",
        "Для каждой корпуса необходимо осуществить раздельно следующую процедуру:\n",
        "1. [0.75 балла] Обучите стандартную модель для извлечения именованных сущностей, CNN-BiLSTM-CRF, для извлечения именованных *низкоуровневых именованных сущностей*, т.е. для самых коротких из вложенных сущностей. Модель устроена так: сверточная сеть на символах + эмбеддинги слов + двунаправленная LSTM сеть (модель последовательности) + CRF (глобальная нормализация). \n",
        "2. [0.75 балла] Замените часть модели на символах и словах (CNN + эмбеддинги словах) на ELMo и / или BERT. Должна получиться модель ELMo / BERT + BiLSTM + CRF. \n",
        "3. [2.5 балла] Замените модель последовательности (BiLSTM) на другой слой, например, на Transformer. Должна получиться модель Transformer + CRF.\n",
        "В результате у вас будет 2 набора моделей - проверьте качество извлечения на тестовых данных.\n",
        "- Примените модели первого корпуса ко всем (!!!) предложениям второго корпуса и наоборот.\n",
        "- Составьте отчёт по качеству работы моделей в терминах извлечения по типам сущностей, которые встречаются в обоих корпусах. Метрику выберите самостоятельно.\n",
        "- Проанализируйте ошибки моделей в терминах предсказания сущностям первого корпуса специфических типов для второго корпуса. И наоборот - когда специфическим типам второго корпуса модель, обученная на LitBank, прсваивает одну из своих категорий.\n",
        "\n",
        "[бонус] Дообучите BERT для извлечения именованных сущностей.\n",
        "\n",
        "[бонус] Используйте модель для извлечения вложенных именованных сущностей [Ju et al., 2018]\n",
        "\n",
        "[бонус] Модифицируйте модель для извлечения вложенных именованных сущностей [Ju et al., 2018]: вместо эмбеддингов слов используйте ELMo и/или BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gdzEToeWXD9R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr5g2ECiLk5x"
      },
      "source": [
        "Создадим класс BookDataset для обработки данных и приведению их к необходимому формату"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ODvX7ngPXD9R"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class BookDataset(Dataset):\n",
        "    def __init__(self, pathes):\n",
        "        super().__init__()\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.all_labels = set()\n",
        "        self.read_books(pathes)\n",
        "        self.len = len(self.data)\n",
        "        \n",
        "    def read_books(self, pathes):\n",
        "        for path in pathes:\n",
        "            # colab init:\n",
        "            folder_path = '/content/drive/MyDrive/litbank_entities/tsv/'\n",
        "            # local init:\n",
        "            # folder_path = 'litbank_entities/tsv/'\n",
        "            df = pd.read_csv(\n",
        "                folder_path + path, sep='\\t', quoting=csv.QUOTE_NONE, names=['word', 'label', '1', '2', '3', '4'], skip_blank_lines=False, index_col=False)\n",
        "            blanks = np.append(-1, df[df['word'].isna()].index)\n",
        "            for i in range(len(blanks) - 1):\n",
        "                self.data.append(df[blanks[i] + 1:blanks[i + 1]]['word'].values)\n",
        "                self.labels.append(df[blanks[i] + 1:blanks[i + 1]]['label'].values)\n",
        "            self.all_labels |= set(df.dropna(subset=['label'])['label'].values)\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index], self.labels[index]\n",
        "    \n",
        "\n",
        "training_data = BookDataset(train_pathes)\n",
        "val_data = BookDataset(val_pathes)\n",
        "test_data = BookDataset(test_pathes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGGqaI6GL76H"
      },
      "source": [
        "реализуем вспомогательные функции, а также сам класс модели BiLSTM_CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fVT8HtalXD9R"
      },
      "outputs": [],
      "source": [
        "def argmax(vec):\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "def prepare_sequence(seq, to_ix, padding=None):\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    if padding:\n",
        "        idxs += [to_ix['<PAD>'] for i in range(padding - len(idxs))]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "    def __init__(self, vocab_size, char_vocab_size, tag_to_ix,\n",
        "                 embedding_dim, hidden_dim, char_embedding_dim, dropout=0.5, use_gpu=False):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.use_gpu = use_gpu\n",
        "        self.device = torch.device(\"cuda\" if self.use_gpu else \"cpu\")\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.char_embeds = nn.Embedding(char_vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim + char_embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "        self.hidden = self.init_hidden()\n",
        "        self.char_embedding_dim = char_embedding_dim\n",
        "        self.cnn = nn.Conv2d(1, char_embedding_dim, kernel_size=(3, embedding_dim))\n",
        "        self.cnn_fc = nn.Linear(char_embedding_dim * 1590, 100)\n",
        "        \n",
        "        \n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000., device=self.device)\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "        forward_var = init_alphas\n",
        "        for feat in feats:\n",
        "            alphas_t = []\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size).to(self.device)\n",
        "                trans_score = self.transitions[next_tag].view(1, -1).to(self.device)\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]].to(self.device)\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "    \n",
        "    def _cnn(self, embedded):\n",
        "        cnn_out = self.cnn(embedded)\n",
        "        cnn_out = nn.functional.max_pool2d(cnn_out, kernel_size=(cnn_out.size(2), 1))\n",
        "        #cnn_out = self.cnn_fc(cnn_out.view(-1))\n",
        "        return cnn_out.view(-1, self.char_embedding_dim)\n",
        "\n",
        "    def _get_lstm_features(self, sentence, chars):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence)\n",
        "        char_features = []\n",
        "        char_embeds = self.char_embeds(chars)\n",
        "        cnn_res = self._cnn(char_embeds.unsqueeze(1))\n",
        "        embeds = torch.cat([embeds, cnn_res], axis=1)\n",
        "        embeds = embeds.view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags]).to(self.device)\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000., device=self.device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []\n",
        "            viterbivars_t = []\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "        \n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, chars, tags):\n",
        "        feats = self._get_lstm_features(sentence, chars)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags).to(self.device)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence, chars):\n",
        "        lstm_feats = self._get_lstm_features(sentence, chars)\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UayEEO-GMFn-"
      },
      "source": [
        "Проиндексируем каждое слово и каждый символ в наших данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uA4q9dDzXD9S"
      },
      "outputs": [],
      "source": [
        "def mapping(data, res, char_=False):\n",
        "    for sentence, tags in data:\n",
        "        for word in sentence:\n",
        "            if char_:\n",
        "                for char in word:\n",
        "                    if char not in res:\n",
        "                        res[char] = len(res)\n",
        "            else:\n",
        "                if word not in res:\n",
        "                    res[word] = len(res)\n",
        "\n",
        "\n",
        "word_to_ix = {}\n",
        "word_to_ix['<PAD>'] = 0\n",
        "mapping(training_data, word_to_ix)\n",
        "mapping(val_data, word_to_ix)\n",
        "mapping(test_data, word_to_ix)\n",
        "\n",
        "char_to_ix = {}\n",
        "char_to_ix['<PAD>'] = 0\n",
        "mapping(training_data, char_to_ix, True)\n",
        "mapping(val_data, char_to_ix, True)\n",
        "mapping(test_data, char_to_ix, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhUSmajSMdch"
      },
      "source": [
        "Проиндексируем каждый label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "w_U2gH8QXD9S"
      },
      "outputs": [],
      "source": [
        "tag_to_ix = {list(training_data.all_labels)[i] : i for i in range(len(training_data.all_labels))}\n",
        "tag_to_ix[START_TAG] = len(tag_to_ix)\n",
        "tag_to_ix[STOP_TAG] = len(tag_to_ix)\n",
        "tag_to_ix['<PAD>'] = tag_to_ix[STOP_TAG]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsdafjuJMg3r"
      },
      "source": [
        "Преобразуем входные данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "STb2JraHXD9S"
      },
      "outputs": [],
      "source": [
        "train_sentences = [' '.join(training_data[i][0]) for i in range(len(training_data))]\n",
        "train_max = max(list(map(len, train_sentences)))\n",
        "\n",
        "val_sentences = [' '.join(val_data[i][0]) for i in range(len(val_data))]\n",
        "val_max = max(list(map(len, val_sentences)))\n",
        "\n",
        "test_sentences = [' '.join(test_data[i][0]) for i in range(len(test_data))]\n",
        "test_max = max(list(map(len, test_sentences)))\n",
        "\n",
        "char_padding_size = max([train_max, val_max, test_max])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DCAv5YP1XD9T"
      },
      "outputs": [],
      "source": [
        "def training(model, training_data, n_epoch=10):\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "    for epoch in range(n_epoch):\n",
        "        print(f\"{epoch} Epoch:\")\n",
        "        epoch_loss = 0\n",
        "        for sentence, tags in tqdm(training_data):\n",
        "            model.zero_grad()\n",
        "            sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "            chars_in = list(map(lambda x : prepare_sequence(x, char_to_ix, padding=char_padding_size), sentence))\n",
        "            chars_in = torch.stack(chars_in)\n",
        "            targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
        "            \n",
        "            loss = model.neg_log_likelihood(sentence_in, chars_in, targets)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(epoch_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "CqJcjR9DXD9U",
        "outputId": "378b15c7-9078-4264-cab7-abe81b6b501b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Epoch:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6794/6794 [34:32<00:00,  3.28it/s]    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "52974.079642772675\n",
            "1 Epoch:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6794/6794 [12:26<00:00,  9.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44420.821353435516\n",
            "2 Epoch:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6794/6794 [12:26<00:00,  9.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47992.713387966156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 32\n",
        "CHAR_EMBEDDING_DIM = 50\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), len(char_to_ix), tag_to_ix,\n",
        "                   EMBEDDING_DIM, HIDDEN_DIM, CHAR_EMBEDDING_DIM, use_gpu=False)\n",
        "\n",
        "training(model, training_data, n_epoch=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0iyrE-bXD9U",
        "outputId": "4dd925ef-5515-4997-bd10-d7a30e500e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model's state_dict:\n",
            "transitions \t torch.Size([16, 16])\n",
            "word_embeds.weight \t torch.Size([17869, 100])\n",
            "char_embeds.weight \t torch.Size([93, 100])\n",
            "lstm.weight_ih_l0 \t torch.Size([64, 150])\n",
            "lstm.weight_hh_l0 \t torch.Size([64, 16])\n",
            "lstm.bias_ih_l0 \t torch.Size([64])\n",
            "lstm.bias_hh_l0 \t torch.Size([64])\n",
            "lstm.weight_ih_l0_reverse \t torch.Size([64, 150])\n",
            "lstm.weight_hh_l0_reverse \t torch.Size([64, 16])\n",
            "lstm.bias_ih_l0_reverse \t torch.Size([64])\n",
            "lstm.bias_hh_l0_reverse \t torch.Size([64])\n",
            "hidden2tag.weight \t torch.Size([16, 32])\n",
            "hidden2tag.bias \t torch.Size([16])\n",
            "cnn.weight \t torch.Size([50, 1, 3, 100])\n",
            "cnn.bias \t torch.Size([50])\n",
            "cnn_fc.weight \t torch.Size([100, 79500])\n",
            "cnn_fc.bias \t torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "torch.save(model.state_dict(), \"BiLSTM_CRF_3_epochs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLlFHAKdH5Hf",
        "outputId": "39e46d03-d582-43a2-897e-c0f040130684"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"BiLSTM_CRF_3_epochs\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mdIUR2NAXD9U"
      },
      "outputs": [],
      "source": [
        "ix_to_tag = {tag_to_ix[key] : key for key in tag_to_ix}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2qYyY8EAXD9U"
      },
      "outputs": [],
      "source": [
        "def calculate_predictions(model, data, ix_to_tag):\n",
        "    predictions = list()\n",
        "    for sentence in tqdm(data):\n",
        "        words_prep = prepare_sequence(sentence[0], word_to_ix)\n",
        "        chars_prep = list(map(lambda x : prepare_sequence(x, char_to_ix, padding=char_padding_size), sentence[0]))\n",
        "        chars_prep = torch.stack(chars_prep)\n",
        "        model_prediction = model(words_prep, chars_prep)[1]\n",
        "        predictions.append(list(map(lambda x : ix_to_tag[x], model_prediction)))\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91bUAl9fXD9U",
        "outputId": "e04184c8-6553-4a08-9999-2d08ae44e885"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 908/908 [00:25<00:00, 35.38it/s]\n"
          ]
        }
      ],
      "source": [
        "y_pred = calculate_predictions(model, test_data, ix_to_tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PxxEty1SXD9V"
      },
      "outputs": [],
      "source": [
        "y_test = [x[1] for x in test_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQD1QmL4N_qy",
        "outputId": "7ec1e8f8-db47-4547-c539-75ebfa0d4cc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn_crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.64.1)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 13.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.8 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn_crfsuite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ETa-YLW3PUYa"
      },
      "outputs": [],
      "source": [
        "labels = list(test_data.all_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gIPYiFdcXD9V"
      },
      "outputs": [],
      "source": [
        "from sklearn_crfsuite.metrics import flat_f1_score\n",
        "# from sklearn_crfsuite.metrics import flat_classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Cm6p7x-XD9V",
        "outputId": "fc2d369e-d9fc-4eef-d544-c308eb755842"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8459202032817422\n"
          ]
        }
      ],
      "source": [
        "f1_score = flat_f1_score(y_test, y_pred, average=\"weighted\", labels=labels)\n",
        "print(f1_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJWHaFihRvQr"
      },
      "source": [
        "Посчитаем f1 метрику"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgc5k10nXD9V"
      },
      "source": [
        "##### BERT + BiLSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6cbogKyJR4N"
      },
      "outputs": [],
      "source": [
        "# !sudo update-alternatives --config python3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3ycARUkJXI6"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers\n",
        "#!pip install sklearn-crfsuite\n",
        "#!pip install pytorch-crf\n",
        "#!pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDeiaWUNNRXM",
        "outputId": "9efab6e4-1e7a-4516-a83e-f3da46b92ce1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'input_ids': tensor([  101,   783,   146,   783,   164,   122,   166,  1426,  1193,   117,\n",
              "            185, 15363, 11505, 19569,  6473,  3820,  1338,  1121,  1103,   188,\n",
              "          13564,  1197,  3925,   117,  7343,   170,  7329,  1104,  2495,  8420,\n",
              "           1113,  1134,   170,  5220,  1105,   170, 20015,  3191,  3809,   119,\n",
              "            102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0]),\n",
              "  'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])},\n",
              " tensor([4., 4., 4., 4., 4., 4., 4., 4., 4., 1., 8., 4., 4., 5., 2., 4., 4., 4.,\n",
              "         4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.]))"
            ]
          },
          "execution_count": 217,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IR4OPMuNbHq3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1GMDI8KXD9W"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from pytorch_lightning import LightningModule\n",
        "from torchcrf import CRF\n",
        "# from sklearn_crfsuite import CRF\n",
        "\n",
        "\n",
        "class BERTBiLSTMCRF(LightningModule):\n",
        "    __doc__ = \"\"\" bert bilstm crf \"\"\"\n",
        "\n",
        "    def __init__(self, lstm_num_layers, hidden_size, num_labels, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-cased\")\n",
        "        self.lstm = nn.LSTM(input_size=self.bert.config.hidden_size * 8,\n",
        "                            bidirectional=True,\n",
        "                            num_layers=lstm_num_layers,\n",
        "                            hidden_size=hidden_size,\n",
        "                            batch_first=True)\n",
        "        self.fc = nn.Linear(in_features=hidden_size * 2, out_features=num_labels)\n",
        "        self.crf = CRF(num_tags=num_labels, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, tokenized, tags_idx):\n",
        "        for i, word in enumerate(tokenized):\n",
        "          input_ids, token_type_ids, attention_mask = word['input_ids'], word['token_type_ids'], word['attention_mask']\n",
        "          if i == 0:\n",
        "            embeds = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)[0].view(1, -1)\n",
        "          else:\n",
        "            embed = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)[0].view(1, -1)\n",
        "            embeds = torch.cat([embeds, embed], axis=0)\n",
        "        print(embeds.shape)\n",
        "        lstm_out, _ = self.lstm(embeds)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        lstm_out = self.fc(lstm_out)\n",
        "        mask = tags_idx != 1\n",
        "        loss = self.crf(lstm_out, tags_idx, mask)\n",
        "        return -loss\n",
        "\n",
        "    def decode(self, tokenized):\n",
        "        for i, word in enumerate(tokenized):\n",
        "          input_ids, token_type_ids, attention_mask = word['input_ids'], word['token_type_ids'], word['attention_mask']\n",
        "          if i == 0:\n",
        "            embeds = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)[0].view(1, -1)\n",
        "          else:\n",
        "            embed = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)[0].view(1, -1)\n",
        "            embeds = torch.cat([embeds, embed], axis=0)\n",
        "        lstm_out, _ = self.lstm(embeds)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        lstm_out = self.fc(lstm_out)\n",
        "        results = self.crf.decode(lstm_out)\n",
        "        result_tensor = []\n",
        "        for result in results:\n",
        "            result_tensor.append(torch.tensor(result))\n",
        "        return torch.stack(result_tensor)\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        tokenized, labels = batch\n",
        "        train_loss = self(tokenized, labels)\n",
        "        return train_loss\n",
        "\n",
        "    def validation_step(self, batch, batch_nb):\n",
        "        tokenized, labels = batch\n",
        "        input_ids, token_type_ids, attention_mask = tokenized['input_ids'], tokenized['token_type_ids'], tokenized['attention_mask']\n",
        "        val_loss = self(input_ids, token_type_ids, attention_mask, labels)\n",
        "        self.log(\"val_loss\", val_loss, prog_bar=True, logger=True)\n",
        "        return val_loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "        return [optimizer]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcUFsqMqA7w-"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
        "\n",
        "class BookBertDataset(Dataset):\n",
        "    def __init__(self, pathes, tag_to_ix, max_tokens=8):\n",
        "        super().__init__()\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.all_labels = set()\n",
        "        self.read_books(pathes)\n",
        "        self.len = len(self.data)\n",
        "        self.max_tokens = max_tokens\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "        \n",
        "    def read_books(self, pathes):\n",
        "        for path in pathes:\n",
        "            folder_path = '/content/drive/MyDrive/litbank_entities/tsv/'\n",
        "            df = pd.read_csv(\n",
        "                folder_path + path, sep='\\t', quoting=csv.QUOTE_NONE, names=['word', 'label', '1', '2', '3', '4'], skip_blank_lines=False, index_col=False)\n",
        "            blanks = np.append(-1, df[df['word'].isna()].index)\n",
        "            for i in range(len(blanks) - 1):\n",
        "                self.data.append(df[blanks[i] + 1:blanks[i + 1]]['word'].values)\n",
        "                self.labels.append(df[blanks[i] + 1:blanks[i + 1]]['label'].values)\n",
        "            self.all_labels |= set(df.dropna(subset=['label'])['label'].values)\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        tokenized = [self.tokenizer(i,\n",
        "                                   add_special_tokens=True, \n",
        "                                   max_length=self.max_tokens, \n",
        "                                   padding=\"max_length\", \n",
        "                                   truncation=True,\n",
        "                                   return_tensors='pt') for i in self.data[index]]\n",
        "        tokenized = [{key: value.squeeze(0) for key, value in i.items()} for i in tokenized]\n",
        "        labels = torch.Tensor(list(map(lambda x : tag_to_ix[x], list(self.labels[index]))))\n",
        "        return tokenized, labels\n",
        "    \n",
        "\n",
        "training_data = BookBertDataset(train_pathes, tag_to_ix)\n",
        "val_data = BookBertDataset(val_pathes, tag_to_ix)\n",
        "test_data = BookBertDataset(test_pathes, tag_to_ix)\n",
        "\n",
        "train_sampler = RandomSampler(training_data)\n",
        "train_loader = DataLoader(training_data, sampler=train_sampler, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b81b4634a6e64f63857f49b3f744bcc0",
            "88d9e738e09d40aa9afe9172964392d1",
            "dc8d1ca612194ab896bb0510a5a9b606",
            "53f037ef348c4506a8ab10173c8c726f",
            "b0fa65a374c14dcd886e2249d046b44a",
            "fd35578273274b8f865ae9394d532c5b",
            "03f45326dc1a4512854e0f2bb570f8aa",
            "fd2a997fb98144bd8d6aa4102f221ed7",
            "9e7f4e4bb7874c509a10187b1800e8f0",
            "9ce013ef15114db6b39a884cc700b6b0",
            "4f45518413fa4d8abd38aee50c29c763"
          ]
        },
        "id": "QhzcHDgyXD9W",
        "outputId": "6fbd61b3-01e4-4373-8894-2fc01fc9b6f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name    | Type      | Params\n",
            "--------------------------------------\n",
            "0 | bert    | BertModel | 108 M \n",
            "1 | lstm    | LSTM      | 4.1 M \n",
            "2 | fc      | Linear    | 1.0 K \n",
            "3 | crf     | CRF       | 288   \n",
            "4 | dropout | Dropout   | 0     \n",
            "--------------------------------------\n",
            "112 M     Trainable params\n",
            "0         Non-trainable params\n",
            "112 M     Total params\n",
            "449.508   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b81b4634a6e64f63857f49b3f744bcc0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([81, 6144])\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-307-60b572899139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         call._call_and_handle_interrupt(\n\u001b[0;32m--> 583\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         )\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         )\n\u001b[0;32m--> 624\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}: trainer tearing down\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_EVALUATE_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_to_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_to_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_processed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_frequencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_idx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             )\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, optimizers, kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_position\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# automatic optimization assumes a loss needs to be returned for extras to be considered as the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_run_optimization\u001b[0;34m(self, kwargs, optimizer)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;31m# the `batch_idx` is optional with inter-batch parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_idx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsume_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mon_tpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTPUAccelerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0musing_native_amp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp_backend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mAMPType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNATIVE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             \u001b[0musing_lbfgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_lbfgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         )\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/module.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m         \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         return self.precision_plugin.optimizer_step(\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, model, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;34m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mclosure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_track_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py\u001b[0m in \u001b[0;36m_wrap_closure\u001b[0;34m(self, model, optimizer, optimizer_idx, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mconsistent\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mPrecisionPlugin\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0msubclasses\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdirectly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mclosure_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclosure_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mClosureResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \"\"\"\n\u001b[1;32m    405\u001b[0m         \u001b[0;31m# manually capture logged metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{self.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m         \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-305-31353011c01f>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_nb)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_nb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mtokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-305-31353011c01f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokenized, tags_idx)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtags_idx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchcrf/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, emissions, tags, mask, reduction)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mreduction\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mnone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \"\"\"\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memissions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'token_mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'invalid reduction: {reduction}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchcrf/__init__.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(self, emissions, tags, mask)\u001b[0m\n\u001b[1;32m    145\u001b[0m             mask: Optional[torch.ByteTensor] = None) -> None:\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0memissions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'emissions must have dimension of 3, got {emissions.dim()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0memissions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_tags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: emissions must have dimension of 3, got 2"
          ]
        }
      ],
      "source": [
        "from pytorch_lightning import Trainer\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 32\n",
        "\n",
        "model = BERTBiLSTMCRF(EMBEDDING_DIM, HIDDEN_DIM, len(tag_to_ix))\n",
        "\n",
        "trainer = Trainer(\n",
        "    gpus=1,\n",
        "    max_epochs=5\n",
        ")\n",
        "trainer.fit(model, train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u0QCqr_SM0C"
      },
      "source": [
        "## Часть 5. [1 балл] Итоги\n",
        "Напишите краткое резюме проделанной работы. Сравните результаты всех разработанных моделей. Что помогло вам в выполнении работы, чего не хватало?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ42_ZCwSNtI"
      },
      "source": [
        "Кратакое резюме проделанной работы:\n",
        "Изучили и проанализировали два набора данных: litbank и multinerd. Построили кластеризацию по этим данным. Также сумели обучить модель CNN + BiLSTM + CRF. К сожалению у нас возникло очень много проблем с реализицей модели BeRT + BiLSTM + CRF из-за чего мы застопорились."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "hw2.ipynb",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03f45326dc1a4512854e0f2bb570f8aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f45518413fa4d8abd38aee50c29c763": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53f037ef348c4506a8ab10173c8c726f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ce013ef15114db6b39a884cc700b6b0",
            "placeholder": "​",
            "style": "IPY_MODEL_4f45518413fa4d8abd38aee50c29c763",
            "value": " 0/6756 [00:00&lt;?, ?it/s]"
          }
        },
        "88d9e738e09d40aa9afe9172964392d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd35578273274b8f865ae9394d532c5b",
            "placeholder": "​",
            "style": "IPY_MODEL_03f45326dc1a4512854e0f2bb570f8aa",
            "value": "Epoch 0:   0%"
          }
        },
        "9ce013ef15114db6b39a884cc700b6b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e7f4e4bb7874c509a10187b1800e8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0fa65a374c14dcd886e2249d046b44a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "b81b4634a6e64f63857f49b3f744bcc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88d9e738e09d40aa9afe9172964392d1",
              "IPY_MODEL_dc8d1ca612194ab896bb0510a5a9b606",
              "IPY_MODEL_53f037ef348c4506a8ab10173c8c726f"
            ],
            "layout": "IPY_MODEL_b0fa65a374c14dcd886e2249d046b44a"
          }
        },
        "dc8d1ca612194ab896bb0510a5a9b606": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd2a997fb98144bd8d6aa4102f221ed7",
            "max": 6756,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e7f4e4bb7874c509a10187b1800e8f0",
            "value": 0
          }
        },
        "fd2a997fb98144bd8d6aa4102f221ed7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd35578273274b8f865ae9394d532c5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
